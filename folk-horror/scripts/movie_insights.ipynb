{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Insights Analysis - Phase 3\n",
    "## Transforming Features into Client-Ready Insights\n",
    "\n",
    "**Purpose**: Generate 7-slide analysis structure for each of 10 folk horror films\n",
    "\n",
    "**Input**: `reviews_enhanced.csv` (3,222 reviews √ó 76 features, 80.4% gender coverage)\n",
    "\n",
    "**Output**: Structured JSON files with slide-ready data + direct quotes\n",
    "\n",
    "---\n",
    "\n",
    "## Module Structure:\n",
    "- **Module 0**: Setup & Data Loading\n",
    "- **Module 1**: Audience Segmentation Analysis (Slide 1)\n",
    "- **Module 2**: What Resonated Analysis (Slide 3)\n",
    "- **Module 3**: What Didn't Work Analysis (Slide 4)\n",
    "- **Module 4**: Polarization Analysis (Slide 4 continued) [TO BE BUILT]\n",
    "- **Module 5**: Marketing Disconnect Analysis (Slide 5) [TO BE BUILT]\n",
    "- **Module 6**: Risk Factors Analysis (Slide 6) [TO BE BUILT]\n",
    "- **Module 7**: Target Audience Recommendation (Slides 2 & 7) [TO BE BUILT]\n",
    "- **Module 8**: Export Functions [TO BE BUILT]\n",
    "- **Module 9**: Cross-Movie Roll-Up [TO BE BUILT]\n",
    "\n",
    "---"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 0: Setup & Data Loading"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the enhanced dataset\n",
    "data_path = Path('/Users/jamesroot/Desktop/JAMES/Noetheca/Reviews/Data/reviews_enhanced.csv')\n",
    "\n",
    "print(f\"Loading dataset from: {data_path}\")\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset loaded successfully!\")\n",
    "print(f\"   Rows: {len(df):,}\")\n",
    "print(f\"   Columns: {len(df.columns)}\")\n",
    "print(f\"\\nüìä Movies in dataset:\")\n",
    "print(df['Movie_Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define movie list and helper functions\n",
    "MOVIES = df['Movie_Title'].unique().tolist()\n",
    "\n",
    "print(f\"\\nüìΩÔ∏è  Total movies: {len(MOVIES)}\")\n",
    "print(f\"\\nMovie list:\")\n",
    "for i, movie in enumerate(MOVIES, 1):\n",
    "    count = len(df[df['Movie_Title'] == movie])\n",
    "    print(f\"  {i}. {movie:30} ({count:4} reviews)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def get_movie_reviews(movie_name):\n",
    "    \"\"\"\n",
    "    Filter dataset to specific movie\n",
    "    Returns: DataFrame with only that movie's reviews\n",
    "    \"\"\"\n",
    "    return df[df['Movie_Title'] == movie_name].copy()\n",
    "\n",
    "def get_gender_segment(df_movie, gender):\n",
    "    \"\"\"\n",
    "    Filter movie reviews by gender\n",
    "    \n",
    "    Args:\n",
    "        df_movie: DataFrame filtered to one movie\n",
    "        gender: 'male', 'female', or 'unknown'\n",
    "    \n",
    "    Returns: DataFrame with only that gender\n",
    "    \"\"\"\n",
    "    return df_movie[df_movie['username_gender_hint'] == gender].copy()\n",
    "\n",
    "def safe_mean(series):\n",
    "    \"\"\"\n",
    "    Calculate mean, handling empty series gracefully\n",
    "    Returns: float or None\n",
    "    \"\"\"\n",
    "    if len(series) == 0:\n",
    "        return None\n",
    "    return float(series.mean())\n",
    "\n",
    "def safe_percentage(count, total):\n",
    "    \"\"\"\n",
    "    Calculate percentage, handling division by zero\n",
    "    Returns: float (0-100) or None\n",
    "    \"\"\"\n",
    "    if total == 0:\n",
    "        return None\n",
    "    return round((count / total) * 100, 1)\n",
    "\n",
    "def extract_quotes(df_filtered, column, limit=10):\n",
    "    \"\"\"\n",
    "    Extract quotes from reviews with Review_ID for traceability\n",
    "    \n",
    "    Args:\n",
    "        df_filtered: DataFrame (pre-filtered for criteria)\n",
    "        column: Column containing text/lists to extract\n",
    "        limit: Maximum number of quotes to return\n",
    "    \n",
    "    Returns: List of dicts with Review_ID, Reviewer, and content\n",
    "    \"\"\"\n",
    "    # Filter to rows where column has content\n",
    "    has_content = df_filtered[df_filtered[column].notna()].copy()\n",
    "    \n",
    "    # If column contains lists (like love_statements), filter for non-empty lists\n",
    "    if len(has_content) > 0:\n",
    "        # Check if first non-null value is a string that looks like a list\n",
    "        first_val = has_content[column].iloc[0]\n",
    "        if isinstance(first_val, str) and first_val.startswith('['):\n",
    "            has_content = has_content[has_content[column] != '[]']\n",
    "    \n",
    "    # Take top N by engagement (total_votes)\n",
    "    top_quotes = has_content.nlargest(limit, 'total_votes')\n",
    "    \n",
    "    # Extract relevant fields\n",
    "    quotes = []\n",
    "    for _, row in top_quotes.iterrows():\n",
    "        quotes.append({\n",
    "            'review_id': row['Review_ID'],\n",
    "            'reviewer': row['Reviewer'],\n",
    "            'rating': int(row['Rating']),\n",
    "            'content': row[column],\n",
    "            'engagement': int(row['total_votes']) if pd.notna(row['total_votes']) else 0\n",
    "        })\n",
    "    \n",
    "    return quotes\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset features are loaded correctly\n",
    "\n",
    "print(\"üîç Verifying key features...\\n\")\n",
    "\n",
    "# Check gender coverage\n",
    "gender_counts = df['username_gender_hint'].value_counts()\n",
    "identified = len(df[df['username_gender_hint'] != 'unknown'])\n",
    "coverage = (identified / len(df)) * 100\n",
    "\n",
    "print(f\"Gender Detection:\")\n",
    "print(f\"  Male: {gender_counts.get('male', 0):,}\")\n",
    "print(f\"  Female: {gender_counts.get('female', 0):,}\")\n",
    "print(f\"  Unknown: {gender_counts.get('unknown', 0):,}\")\n",
    "print(f\"  Coverage: {coverage:.1f}%\")\n",
    "\n",
    "# Check emotion columns\n",
    "emotion_cols = ['emotion_joy', 'emotion_trust', 'emotion_fear', 'emotion_surprise', \n",
    "                'emotion_sadness', 'emotion_disgust', 'emotion_anger', 'emotion_anticipation']\n",
    "print(f\"\\nEmotion Columns: {all(col in df.columns for col in emotion_cols)}\")\n",
    "\n",
    "# Check preference phrases\n",
    "print(f\"\\nPreference Phrases:\")\n",
    "print(f\"  Reviews with love_statements: {len(df[df['love_count'] > 0]):,}\")\n",
    "print(f\"  Reviews with hate_statements: {len(df[df['hate_count'] > 0]):,}\")\n",
    "print(f\"  Reviews with wish_statements: {len(df[df['wish_count'] > 0]):,}\")\n",
    "\n",
    "# Check engagement data\n",
    "print(f\"\\nEngagement:\")\n",
    "print(f\"  Reviews with votes: {len(df[df['has_engagement'] == True]):,}\")\n",
    "print(f\"  Avg votes per review: {df['total_votes'].mean():.1f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Feature verification complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module 1: Audience Segmentation Analysis\n",
    "**Purpose**: Generate data for Slide 1 - Overview & Ratings Distribution\n",
    "\n",
    "**Outputs**:\n",
    "- Total review count\n",
    "- Rating distribution (1-10)\n",
    "- Gender breakdown (with coverage %)\n",
    "- Average rating & variance\n",
    "- Temporal segments (when reviews were written)\n",
    "- Engagement patterns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audience_breakdown(movie_name):\n",
    "    \"\"\"\n",
    "    Generate Slide 1: Overview & Ratings Distribution\n",
    "    \n",
    "    Returns: Dictionary with audience segmentation data\n",
    "    \"\"\"\n",
    "    reviews = get_movie_reviews(movie_name)\n",
    "    \n",
    "    # Basic metrics\n",
    "    total_reviews = len(reviews)\n",
    "    \n",
    "    # Rating distribution\n",
    "    rating_dist = reviews['Rating'].value_counts().sort_index().to_dict()\n",
    "    avg_rating = safe_mean(reviews['Rating'])\n",
    "    rating_variance = float(reviews['Rating'].var()) if len(reviews) > 0 else None\n",
    "    \n",
    "    # Gender breakdown\n",
    "    gender_counts = reviews['username_gender_hint'].value_counts().to_dict()\n",
    "    identified = len(reviews[reviews['username_gender_hint'] != 'unknown'])\n",
    "    gender_coverage = safe_percentage(identified, total_reviews)\n",
    "    \n",
    "    # Temporal segments\n",
    "    temporal_dist = reviews['review_window'].value_counts().to_dict()\n",
    "    \n",
    "    # Engagement patterns\n",
    "    has_engagement = len(reviews[reviews['has_engagement'] == True])\n",
    "    engagement_pct = safe_percentage(has_engagement, total_reviews)\n",
    "    avg_votes = safe_mean(reviews['total_votes'])\n",
    "    avg_helpfulness = safe_mean(reviews['helpfulness_ratio'])\n",
    "    \n",
    "    # Segment by rating groups\n",
    "    lovers = len(reviews[reviews['Rating'] >= 8])  # 8-10\n",
    "    mixed = len(reviews[(reviews['Rating'] >= 4) & (reviews['Rating'] <= 7)])  # 4-7\n",
    "    haters = len(reviews[reviews['Rating'] <= 3])  # 1-3\n",
    "    \n",
    "    return {\n",
    "        'movie': movie_name,\n",
    "        'total_reviews': total_reviews,\n",
    "        'rating_distribution': rating_dist,\n",
    "        'avg_rating': avg_rating,\n",
    "        'rating_variance': rating_variance,\n",
    "        \n",
    "        'rating_segments': {\n",
    "            'lovers_8_10': lovers,\n",
    "            'lovers_pct': safe_percentage(lovers, total_reviews),\n",
    "            'mixed_4_7': mixed,\n",
    "            'mixed_pct': safe_percentage(mixed, total_reviews),\n",
    "            'haters_1_3': haters,\n",
    "            'haters_pct': safe_percentage(haters, total_reviews)\n",
    "        },\n",
    "        \n",
    "        'gender_breakdown': {\n",
    "            'male': gender_counts.get('male', 0),\n",
    "            'female': gender_counts.get('female', 0),\n",
    "            'unknown': gender_counts.get('unknown', 0),\n",
    "            'coverage_pct': gender_coverage\n",
    "        },\n",
    "        \n",
    "        'temporal_segments': temporal_dist,\n",
    "        \n",
    "        'engagement': {\n",
    "            'reviews_with_votes': has_engagement,\n",
    "            'engagement_pct': engagement_pct,\n",
    "            'avg_votes_per_review': avg_votes,\n",
    "            'avg_helpfulness_ratio': avg_helpfulness\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ audience_breakdown() function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Module 1 on The Witch (largest dataset)\n",
    "\n",
    "print(\"üß™ Testing Module 1: Audience Segmentation\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_movie = \"The Witch\"\n",
    "result = audience_breakdown(test_movie)\n",
    "\n",
    "# Display results in readable format\n",
    "print(f\"\\nüìä AUDIENCE BREAKDOWN: {test_movie}\")\n",
    "print(f\"\\nTotal Reviews: {result['total_reviews']:,}\")\n",
    "print(f\"Average Rating: {result['avg_rating']:.2f}/10\")\n",
    "print(f\"Rating Variance: {result['rating_variance']:.2f}\")\n",
    "\n",
    "print(f\"\\nüìà Rating Segments:\")\n",
    "print(f\"  Lovers (8-10): {result['rating_segments']['lovers_8_10']:,} ({result['rating_segments']['lovers_pct']}%)\")\n",
    "print(f\"  Mixed (4-7):   {result['rating_segments']['mixed_4_7']:,} ({result['rating_segments']['mixed_pct']}%)\")\n",
    "print(f\"  Haters (1-3):  {result['rating_segments']['haters_1_3']:,} ({result['rating_segments']['haters_pct']}%)\")\n",
    "\n",
    "print(f\"\\nüë• Gender Breakdown ({result['gender_breakdown']['coverage_pct']}% coverage):\")\n",
    "print(f\"  Male:    {result['gender_breakdown']['male']:,}\")\n",
    "print(f\"  Female:  {result['gender_breakdown']['female']:,}\")\n",
    "print(f\"  Unknown: {result['gender_breakdown']['unknown']:,}\")\n",
    "\n",
    "print(f\"\\nüìÖ Temporal Distribution:\")\n",
    "for window, count in sorted(result['temporal_segments'].items()):\n",
    "    print(f\"  {window:20} {count:4} reviews\")\n",
    "\n",
    "print(f\"\\nüí¨ Engagement:\")\n",
    "print(f\"  Reviews with votes: {result['engagement']['reviews_with_votes']:,} ({result['engagement']['engagement_pct']}%)\")\n",
    "print(f\"  Avg votes: {result['engagement']['avg_votes_per_review']:.1f}\")\n",
    "print(f\"  Avg helpfulness: {result['engagement']['avg_helpfulness_ratio']:.2f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Module 1 test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module 2: What Resonated Analysis (Lovers)\n",
    "**Purpose**: Generate data for Slide 3 - What Resonated (by demographic)\n",
    "\n",
    "**Focus**: Reviews with Rating >= 8\n",
    "\n",
    "**Outputs**:\n",
    "- Total lovers count\n",
    "- Gender segmentation of lovers\n",
    "- Emotion profiles by gender (joy, trust, fear, anticipation)\n",
    "- Love statements with quotes\n",
    "- Writing style profiles (analytical vs emotional)\n",
    "- Top themes/patterns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def what_resonated(movie_name):\n",
    "    \"\"\"\n",
    "    Generate Slide 3: What Resonated (by demographic)\n",
    "    \n",
    "    Analyzes reviews with Rating >= 8\n",
    "    \n",
    "    Returns: Dictionary with lover insights segmented by gender\n",
    "    \"\"\"\n",
    "    reviews = get_movie_reviews(movie_name)\n",
    "    lovers = reviews[reviews['Rating'] >= 8].copy()\n",
    "    \n",
    "    total_lovers = len(lovers)\n",
    "    \n",
    "    if total_lovers == 0:\n",
    "        return {\n",
    "            'movie': movie_name,\n",
    "            'total_lovers': 0,\n",
    "            'message': 'No reviews with rating >= 8'\n",
    "        }\n",
    "    \n",
    "    # Gender segmentation\n",
    "    male_lovers = get_gender_segment(lovers, 'male')\n",
    "    female_lovers = get_gender_segment(lovers, 'female')\n",
    "    \n",
    "    # Emotion profiles by gender (note: columns are prefixed with emotion_)\n",
    "    emotion_cols = ['emotion_joy', 'emotion_trust', 'emotion_fear', 'emotion_surprise', \n",
    "                    'emotion_sadness', 'emotion_disgust', 'emotion_anger', 'emotion_anticipation']\n",
    "    \n",
    "    # Remove 'emotion_' prefix for cleaner output\n",
    "    all_emotions = {col.replace('emotion_', ''): safe_mean(lovers[col]) for col in emotion_cols}\n",
    "    male_emotions = {col.replace('emotion_', ''): safe_mean(male_lovers[col]) for col in emotion_cols} if len(male_lovers) > 0 else {}\n",
    "    female_emotions = {col.replace('emotion_', ''): safe_mean(female_lovers[col]) for col in emotion_cols} if len(female_lovers) > 0 else {}\n",
    "    \n",
    "    # Love statements\n",
    "    lovers_with_love = lovers[lovers['love_count'] > 0]\n",
    "    love_quotes = extract_quotes(lovers_with_love, 'love_statements', limit=10)\n",
    "    \n",
    "    # Writing style analysis\n",
    "    avg_reading_ease = safe_mean(lovers['flesch_reading_ease'])\n",
    "    avg_grade_level = safe_mean(lovers['flesch_kincaid_grade'])\n",
    "    avg_first_person = safe_mean(lovers['first_person_ratio'])\n",
    "    avg_exclamations = safe_mean(lovers['exclamation_count'])\n",
    "    \n",
    "    # Determine writing style profile\n",
    "    if avg_first_person and avg_first_person > 0.03:\n",
    "        style_profile = 'emotional/personal'\n",
    "    elif avg_reading_ease and avg_reading_ease < 60:\n",
    "        style_profile = 'analytical/complex'\n",
    "    else:\n",
    "        style_profile = 'balanced'\n",
    "    \n",
    "    # Comparison films mentioned\n",
    "    comparisons = lovers[lovers['has_comparisons'] == True]\n",
    "    comparison_pct = safe_percentage(len(comparisons), total_lovers)\n",
    "    \n",
    "    return {\n",
    "        'movie': movie_name,\n",
    "        'total_lovers': total_lovers,\n",
    "        'lovers_pct_of_all_reviews': safe_percentage(total_lovers, len(reviews)),\n",
    "        \n",
    "        'gender_segmentation': {\n",
    "            'male': len(male_lovers),\n",
    "            'male_pct': safe_percentage(len(male_lovers), total_lovers),\n",
    "            'female': len(female_lovers),\n",
    "            'female_pct': safe_percentage(len(female_lovers), total_lovers),\n",
    "            'unknown': total_lovers - len(male_lovers) - len(female_lovers)\n",
    "        },\n",
    "        \n",
    "        'emotion_profiles': {\n",
    "            'all_lovers': all_emotions,\n",
    "            'male_lovers': male_emotions,\n",
    "            'female_lovers': female_emotions\n",
    "        },\n",
    "        \n",
    "        'love_statements': {\n",
    "            'count': len(lovers_with_love),\n",
    "            'percentage': safe_percentage(len(lovers_with_love), total_lovers),\n",
    "            'quotes': love_quotes\n",
    "        },\n",
    "        \n",
    "        'writing_style': {\n",
    "            'profile': style_profile,\n",
    "            'avg_reading_ease': avg_reading_ease,\n",
    "            'avg_grade_level': avg_grade_level,\n",
    "            'avg_first_person_ratio': avg_first_person,\n",
    "            'avg_exclamations': avg_exclamations\n",
    "        },\n",
    "        \n",
    "        'comparisons': {\n",
    "            'reviews_with_comparisons': len(comparisons),\n",
    "            'comparison_pct': comparison_pct\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ what_resonated() function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Module 2 on The Witch\n",
    "\n",
    "print(\"üß™ Testing Module 2: What Resonated (Lovers)\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_movie = \"The Witch\"\n",
    "result = what_resonated(test_movie)\n",
    "\n",
    "print(f\"\\n‚ù§Ô∏è  WHAT RESONATED: {test_movie}\")\n",
    "print(f\"\\nLovers (Rating >= 8): {result['total_lovers']:,} ({result['lovers_pct_of_all_reviews']}% of all reviews)\")\n",
    "\n",
    "print(f\"\\nüë• Gender Breakdown of Lovers:\")\n",
    "print(f\"  Male:   {result['gender_segmentation']['male']:,} ({result['gender_segmentation']['male_pct']}%)\")\n",
    "print(f\"  Female: {result['gender_segmentation']['female']:,} ({result['gender_segmentation']['female_pct']}%)\")\n",
    "print(f\"  Unknown: {result['gender_segmentation']['unknown']:,}\")\n",
    "\n",
    "print(f\"\\nüòä Emotion Profiles (All Lovers):\")\n",
    "for emotion, score in result['emotion_profiles']['all_lovers'].items():\n",
    "    if score:\n",
    "        print(f\"  {emotion.capitalize():12} {score:.3f}\")\n",
    "\n",
    "if result['emotion_profiles']['male_lovers'] and result['emotion_profiles']['female_lovers']:\n",
    "    print(f\"\\nüìä Gender Emotion Comparison (Top 3 emotions):\")\n",
    "    print(f\"\\n  Male Lovers:\")\n",
    "    male_sorted = sorted(result['emotion_profiles']['male_lovers'].items(), key=lambda x: x[1] if x[1] else 0, reverse=True)[:3]\n",
    "    for emotion, score in male_sorted:\n",
    "        if score:\n",
    "            print(f\"    {emotion.capitalize():12} {score:.3f}\")\n",
    "    \n",
    "    print(f\"\\n  Female Lovers:\")\n",
    "    female_sorted = sorted(result['emotion_profiles']['female_lovers'].items(), key=lambda x: x[1] if x[1] else 0, reverse=True)[:3]\n",
    "    for emotion, score in female_sorted:\n",
    "        if score:\n",
    "            print(f\"    {emotion.capitalize():12} {score:.3f}\")\n",
    "\n",
    "print(f\"\\nüí¨ Love Statements:\")\n",
    "print(f\"  Reviews with love statements: {result['love_statements']['count']} ({result['love_statements']['percentage']}%)\")\n",
    "\n",
    "if result['love_statements']['quotes']:\n",
    "    print(f\"\\n  üìù Top 3 Love Quotes (by engagement):\")\n",
    "    for i, quote in enumerate(result['love_statements']['quotes'][:3], 1):\n",
    "        print(f\"\\n  {i}. [{quote['review_id']}] by {quote['reviewer']} (Rating: {quote['rating']}/10, Votes: {quote['engagement']})\")\n",
    "        content = quote['content'][:200] + '...' if len(quote['content']) > 200 else quote['content']\n",
    "        print(f\"     {content}\")\n",
    "\n",
    "print(f\"\\n‚úçÔ∏è  Writing Style:\")\n",
    "print(f\"  Profile: {result['writing_style']['profile']}\")\n",
    "print(f\"  Avg Reading Ease: {result['writing_style']['avg_reading_ease']:.1f}\")\n",
    "print(f\"  Avg Grade Level: {result['writing_style']['avg_grade_level']:.1f}\")\n",
    "print(f\"  Avg First Person Usage: {result['writing_style']['avg_first_person_ratio']:.3f}\")\n",
    "print(f\"  Avg Exclamations: {result['writing_style']['avg_exclamations']:.1f}\")\n",
    "\n",
    "print(f\"\\nüé¨ Comparisons:\")\n",
    "print(f\"  Reviews mentioning other films: {result['comparisons']['reviews_with_comparisons']} ({result['comparisons']['comparison_pct']}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Module 2 test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module 3: What Didn't Work Analysis (Haters)\n",
    "**Purpose**: Generate data for Slide 4 - What Didn't Work (polarization points)\n",
    "\n",
    "**Focus**: Reviews with Rating <= 3\n",
    "\n",
    "**Outputs**:\n",
    "- Total haters count\n",
    "- Gender segmentation of haters\n",
    "- Emotion profiles (anger, disgust, sadness)\n",
    "- Hate statements and wish statements with quotes\n",
    "- Comparison films (what did they expect vs what they got)\n",
    "- Common pain points"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def what_didnt_work(movie_name):\n",
    "    \"\"\"\n",
    "    Generate Slide 4: What Didn't Work (polarization points)\n",
    "    \n",
    "    Analyzes reviews with Rating <= 3\n",
    "    \n",
    "    Returns: Dictionary with hater insights\n",
    "    \"\"\"\n",
    "    reviews = get_movie_reviews(movie_name)\n",
    "    haters = reviews[reviews['Rating'] <= 3].copy()\n",
    "    \n",
    "    total_haters = len(haters)\n",
    "    \n",
    "    if total_haters == 0:\n",
    "        return {\n",
    "            'movie': movie_name,\n",
    "            'total_haters': 0,\n",
    "            'message': 'No reviews with rating <= 3'\n",
    "        }\n",
    "    \n",
    "    # Gender segmentation\n",
    "    male_haters = get_gender_segment(haters, 'male')\n",
    "    female_haters = get_gender_segment(haters, 'female')\n",
    "    \n",
    "    # Emotion profiles - focus on negative emotions\n",
    "    negative_emotions = ['emotion_anger', 'emotion_disgust', 'emotion_sadness', 'emotion_fear']\n",
    "    \n",
    "    all_emotions = {col.replace('emotion_', ''): safe_mean(haters[col]) for col in negative_emotions}\n",
    "    male_emotions = {col.replace('emotion_', ''): safe_mean(male_haters[col]) for col in negative_emotions} if len(male_haters) > 0 else {}\n",
    "    female_emotions = {col.replace('emotion_', ''): safe_mean(female_haters[col]) for col in negative_emotions} if len(female_haters) > 0 else {}\n",
    "    \n",
    "    # Hate statements\n",
    "    haters_with_hate = haters[haters['hate_count'] > 0]\n",
    "    hate_quotes = extract_quotes(haters_with_hate, 'hate_statements', limit=10)\n",
    "    \n",
    "    # Wish statements (\"I wish it had...\")\n",
    "    haters_with_wish = haters[haters['wish_count'] > 0]\n",
    "    wish_quotes = extract_quotes(haters_with_wish, 'wish_statements', limit=10)\n",
    "    \n",
    "    # Comparison films - what did they expect?\n",
    "    haters_with_comparisons = haters[haters['has_comparisons'] == True]\n",
    "    comparison_pct = safe_percentage(len(haters_with_comparisons), total_haters)\n",
    "    \n",
    "    # Extract mentioned movies from haters\n",
    "    mentioned_movies = []\n",
    "    if 'movies_mentioned' in haters.columns:\n",
    "        for movies in haters['movies_mentioned'].dropna():\n",
    "            if isinstance(movies, str) and movies != '[]':\n",
    "                # Parse the list string\n",
    "                import ast\n",
    "                try:\n",
    "                    movie_list = ast.literal_eval(movies)\n",
    "                    mentioned_movies.extend(movie_list)\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    from collections import Counter\n",
    "    movie_mentions = dict(Counter(mentioned_movies).most_common(10))\n",
    "    \n",
    "    # Writing style\n",
    "    avg_reading_ease = safe_mean(haters['flesch_reading_ease'])\n",
    "    avg_grade_level = safe_mean(haters['flesch_kincaid_grade'])\n",
    "    avg_exclamations = safe_mean(haters['exclamation_count'])\n",
    "    avg_caps = safe_mean(haters['caps_word_count'])\n",
    "    \n",
    "    # Question count - indicates confusion/disappointment\n",
    "    haters_with_questions = haters[haters['question_count'] > 0]\n",
    "    question_pct = safe_percentage(len(haters_with_questions), total_haters)\n",
    "    \n",
    "    return {\n",
    "        'movie': movie_name,\n",
    "        'total_haters': total_haters,\n",
    "        'haters_pct_of_all_reviews': safe_percentage(total_haters, len(reviews)),\n",
    "        \n",
    "        'gender_segmentation': {\n",
    "            'male': len(male_haters),\n",
    "            'male_pct': safe_percentage(len(male_haters), total_haters),\n",
    "            'female': len(female_haters),\n",
    "            'female_pct': safe_percentage(len(female_haters), total_haters),\n",
    "            'unknown': total_haters - len(male_haters) - len(female_haters)\n",
    "        },\n",
    "        \n",
    "        'emotion_profiles': {\n",
    "            'all_haters': all_emotions,\n",
    "            'male_haters': male_emotions,\n",
    "            'female_haters': female_emotions\n",
    "        },\n",
    "        \n",
    "        'hate_statements': {\n",
    "            'count': len(haters_with_hate),\n",
    "            'percentage': safe_percentage(len(haters_with_hate), total_haters),\n",
    "            'quotes': hate_quotes\n",
    "        },\n",
    "        \n",
    "        'wish_statements': {\n",
    "            'count': len(haters_with_wish),\n",
    "            'percentage': safe_percentage(len(haters_with_wish), total_haters),\n",
    "            'quotes': wish_quotes\n",
    "        },\n",
    "        \n",
    "        'comparisons': {\n",
    "            'reviews_with_comparisons': len(haters_with_comparisons),\n",
    "            'comparison_pct': comparison_pct,\n",
    "            'mentioned_movies': movie_mentions\n",
    "        },\n",
    "        \n",
    "        'writing_indicators': {\n",
    "            'avg_reading_ease': avg_reading_ease,\n",
    "            'avg_grade_level': avg_grade_level,\n",
    "            'avg_exclamations': avg_exclamations,\n",
    "            'avg_caps_words': avg_caps,\n",
    "            'reviews_with_questions': len(haters_with_questions),\n",
    "            'question_pct': question_pct\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ what_didnt_work() function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Module 3 on The Witch\n",
    "\n",
    "print(\"üß™ Testing Module 3: What Didn't Work (Haters)\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_movie = \"The Witch\"\n",
    "result = what_didnt_work(test_movie)\n",
    "\n",
    "print(f\"\\nüíî WHAT DIDN'T WORK: {test_movie}\")\n",
    "print(f\"\\nHaters (Rating <= 3): {result['total_haters']:,} ({result['haters_pct_of_all_reviews']}% of all reviews)\")\n",
    "\n",
    "print(f\"\\nüë• Gender Breakdown of Haters:\")\n",
    "print(f\"  Male:   {result['gender_segmentation']['male']:,} ({result['gender_segmentation']['male_pct']}%)\")\n",
    "print(f\"  Female: {result['gender_segmentation']['female']:,} ({result['gender_segmentation']['female_pct']}%)\")\n",
    "print(f\"  Unknown: {result['gender_segmentation']['unknown']:,}\")\n",
    "\n",
    "print(f\"\\nüò† Negative Emotion Profiles (All Haters):\")\n",
    "for emotion, score in sorted(result['emotion_profiles']['all_haters'].items(), key=lambda x: x[1] if x[1] else 0, reverse=True):\n",
    "    if score:\n",
    "        print(f\"  {emotion.capitalize():12} {score:.3f}\")\n",
    "\n",
    "print(f\"\\nüí¨ Hate Statements:\")\n",
    "print(f\"  Reviews with hate statements: {result['hate_statements']['count']} ({result['hate_statements']['percentage']}%)\")\n",
    "\n",
    "if result['hate_statements']['quotes']:\n",
    "    print(f\"\\n  üìù Top 3 Hate Quotes (by engagement):\")\n",
    "    for i, quote in enumerate(result['hate_statements']['quotes'][:3], 1):\n",
    "        print(f\"\\n  {i}. [{quote['review_id']}] by {quote['reviewer']} (Rating: {quote['rating']}/10, Votes: {quote['engagement']})\")\n",
    "        content = quote['content'][:200] + '...' if len(quote['content']) > 200 else quote['content']\n",
    "        print(f\"     {content}\")\n",
    "\n",
    "print(f\"\\nüôè Wish Statements:\")\n",
    "print(f\"  Reviews with wish statements: {result['wish_statements']['count']} ({result['wish_statements']['percentage']}%)\")\n",
    "\n",
    "if result['wish_statements']['quotes']:\n",
    "    print(f\"\\n  üìù Top 3 Wish Quotes (by engagement):\")\n",
    "    for i, quote in enumerate(result['wish_statements']['quotes'][:3], 1):\n",
    "        print(f\"\\n  {i}. [{quote['review_id']}] by {quote['reviewer']} (Rating: {quote['rating']}/10, Votes: {quote['engagement']})\")\n",
    "        content = quote['content'][:200] + '...' if len(quote['content']) > 200 else quote['content']\n",
    "        print(f\"     {content}\")\n",
    "\n",
    "print(f\"\\nüé¨ Comparisons (What They Expected):\")\n",
    "print(f\"  Reviews mentioning other films: {result['comparisons']['reviews_with_comparisons']} ({result['comparisons']['comparison_pct']}%)\")\n",
    "\n",
    "if result['comparisons']['mentioned_movies']:\n",
    "    print(f\"\\n  Most Mentioned Films:\")\n",
    "    for movie, count in list(result['comparisons']['mentioned_movies'].items())[:5]:\n",
    "        print(f\"    {movie:40} {count:3} mentions\")\n",
    "\n",
    "print(f\"\\n‚úçÔ∏è  Writing Indicators (Emotional Intensity):\")\n",
    "print(f\"  Avg Reading Ease: {result['writing_indicators']['avg_reading_ease']:.1f}\")\n",
    "print(f\"  Avg Grade Level: {result['writing_indicators']['avg_grade_level']:.1f}\")\n",
    "print(f\"  Avg Exclamations: {result['writing_indicators']['avg_exclamations']:.1f}\")\n",
    "print(f\"  Avg CAPS Words: {result['writing_indicators']['avg_caps_words']:.1f}\")\n",
    "print(f\"  Reviews with Questions: {result['writing_indicators']['reviews_with_questions']} ({result['writing_indicators']['question_pct']}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Module 3 test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Next Steps\n",
    "\n",
    "**Modules 1-3 Complete!** ‚úÖ\n",
    "\n",
    "**Ready to build:**\n",
    "- Module 4: Polarization Analysis\n",
    "- Module 5: Marketing Disconnect Analysis\n",
    "- Module 6: Risk Factors Analysis\n",
    "- Module 7: Target Audience Recommendation\n",
    "- Module 8: Export Functions (generate JSON files)\n",
    "- Module 9: Cross-Movie Roll-Up\n",
    "\n",
    "**Current Status:**\n",
    "- ‚úÖ Data loading and helper functions working\n",
    "- ‚úÖ Audience breakdown analysis (Slide 1 data)\n",
    "- ‚úÖ What resonated analysis (Slide 3 data)\n",
    "- ‚úÖ What didn't work analysis (Slide 4 data)\n",
    "- ‚úÖ Gender segmentation functioning at 80.4% coverage\n",
    "- ‚úÖ Quote extraction with traceability (Review_IDs)\n",
    "- ‚úÖ Emotion profiling by demographic\n",
    "\n",
    "**Testing passed on:** The Witch (1,105 reviews)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# MODULE 4: POLARIZATION ANALYSIS\n",
    "\n",
    "**Purpose**: Generate data for Slide 4 (continued) - What Divides Audiences\n",
    "\n",
    "**Approach**: Compare lovers (8-10) vs haters (1-3) to identify polarizing elements\n",
    "\n",
    "**Outputs**:\n",
    "- Polarization metrics (rating variance, vote distribution)\n",
    "- Emotion divergence (which emotions differ most between lovers/haters)\n",
    "- Theme contradictions (what lovers praise vs haters criticize)\n",
    "- Gender-based polarization patterns\n",
    "- Review timing patterns (early vs late polarization)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarization_analysis(movie_name):\n",
    "    \"\"\"\n",
    "    Generate Slide 4 (continued): Polarization Analysis\n",
    "    \n",
    "    Compares lovers (8-10) vs haters (1-3) to identify what divides audiences\n",
    "    \n",
    "    Returns: Dictionary with polarization insights\n",
    "    \"\"\"\n",
    "    reviews = get_movie_reviews(movie_name)\n",
    "    \n",
    "    # Get lovers and haters\n",
    "    lovers = reviews[reviews['Rating'] >= 8].copy()\n",
    "    haters = reviews[reviews['Rating'] <= 3].copy()\n",
    "    \n",
    "    total_reviews = len(reviews)\n",
    "    \n",
    "    # Basic polarization metrics\n",
    "    rating_variance = float(reviews['Rating'].var())\n",
    "    rating_std = float(reviews['Rating'].std())\n",
    "    \n",
    "    # Bimodal distribution check (high variance + gap in middle ratings)\n",
    "    middle_reviews = len(reviews[(reviews['Rating'] >= 4) & (reviews['Rating'] <= 7)])\n",
    "    middle_pct = safe_percentage(middle_reviews, total_reviews)\n",
    "    \n",
    "    # Determine polarization level\n",
    "    if rating_variance > 8 and middle_pct and middle_pct < 30:\n",
    "        polarization_level = \"HIGHLY_POLARIZING\"\n",
    "    elif rating_variance > 6:\n",
    "        polarization_level = \"MODERATELY_POLARIZING\"\n",
    "    else:\n",
    "        polarization_level = \"CONSENSUS\"\n",
    "    \n",
    "    # Emotion divergence analysis\n",
    "    emotion_cols = ['emotion_joy', 'emotion_trust', 'emotion_fear', 'emotion_surprise', \n",
    "                    'emotion_sadness', 'emotion_disgust', 'emotion_anger', 'emotion_anticipation']\n",
    "    \n",
    "    emotion_divergence = {}\n",
    "    for col in emotion_cols:\n",
    "        lovers_mean = safe_mean(lovers[col])\n",
    "        haters_mean = safe_mean(haters[col])\n",
    "        \n",
    "        if lovers_mean is not None and haters_mean is not None:\n",
    "            divergence = abs(lovers_mean - haters_mean)\n",
    "            emotion_name = col.replace('emotion_', '')\n",
    "            emotion_divergence[emotion_name] = {\n",
    "                'lovers_score': lovers_mean,\n",
    "                'haters_score': haters_mean,\n",
    "                'divergence': divergence\n",
    "            }\n",
    "    \n",
    "    # Sort by divergence to find most polarizing emotions\n",
    "    sorted_emotions = sorted(emotion_divergence.items(), \n",
    "                            key=lambda x: x[1]['divergence'], \n",
    "                            reverse=True)\n",
    "    \n",
    "    # Writing style differences\n",
    "    style_differences = {\n",
    "        'reading_ease': {\n",
    "            'lovers': safe_mean(lovers['flesch_reading_ease']),\n",
    "            'haters': safe_mean(haters['flesch_reading_ease']),\n",
    "            'difference': safe_mean(haters['flesch_reading_ease']) - safe_mean(lovers['flesch_reading_ease']) if safe_mean(haters['flesch_reading_ease']) and safe_mean(lovers['flesch_reading_ease']) else None\n",
    "        },\n",
    "        'grade_level': {\n",
    "            'lovers': safe_mean(lovers['flesch_kincaid_grade']),\n",
    "            'haters': safe_mean(haters['flesch_kincaid_grade']),\n",
    "            'difference': safe_mean(haters['flesch_kincaid_grade']) - safe_mean(lovers['flesch_kincaid_grade']) if safe_mean(haters['flesch_kincaid_grade']) and safe_mean(lovers['flesch_kincaid_grade']) else None\n",
    "        },\n",
    "        'first_person_usage': {\n",
    "            'lovers': safe_mean(lovers['first_person_ratio']),\n",
    "            'haters': safe_mean(haters['first_person_ratio']),\n",
    "            'difference': safe_mean(haters['first_person_ratio']) - safe_mean(lovers['first_person_ratio']) if safe_mean(haters['first_person_ratio']) and safe_mean(lovers['first_person_ratio']) else None\n",
    "        },\n",
    "        'exclamations': {\n",
    "            'lovers': safe_mean(lovers['exclamation_count']),\n",
    "            'haters': safe_mean(haters['exclamation_count']),\n",
    "            'difference': safe_mean(haters['exclamation_count']) - safe_mean(lovers['exclamation_count']) if safe_mean(haters['exclamation_count']) and safe_mean(lovers['exclamation_count']) else None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Engagement patterns\n",
    "    lovers_avg_votes = safe_mean(lovers['total_votes'])\n",
    "    haters_avg_votes = safe_mean(haters['total_votes'])\n",
    "    \n",
    "    lovers_polarization = safe_mean(lovers['vote_polarization'])\n",
    "    haters_polarization = safe_mean(haters['vote_polarization'])\n",
    "    \n",
    "    # Temporal polarization (early vs late reviews)\n",
    "    early_reviews = reviews[reviews['review_window'].isin(['Opening Year', 'Year 2'])]\n",
    "    late_reviews = reviews[reviews['review_window'].isin(['Years 4-5', '5+ Years'])]\n",
    "    \n",
    "    early_avg_rating = safe_mean(early_reviews['Rating'])\n",
    "    late_avg_rating = safe_mean(late_reviews['Rating'])\n",
    "    \n",
    "    temporal_shift = None\n",
    "    if early_avg_rating and late_avg_rating:\n",
    "        temporal_shift = late_avg_rating - early_avg_rating\n",
    "    \n",
    "    # Gender polarization\n",
    "    male_reviews = reviews[reviews['username_gender_hint'] == 'male']\n",
    "    female_reviews = reviews[reviews['username_gender_hint'] == 'female']\n",
    "    \n",
    "    male_avg_rating = safe_mean(male_reviews['Rating'])\n",
    "    female_avg_rating = safe_mean(female_reviews['Rating'])\n",
    "    \n",
    "    gender_rating_gap = None\n",
    "    if male_avg_rating and female_avg_rating:\n",
    "        gender_rating_gap = abs(male_avg_rating - female_avg_rating)\n",
    "    \n",
    "    # Identify contradictions (lovers praise vs haters criticize)\n",
    "    # Find themes mentioned by both groups\n",
    "    lovers_comparisons = lovers[lovers['has_comparisons'] == True]\n",
    "    haters_comparisons = haters[haters['has_comparisons'] == True]\n",
    "    \n",
    "    comparison_contradiction_pct = None\n",
    "    if len(lovers) > 0 and len(haters) > 0:\n",
    "        lovers_compare_pct = len(lovers_comparisons) / len(lovers) * 100\n",
    "        haters_compare_pct = len(haters_comparisons) / len(haters) * 100\n",
    "        comparison_contradiction_pct = abs(lovers_compare_pct - haters_compare_pct)\n",
    "    \n",
    "    return {\n",
    "        'movie': movie_name,\n",
    "        \n",
    "        'polarization_metrics': {\n",
    "            'level': polarization_level,\n",
    "            'rating_variance': rating_variance,\n",
    "            'rating_std_dev': rating_std,\n",
    "            'middle_ground_pct': middle_pct,\n",
    "            'lovers_pct': safe_percentage(len(lovers), total_reviews),\n",
    "            'haters_pct': safe_percentage(len(haters), total_reviews)\n",
    "        },\n",
    "        \n",
    "        'emotion_divergence': {\n",
    "            'top_5_divergent': [(emotion, data) for emotion, data in sorted_emotions[:5]],\n",
    "            'all_emotions': emotion_divergence\n",
    "        },\n",
    "        \n",
    "        'writing_style_differences': style_differences,\n",
    "        \n",
    "        'engagement_patterns': {\n",
    "            'lovers_avg_votes': lovers_avg_votes,\n",
    "            'haters_avg_votes': haters_avg_votes,\n",
    "            'lovers_vote_polarization': lovers_polarization,\n",
    "            'haters_vote_polarization': haters_polarization\n",
    "        },\n",
    "        \n",
    "        'temporal_polarization': {\n",
    "            'early_avg_rating': early_avg_rating,\n",
    "            'late_avg_rating': late_avg_rating,\n",
    "            'temporal_shift': temporal_shift,\n",
    "            'shift_direction': 'improved' if temporal_shift and temporal_shift > 0 else 'declined' if temporal_shift and temporal_shift < 0 else 'stable'\n",
    "        },\n",
    "        \n",
    "        'gender_polarization': {\n",
    "            'male_avg_rating': male_avg_rating,\n",
    "            'female_avg_rating': female_avg_rating,\n",
    "            'gender_rating_gap': gender_rating_gap,\n",
    "            'gap_significance': 'significant' if gender_rating_gap and gender_rating_gap > 1.0 else 'minimal'\n",
    "        },\n",
    "        \n",
    "        'theme_contradictions': {\n",
    "            'lovers_use_comparisons_pct': safe_percentage(len(lovers_comparisons), len(lovers)) if len(lovers) > 0 else None,\n",
    "            'haters_use_comparisons_pct': safe_percentage(len(haters_comparisons), len(haters)) if len(haters) > 0 else None,\n",
    "            'comparison_gap': comparison_contradiction_pct\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ polarization_analysis() function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Module 4 on The Witch\n",
    "\n",
    "print(\"üß™ Testing Module 4: Polarization Analysis\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_movie = \"The Witch\"\n",
    "result = polarization_analysis(test_movie)\n",
    "\n",
    "print(f\"\\n‚ö° POLARIZATION ANALYSIS: {test_movie}\")\n",
    "\n",
    "print(f\"\\nüìä Polarization Level: {result['polarization_metrics']['level']}\")\n",
    "print(f\"  Rating Variance: {result['polarization_metrics']['rating_variance']:.2f}\")\n",
    "print(f\"  Rating Std Dev: {result['polarization_metrics']['rating_std_dev']:.2f}\")\n",
    "print(f\"  Middle Ground (4-7): {result['polarization_metrics']['middle_ground_pct']}%\")\n",
    "print(f\"  Lovers (8-10): {result['polarization_metrics']['lovers_pct']}%\")\n",
    "print(f\"  Haters (1-3): {result['polarization_metrics']['haters_pct']}%\")\n",
    "\n",
    "print(f\"\\nüòäüò† Emotion Divergence (Top 5 Most Polarizing):\")\n",
    "for emotion, data in result['emotion_divergence']['top_5_divergent']:\n",
    "    print(f\"\\n  {emotion.capitalize()}:\")\n",
    "    print(f\"    Lovers: {data['lovers_score']:.3f}\")\n",
    "    print(f\"    Haters: {data['haters_score']:.3f}\")\n",
    "    print(f\"    Gap: {data['divergence']:.3f}\")\n",
    "\n",
    "print(f\"\\n‚úçÔ∏è  Writing Style Differences:\")\n",
    "for metric, data in result['writing_style_differences'].items():\n",
    "    if data['difference'] is not None:\n",
    "        print(f\"\\n  {metric.replace('_', ' ').title()}:\")\n",
    "        print(f\"    Lovers: {data['lovers']:.2f}\")\n",
    "        print(f\"    Haters: {data['haters']:.2f}\")\n",
    "        print(f\"    Difference: {data['difference']:+.2f}\")\n",
    "\n",
    "print(f\"\\nüí¨ Engagement Patterns:\")\n",
    "print(f\"  Lovers avg votes: {result['engagement_patterns']['lovers_avg_votes']:.1f}\")\n",
    "print(f\"  Haters avg votes: {result['engagement_patterns']['haters_avg_votes']:.1f}\")\n",
    "print(f\"  Lovers vote polarization: {result['engagement_patterns']['lovers_vote_polarization']:.3f}\")\n",
    "print(f\"  Haters vote polarization: {result['engagement_patterns']['haters_vote_polarization']:.3f}\")\n",
    "\n",
    "print(f\"\\nüìÖ Temporal Polarization:\")\n",
    "print(f\"  Early reviews (Opening/Year 2) avg: {result['temporal_polarization']['early_avg_rating']:.2f}\")\n",
    "print(f\"  Late reviews (Years 4-5/5+) avg: {result['temporal_polarization']['late_avg_rating']:.2f}\")\n",
    "print(f\"  Temporal shift: {result['temporal_polarization']['temporal_shift']:+.2f} ({result['temporal_polarization']['shift_direction']})\")\n",
    "\n",
    "print(f\"\\nüë• Gender Polarization:\")\n",
    "print(f\"  Male avg rating: {result['gender_polarization']['male_avg_rating']:.2f}\")\n",
    "print(f\"  Female avg rating: {result['gender_polarization']['female_avg_rating']:.2f}\")\n",
    "print(f\"  Gender gap: {result['gender_polarization']['gender_rating_gap']:.2f} ({result['gender_polarization']['gap_significance']})\")\n",
    "\n",
    "print(f\"\\nüé¨ Theme Contradictions:\")\n",
    "print(f\"  Lovers using comparisons: {result['theme_contradictions']['lovers_use_comparisons_pct']}%\")\n",
    "print(f\"  Haters using comparisons: {result['theme_contradictions']['haters_use_comparisons_pct']}%\")\n",
    "print(f\"  Comparison usage gap: {result['theme_contradictions']['comparison_gap']:.1f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ Module 4 test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module 5: Marketing Disconnect Analysis\n",
    "**Purpose**: Generate data for Slide 5 - Marketing vs Audience Focus\n",
    "\n",
    "**Approach**: Identify gaps between what marketing emphasized and what audiences discussed\n",
    "\n",
    "**Outputs**:\n",
    "- Comparison film mentions (what audiences compared to)\n",
    "- Expectation indicators (wish statements, disappointment markers)\n",
    "- Theme emphasis gaps (marketing focus vs review focus)\n",
    "- Sentiment by review timing (early disappointment vs later satisfaction)\n",
    "\n",
    "**Note**: This module requires manual input of marketing themes for complete analysis. \n",
    "Without marketing data, it focuses on audience discussion patterns and expectation mismatches."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marketing_disconnect_analysis(movie_name, marketing_themes=None):\n",
    "    \"\"\"\n",
    "    Generate Slide 5: Marketing Disconnect Analysis\n",
    "    \n",
    "    Identifies gaps between audience expectations/discussions and film delivery\n",
    "    \n",
    "    Args:\n",
    "        movie_name: Name of the movie to analyze\n",
    "        marketing_themes: Optional list of themes emphasized in marketing\n",
    "                         Example: ['witch', 'period piece', 'family drama', 'horror']\n",
    "    \n",
    "    Returns: Dictionary with marketing disconnect insights\n",
    "    \"\"\"\n",
    "    reviews = get_movie_reviews(movie_name)\n",
    "    \n",
    "    # Segment by rating for expectation analysis\n",
    "    lovers = reviews[reviews['Rating'] >= 8].copy()\n",
    "    mixed = reviews[(reviews['Rating'] >= 4) & (reviews['Rating'] <= 7)].copy()\n",
    "    haters = reviews[reviews['Rating'] <= 3].copy()\n",
    "    \n",
    "    # 1. COMPARISON FILMS - What did audiences compare this to?\n",
    "    # Extract mentioned movies from reviews\n",
    "    mentioned_movies = []\n",
    "    for movies in reviews['movies_mentioned'].dropna():\n",
    "        if isinstance(movies, str) and movies != '[]':\n",
    "            import ast\n",
    "            try:\n",
    "                movie_list = ast.literal_eval(movies)\n",
    "                mentioned_movies.extend(movie_list)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    from collections import Counter\n",
    "    comparison_films = dict(Counter(mentioned_movies).most_common(15))\n",
    "    \n",
    "    # Filter out self-references (the movie being reviewed)\n",
    "    comparison_films_filtered = {film: count for film, count in comparison_films.items() \n",
    "                                  if movie_name.lower() not in film.lower()}\n",
    "    \n",
    "    # 2. EXPECTATION MISMATCH INDICATORS\n",
    "    # Wish statements by rating group\n",
    "    lovers_with_wish = lovers[lovers['wish_count'] > 0]\n",
    "    haters_with_wish = haters[haters['wish_count'] > 0]\n",
    "    \n",
    "    wish_quotes_lovers = extract_quotes(lovers_with_wish, 'wish_statements', limit=5)\n",
    "    wish_quotes_haters = extract_quotes(haters_with_wish, 'wish_statements', limit=5)\n",
    "    \n",
    "    # Question patterns (confusion/uncertainty)\n",
    "    lovers_with_questions = lovers[lovers['question_count'] > 0]\n",
    "    haters_with_questions = haters[haters['question_count'] > 0]\n",
    "    \n",
    "    # 3. TEMPORAL SENTIMENT ANALYSIS\n",
    "    # Early reviews often reflect marketing-driven expectations\n",
    "    early_reviews = reviews[reviews['review_window'].isin(['Opening Year', 'Year 2'])]\n",
    "    late_reviews = reviews[reviews['review_window'].isin(['Years 4-5', '5+ Years'])]\n",
    "    \n",
    "    early_sentiment = {\n",
    "        'avg_rating': safe_mean(early_reviews['Rating']),\n",
    "        'avg_vader_compound': safe_mean(early_reviews['vader_compound']),\n",
    "        'hate_statement_pct': safe_percentage(len(early_reviews[early_reviews['hate_count'] > 0]), len(early_reviews)),\n",
    "        'wish_statement_pct': safe_percentage(len(early_reviews[early_reviews['wish_count'] > 0]), len(early_reviews))\n",
    "    }\n",
    "    \n",
    "    late_sentiment = {\n",
    "        'avg_rating': safe_mean(late_reviews['Rating']),\n",
    "        'avg_vader_compound': safe_mean(late_reviews['vader_compound']),\n",
    "        'hate_statement_pct': safe_percentage(len(late_reviews[late_reviews['hate_count'] > 0]), len(late_reviews)),\n",
    "        'wish_statement_pct': safe_percentage(len(late_reviews[late_reviews['wish_count'] > 0]), len(late_reviews))\n",
    "    }\n",
    "    \n",
    "    # 4. COMPARISON USAGE BY RATING GROUP\n",
    "    # Do different groups reference comparisons differently?\n",
    "    lovers_comparisons = lovers[lovers['has_comparisons'] == True]\n",
    "    haters_comparisons = haters[haters['has_comparisons'] == True]\n",
    "    \n",
    "    comparison_patterns = {\n",
    "        'lovers_pct': safe_percentage(len(lovers_comparisons), len(lovers)),\n",
    "        'haters_pct': safe_percentage(len(haters_comparisons), len(haters)),\n",
    "        'gap': safe_percentage(len(lovers_comparisons), len(lovers)) - safe_percentage(len(haters_comparisons), len(haters)) if len(lovers) > 0 and len(haters) > 0 else None\n",
    "    }\n",
    "    \n",
    "    # 5. SENTIMENT POLARITY (positive vs negative language)\n",
    "    lovers_vader = safe_mean(lovers['vader_compound'])\n",
    "    haters_vader = safe_mean(haters['vader_compound'])\n",
    "    \n",
    "    sentiment_gap = None\n",
    "    if lovers_vader is not None and haters_vader is not None:\n",
    "        sentiment_gap = lovers_vader - haters_vader\n",
    "    \n",
    "    # 6. MARKETING THEME ANALYSIS (if provided)\n",
    "    marketing_analysis = None\n",
    "    if marketing_themes:\n",
    "        marketing_analysis = {\n",
    "            'provided_themes': marketing_themes,\n",
    "            'note': 'Theme frequency analysis requires text mining implementation',\n",
    "            'status': 'Manual review recommended'\n",
    "        }\n",
    "    else:\n",
    "        marketing_analysis = {\n",
    "            'status': 'No marketing themes provided',\n",
    "            'note': 'Analysis limited to audience discussion patterns'\n",
    "        }\n",
    "    \n",
    "    # 7. DISAPPOINTMENT INDICATORS\n",
    "    # Reviews with high wish_count + low rating = expectation mismatch\n",
    "    disappointed = reviews[(reviews['Rating'] <= 5) & (reviews['wish_count'] > 0)]\n",
    "    disappointment_rate = safe_percentage(len(disappointed), len(reviews))\n",
    "    \n",
    "    disappointed_quotes = extract_quotes(disappointed, 'wish_statements', limit=10)\n",
    "    \n",
    "    return {\n",
    "        'movie': movie_name,\n",
    "        \n",
    "        'comparison_films': {\n",
    "            'all_mentions': comparison_films_filtered,\n",
    "            'top_5': dict(list(comparison_films_filtered.items())[:5]),\n",
    "            'total_unique_films': len(comparison_films_filtered),\n",
    "            'total_mentions': sum(comparison_films_filtered.values())\n",
    "        },\n",
    "        \n",
    "        'expectation_mismatch': {\n",
    "            'lovers_with_wishes': {\n",
    "                'count': len(lovers_with_wish),\n",
    "                'percentage': safe_percentage(len(lovers_with_wish), len(lovers)),\n",
    "                'sample_quotes': wish_quotes_lovers\n",
    "            },\n",
    "            'haters_with_wishes': {\n",
    "                'count': len(haters_with_wish),\n",
    "                'percentage': safe_percentage(len(haters_with_wish), len(haters)),\n",
    "                'sample_quotes': wish_quotes_haters\n",
    "            },\n",
    "            'confusion_indicators': {\n",
    "                'lovers_with_questions_pct': safe_percentage(len(lovers_with_questions), len(lovers)),\n",
    "                'haters_with_questions_pct': safe_percentage(len(haters_with_questions), len(haters))\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        'temporal_sentiment': {\n",
    "            'early_reviews': early_sentiment,\n",
    "            'late_reviews': late_sentiment,\n",
    "            'rating_shift': late_sentiment['avg_rating'] - early_sentiment['avg_rating'] if early_sentiment['avg_rating'] and late_sentiment['avg_rating'] else None,\n",
    "            'interpretation': 'improved' if late_sentiment['avg_rating'] and early_sentiment['avg_rating'] and late_sentiment['avg_rating'] > early_sentiment['avg_rating'] else 'declined' if late_sentiment['avg_rating'] and early_sentiment['avg_rating'] else 'unknown'\n",
    "        },\n",
    "        \n",
    "        'comparison_patterns': comparison_patterns,\n",
    "        \n",
    "        'sentiment_polarity': {\n",
    "            'lovers_vader': lovers_vader,\n",
    "            'haters_vader': haters_vader,\n",
    "            'sentiment_gap': sentiment_gap\n",
    "        },\n",
    "        \n",
    "        'marketing_theme_analysis': marketing_analysis,\n",
    "        \n",
    "        'disappointment_indicators': {\n",
    "            'disappointed_reviewer_pct': disappointment_rate,\n",
    "            'disappointed_count': len(disappointed),\n",
    "            'sample_disappointment_quotes': disappointed_quotes\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ marketing_disconnect_analysis() function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Module 5 on The Witch (without marketing themes)\n",
    "\n",
    "print(\"üß™ Testing Module 5: Marketing Disconnect Analysis\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_movie = \"The Witch\"\n",
    "result = marketing_disconnect_analysis(test_movie)\n",
    "\n",
    "print(f\"\\nüìä MARKETING DISCONNECT ANALYSIS: {test_movie}\")\n",
    "print(f\"\\nNote: Analysis performed WITHOUT marketing theme data\")\n",
    "print(f\"      Focus is on audience discussion patterns and expectation gaps\\n\")\n",
    "\n",
    "print(f\"üé¨ Comparison Films (What Audiences Referenced):\")\n",
    "print(f\"  Total unique films mentioned: {result['comparison_films']['total_unique_films']}\")\n",
    "print(f\"  Total mentions: {result['comparison_films']['total_mentions']}\")\n",
    "print(f\"\\n  Top 5 Most Compared Films:\")\n",
    "for i, (film, count) in enumerate(list(result['comparison_films']['top_5'].items())[:5], 1):\n",
    "    print(f\"    {i}. {film:40} ({count:3} mentions)\")\n",
    "\n",
    "print(f\"\\n‚ùì Expectation Mismatch Indicators:\")\n",
    "print(f\"\\n  Lovers (8-10) expressing wishes:\")\n",
    "print(f\"    Count: {result['expectation_mismatch']['lovers_with_wishes']['count']} ({result['expectation_mismatch']['lovers_with_wishes']['percentage']}%)\")\n",
    "\n",
    "if result['expectation_mismatch']['lovers_with_wishes']['sample_quotes']:\n",
    "    print(f\"\\n    Sample wish from lover:\")\n",
    "    quote = result['expectation_mismatch']['lovers_with_wishes']['sample_quotes'][0]\n",
    "    content = quote['content'][:150] + '...' if len(quote['content']) > 150 else quote['content']\n",
    "    print(f\"      [{quote['review_id']}] Rating: {quote['rating']}/10\")\n",
    "    print(f\"      {content}\")\n",
    "\n",
    "print(f\"\\n  Haters (1-3) expressing wishes:\")\n",
    "print(f\"    Count: {result['expectation_mismatch']['haters_with_wishes']['count']} ({result['expectation_mismatch']['haters_with_wishes']['percentage']}%)\")\n",
    "\n",
    "if result['expectation_mismatch']['haters_with_wishes']['sample_quotes']:\n",
    "    print(f\"\\n    Sample wish from hater:\")\n",
    "    quote = result['expectation_mismatch']['haters_with_wishes']['sample_quotes'][0]\n",
    "    content = quote['content'][:150] + '...' if len(quote['content']) > 150 else quote['content']\n",
    "    print(f\"      [{quote['review_id']}] Rating: {quote['rating']}/10\")\n",
    "    print(f\"      {content}\")\n",
    "\n",
    "print(f\"\\n  Confusion indicators (question usage):\")\n",
    "print(f\"    Lovers with questions: {result['expectation_mismatch']['confusion_indicators']['lovers_with_questions_pct']}%\")\n",
    "print(f\"    Haters with questions: {result['expectation_mismatch']['confusion_indicators']['haters_with_questions_pct']}%\")\n",
    "\n",
    "print(f\"\\nüìÖ Temporal Sentiment Shift:\")\n",
    "print(f\"  Early reviews (Opening/Year 2):\")\n",
    "print(f\"    Avg rating: {result['temporal_sentiment']['early_reviews']['avg_rating']:.2f}\")\n",
    "print(f\"    VADER sentiment: {result['temporal_sentiment']['early_reviews']['avg_vader_compound']:.3f}\")\n",
    "print(f\"    Hate statements: {result['temporal_sentiment']['early_reviews']['hate_statement_pct']}%\")\n",
    "print(f\"    Wish statements: {result['temporal_sentiment']['early_reviews']['wish_statement_pct']}%\")\n",
    "\n",
    "print(f\"\\n  Late reviews (Years 4-5/5+):\")\n",
    "print(f\"    Avg rating: {result['temporal_sentiment']['late_reviews']['avg_rating']:.2f}\")\n",
    "print(f\"    VADER sentiment: {result['temporal_sentiment']['late_reviews']['avg_vader_compound']:.3f}\")\n",
    "print(f\"    Hate statements: {result['temporal_sentiment']['late_reviews']['hate_statement_pct']}%\")\n",
    "print(f\"    Wish statements: {result['temporal_sentiment']['late_reviews']['wish_statement_pct']}%\")\n",
    "\n",
    "print(f\"\\n  Rating shift: {result['temporal_sentiment']['rating_shift']:+.2f} ({result['temporal_sentiment']['interpretation']})\")\n",
    "\n",
    "print(f\"\\nüîç Comparison Usage Patterns:\")\n",
    "print(f\"  Lovers using comparisons: {result['comparison_patterns']['lovers_pct']}%\")\n",
    "print(f\"  Haters using comparisons: {result['comparison_patterns']['haters_pct']}%\")\n",
    "print(f\"  Gap: {result['comparison_patterns']['gap']:+.1f} percentage points\")\n",
    "\n",
    "print(f\"\\nüòäüò† Sentiment Polarity (VADER):\")\n",
    "print(f\"  Lovers: {result['sentiment_polarity']['lovers_vader']:.3f}\")\n",
    "print(f\"  Haters: {result['sentiment_polarity']['haters_vader']:.3f}\")\n",
    "print(f\"  Gap: {result['sentiment_polarity']['sentiment_gap']:.3f}\")\n",
    "\n",
    "print(f\"\\nüíî Disappointment Indicators:\")\n",
    "print(f\"  Disappointed reviewers (low rating + wishes): {result['disappointment_indicators']['disappointed_count']} ({result['disappointment_indicators']['disappointed_reviewer_pct']}%)\")\n",
    "\n",
    "if result['disappointment_indicators']['sample_disappointment_quotes']:\n",
    "    print(f\"\\n  Top 3 Disappointment Quotes (by engagement):\")\n",
    "    for i, quote in enumerate(result['disappointment_indicators']['sample_disappointment_quotes'][:3], 1):\n",
    "        print(f\"\\n    {i}. [{quote['review_id']}] Rating: {quote['rating']}/10, Votes: {quote['engagement']}\")\n",
    "        content = quote['content'][:150] + '...' if len(quote['content']) > 150 else quote['content']\n",
    "        print(f\"       {content}\")\n",
    "\n",
    "print(f\"\\nüì¢ Marketing Theme Analysis:\")\n",
    "print(f\"  Status: {result['marketing_theme_analysis']['status']}\")\n",
    "print(f\"  Note: {result['marketing_theme_analysis']['note']}\")\n",
    "\n",
    "print(\"\\n‚úÖ Module 5 test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Module 5 WITH marketing themes (optional - demonstrates full functionality)\n",
    "\n",
    "print(\"üß™ Testing Module 5: Marketing Disconnect Analysis WITH Themes\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Example marketing themes for The Witch\n",
    "# (These would come from actual marketing materials)\n",
    "marketing_themes_example = [\n",
    "    'witch',\n",
    "    'period piece',\n",
    "    'new england',\n",
    "    '1630s',\n",
    "    'family',\n",
    "    'horror',\n",
    "    'supernatural',\n",
    "    'folktale'\n",
    "]\n",
    "\n",
    "test_movie = \"The Witch\"\n",
    "result = marketing_disconnect_analysis(test_movie, marketing_themes=marketing_themes_example)\n",
    "\n",
    "print(f\"\\nüìä MARKETING DISCONNECT ANALYSIS: {test_movie}\")\n",
    "print(f\"\\nNote: Analysis performed WITH example marketing themes\\n\")\n",
    "\n",
    "print(f\"üì¢ Marketing Theme Analysis:\")\n",
    "print(f\"  Status: {result['marketing_theme_analysis']['status']}\")\n",
    "print(f\"  Provided themes: {', '.join(result['marketing_theme_analysis']['provided_themes'])}\")\n",
    "print(f\"  Note: {result['marketing_theme_analysis']['note']}\")\n",
    "\n",
    "print(\"\\n‚úÖ Full Module 5 test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 6 Risk Factors Analysis"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_contextual_quotes(df_filtered, search_terms=None, limit=5, context_sentences=2):\n",
    "    \"\"\"\n",
    "    Extract quotes from full review text with surrounding context\n",
    "    \n",
    "    Args:\n",
    "        df_filtered: Pre-filtered DataFrame (already segmented by risk criteria)\n",
    "        search_terms: List of keywords to search for (optional - if None, just returns top reviews)\n",
    "        limit: Maximum number of quotes to return\n",
    "        context_sentences: Number of sentences before/after to include for context\n",
    "    \n",
    "    Returns: List of dicts with review_id, contextual quote, engagement\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    quotes = []\n",
    "    \n",
    "    # Sort by engagement to get most impactful reviews\n",
    "    candidates = df_filtered.nlargest(limit * 3, 'total_votes') if len(df_filtered) > limit * 3 else df_filtered.sort_values('total_votes', ascending=False)\n",
    "    \n",
    "    for _, row in candidates.iterrows():\n",
    "        if len(quotes) >= limit:\n",
    "            break\n",
    "            \n",
    "        text = row['Review_Text']\n",
    "        if pd.isna(text) or len(text) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Split into sentences (handle multiple punctuation patterns)\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "        sentences = [s.strip() for s in sentences if len(s.strip()) > 10]  # Filter tiny fragments\n",
    "        \n",
    "        if not sentences:\n",
    "            continue\n",
    "        \n",
    "        # If search terms provided, find relevant sentences\n",
    "        if search_terms:\n",
    "            found_match = False\n",
    "            for i, sentence in enumerate(sentences):\n",
    "                sentence_lower = sentence.lower()\n",
    "                \n",
    "                # Check if any search term appears in this sentence\n",
    "                if any(term.lower() in sentence_lower for term in search_terms):\n",
    "                    # Get context window\n",
    "                    start_idx = max(0, i - context_sentences)\n",
    "                    end_idx = min(len(sentences), i + context_sentences + 1)\n",
    "                    \n",
    "                    context = ' '.join(sentences[start_idx:end_idx])\n",
    "                    \n",
    "                    # Add ellipsis if we're not at the beginning/end\n",
    "                    if start_idx > 0:\n",
    "                        context = '...' + context\n",
    "                    if end_idx < len(sentences):\n",
    "                        context = context + '...'\n",
    "                    \n",
    "                    quotes.append({\n",
    "                        'review_id': row['Review_ID'],\n",
    "                        'reviewer': row['Reviewer'],\n",
    "                        'rating': int(row['Rating']),\n",
    "                        'review_title': row['Review_Title'] if pd.notna(row['Review_Title']) else '',\n",
    "                        'quote': context,\n",
    "                        'engagement': int(row['total_votes']) if pd.notna(row['total_votes']) else 0,\n",
    "                        'matched_term': [t for t in search_terms if t.lower() in sentence_lower][0]  # Which term matched\n",
    "                    })\n",
    "                    \n",
    "                    found_match = True\n",
    "                    break  # Only one quote per review\n",
    "            \n",
    "            if found_match:\n",
    "                continue\n",
    "        \n",
    "        # If no search terms or no match found, use opening of review\n",
    "        if not search_terms or not found_match:\n",
    "            # Take first 2-3 sentences as representative quote\n",
    "            opening = ' '.join(sentences[:3])\n",
    "            if len(sentences) > 3:\n",
    "                opening += '...'\n",
    "            \n",
    "            quotes.append({\n",
    "                'review_id': row['Review_ID'],\n",
    "                'reviewer': row['Reviewer'],\n",
    "                'rating': int(row['Rating']),\n",
    "                'review_title': row['Review_Title'] if pd.notna(row['Review_Title']) else '',\n",
    "                'quote': opening,\n",
    "                'engagement': int(row['total_votes']) if pd.notna(row['total_votes']) else 0,\n",
    "                'matched_term': None\n",
    "            })\n",
    "    \n",
    "    return quotes[:limit]\n",
    "\n",
    "print(\"‚úÖ extract_contextual_quotes() helper function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_factors_analysis(movie_name):\n",
    "    \"\"\"\n",
    "    Generate Slide 6: Risk Factors Analysis\n",
    "    \n",
    "    Identifies potential marketing/audience risks based on review patterns\n",
    "    Uses contextual quote extraction for better insight\n",
    "    \n",
    "    Returns: Dictionary with risk assessments and mitigation recommendations\n",
    "    \"\"\"\n",
    "    reviews = get_movie_reviews(movie_name)\n",
    "    \n",
    "    if len(reviews) == 0:\n",
    "        return {\n",
    "            'movie': movie_name,\n",
    "            'message': 'No reviews available for analysis'\n",
    "        }\n",
    "    \n",
    "    # Segment by rating\n",
    "    lovers = reviews[reviews['Rating'] >= 8].copy()\n",
    "    mixed = reviews[(reviews['Rating'] >= 4) & (reviews['Rating'] <= 7)].copy()\n",
    "    haters = reviews[reviews['Rating'] <= 3].copy()\n",
    "    \n",
    "    # Initialize risk flags\n",
    "    risks = []\n",
    "    \n",
    "    # ========================================\n",
    "    # RISK 1: INTENSITY WARNING\n",
    "    # High fear + negative emotions = \"too intense\" for casual audiences\n",
    "    # ========================================\n",
    "    \n",
    "    avg_fear = safe_mean(reviews['emotion_fear'])\n",
    "    avg_disgust = safe_mean(reviews['emotion_disgust'])\n",
    "    hate_review_pct = safe_percentage(len(haters), len(reviews))\n",
    "    \n",
    "    intensity_score = 0\n",
    "    if avg_fear and avg_fear > 0.10:  # Top quartile fear\n",
    "        intensity_score += 1\n",
    "    if avg_disgust and avg_disgust > 0.08:  # Top quartile disgust\n",
    "        intensity_score += 1\n",
    "    if hate_review_pct and hate_review_pct > 20:  # High hate rate\n",
    "        intensity_score += 1\n",
    "    \n",
    "    # Extract quotes mentioning intensity/fear/disturbing elements\n",
    "    intensity_quotes = extract_contextual_quotes(\n",
    "        haters,\n",
    "        search_terms=['disturbing', 'scary', 'intense', 'graphic', 'dark', 'uncomfortable', 'creepy', 'frightening'],\n",
    "        limit=3,\n",
    "        context_sentences=1\n",
    "    )\n",
    "    \n",
    "    intensity_risk = {\n",
    "        'risk_level': 'HIGH' if intensity_score >= 2 else 'MODERATE' if intensity_score == 1 else 'LOW',\n",
    "        'avg_fear': avg_fear,\n",
    "        'avg_disgust': avg_disgust,\n",
    "        'hate_review_pct': hate_review_pct,\n",
    "        'intensity_score': intensity_score,\n",
    "        'interpretation': None,\n",
    "        'mitigation': None,\n",
    "        'sample_quotes': intensity_quotes\n",
    "    }\n",
    "    \n",
    "    if intensity_score >= 2:\n",
    "        intensity_risk['interpretation'] = \"Film likely too intense for mainstream horror audiences. High fear/disgust + significant hate rate suggests casual viewers will be turned off.\"\n",
    "        intensity_risk['mitigation'] = \"Market to horror enthusiasts, not casual fans. Use content warnings. Emphasize 'elevated horror' or 'arthouse' positioning. Target A24/Neon audience, not mainstream theaters.\"\n",
    "        risks.append('INTENSITY_WARNING')\n",
    "    elif intensity_score == 1:\n",
    "        intensity_risk['interpretation'] = \"Moderate intensity that may polarize. Some audiences will find it too much.\"\n",
    "        intensity_risk['mitigation'] = \"Clear genre positioning in marketing. Avoid misleading trailers that suggest lighter tone.\"\n",
    "    \n",
    "    # ========================================\n",
    "    # RISK 2: COMPLEXITY BARRIER\n",
    "    # High reading complexity + negative reviews = film too \"difficult\"\n",
    "    # ========================================\n",
    "    \n",
    "    # Compare haters' vs lovers' writing complexity\n",
    "    haters_reading_ease = safe_mean(haters['flesch_reading_ease'])\n",
    "    lovers_reading_ease = safe_mean(lovers['flesch_reading_ease'])\n",
    "    \n",
    "    # If haters write SIMPLER reviews than lovers, suggests complexity barrier\n",
    "    complexity_gap = None\n",
    "    if haters_reading_ease and lovers_reading_ease:\n",
    "        complexity_gap = haters_reading_ease - lovers_reading_ease\n",
    "    \n",
    "    # Extract quotes about pacing/confusion/arthouse criticism\n",
    "    complexity_quotes = extract_contextual_quotes(\n",
    "        haters,\n",
    "        search_terms=['slow', 'boring', 'nothing happens', 'pretentious', 'confusing', 'pointless', 'dragged', 'waste of time', \"doesn't make sense\"],\n",
    "        limit=3,\n",
    "        context_sentences=1\n",
    "    )\n",
    "    \n",
    "    complexity_risk = {\n",
    "        'risk_level': 'HIGH' if complexity_gap and complexity_gap > 10 and hate_review_pct and hate_review_pct > 15 else 'MODERATE' if complexity_gap and complexity_gap > 5 else 'LOW',\n",
    "        'haters_reading_ease': haters_reading_ease,\n",
    "        'lovers_reading_ease': lovers_reading_ease,\n",
    "        'complexity_gap': complexity_gap,\n",
    "        'interpretation': None,\n",
    "        'mitigation': None,\n",
    "        'sample_quotes': complexity_quotes\n",
    "    }\n",
    "    \n",
    "    if complexity_gap and complexity_gap > 10 and hate_review_pct and hate_review_pct > 15:\n",
    "        complexity_risk['interpretation'] = \"Significant complexity barrier detected. Haters write much simpler reviews than lovers, suggesting film is 'too arthouse' for general audiences.\"\n",
    "        complexity_risk['mitigation'] = \"Position as arthouse/festival film. Target film critics and serious horror fans. Consider platform release (streaming/VOD) rather than wide theatrical. Emphasize auteur credentials.\"\n",
    "        risks.append('COMPLEXITY_BARRIER')\n",
    "    elif complexity_gap and complexity_gap > 5:\n",
    "        complexity_risk['interpretation'] = \"Moderate complexity barrier. Film may be too slow/cerebral for some viewers.\"\n",
    "        complexity_risk['mitigation'] = \"Marketing should prepare audiences for 'slow burn' pacing. Use critic quotes emphasizing atmosphere over action.\"\n",
    "    \n",
    "    # ========================================\n",
    "    # RISK 3: EARLY NEGATIVE BUZZ\n",
    "    # Opening year reviews with low ratings + high engagement = bad word of mouth\n",
    "    # ========================================\n",
    "    \n",
    "    early_reviews = reviews[reviews['review_window'].isin(['Opening Year', 'Year 2'])]\n",
    "    early_negative = early_reviews[(early_reviews['Rating'] <= 5) & (early_reviews['total_votes'] > 20)]\n",
    "    \n",
    "    early_negative_pct = safe_percentage(len(early_negative), len(early_reviews)) if len(early_reviews) > 0 else None\n",
    "    early_avg_rating = safe_mean(early_reviews['Rating'])\n",
    "    \n",
    "    # Extract most engaged early negative reviews\n",
    "    early_buzz_quotes = extract_contextual_quotes(\n",
    "        early_negative,\n",
    "        search_terms=['disappointed', 'misled', 'expected', 'overhyped', 'waste', 'boring', 'misleading'],\n",
    "        limit=3,\n",
    "        context_sentences=2\n",
    "    )\n",
    "    \n",
    "    early_buzz_risk = {\n",
    "        'risk_level': 'HIGH' if early_negative_pct and early_negative_pct > 30 else 'MODERATE' if early_negative_pct and early_negative_pct > 15 else 'LOW',\n",
    "        'early_negative_count': len(early_negative),\n",
    "        'early_negative_pct': early_negative_pct,\n",
    "        'early_avg_rating': early_avg_rating,\n",
    "        'total_early_reviews': len(early_reviews),\n",
    "        'interpretation': None,\n",
    "        'mitigation': None,\n",
    "        'sample_quotes': early_buzz_quotes\n",
    "    }\n",
    "    \n",
    "    if early_negative_pct and early_negative_pct > 30:\n",
    "        early_buzz_risk['interpretation'] = \"High early negative buzz detected. Opening audiences were disappointed and vocal about it.\"\n",
    "        early_buzz_risk['mitigation'] = \"Avoid wide theatrical release. Consider festival circuit first to build critical support. Use critic screenings to generate positive reviews before public release. Platform release strategy.\"\n",
    "        risks.append('EARLY_NEGATIVE_BUZZ')\n",
    "    elif early_negative_pct and early_negative_pct > 15:\n",
    "        early_buzz_risk['interpretation'] = \"Moderate early negative buzz. Some opening audiences felt misled.\"\n",
    "        early_buzz_risk['mitigation'] = \"Ensure marketing accurately represents film tone. Screen for target audience first, not general public.\"\n",
    "    \n",
    "    # ========================================\n",
    "    # RISK 4: PACING ISSUES\n",
    "    # High boredom indicators from haters\n",
    "    # ========================================\n",
    "    \n",
    "    haters_with_wishes = haters[haters['wish_count'] > 0]\n",
    "    boredom_pct = safe_percentage(len(haters_with_wishes), len(haters)) if len(haters) > 0 else None\n",
    "    \n",
    "    # Extract pacing complaints with context\n",
    "    pacing_quotes = extract_contextual_quotes(\n",
    "        haters,\n",
    "        search_terms=['slow', 'boring', 'nothing happens', 'dragged', 'pacing', 'tedious', 'dull', 'uneventful', 'wished', 'wanted more'],\n",
    "        limit=3,\n",
    "        context_sentences=2\n",
    "    )\n",
    "    \n",
    "    pacing_risk = {\n",
    "        'risk_level': 'HIGH' if boredom_pct and boredom_pct > 15 and hate_review_pct and hate_review_pct > 20 else 'MODERATE' if boredom_pct and boredom_pct > 10 else 'LOW',\n",
    "        'haters_with_wishes_pct': boredom_pct,\n",
    "        'interpretation': None,\n",
    "        'mitigation': None,\n",
    "        'sample_quotes': pacing_quotes\n",
    "    }\n",
    "    \n",
    "    if boredom_pct and boredom_pct > 15 and hate_review_pct and hate_review_pct > 20:\n",
    "        pacing_risk['interpretation'] = \"Pacing issues detected. High percentage of haters expressing wishes (what they wanted but didn't get), suggesting film is too slow or doesn't deliver expected payoff.\"\n",
    "        pacing_risk['mitigation'] = \"Marketing must emphasize 'slow burn' nature upfront. Don't promise action/scares that aren't delivered. Target patient, atmosphere-focused horror fans. Consider re-edit if in post-production.\"\n",
    "        risks.append('PACING_ISSUES')\n",
    "    elif boredom_pct and boredom_pct > 10:\n",
    "        pacing_risk['interpretation'] = \"Moderate pacing concerns. Some viewers wanted more action/payoff.\"\n",
    "        pacing_risk['mitigation'] = \"Set expectations clearly in marketing. Use critic quotes about 'atmospheric' and 'meditative' qualities.\"\n",
    "    \n",
    "    # ========================================\n",
    "    # RISK 5: EXPECTATION MISMATCH\n",
    "    # Disappointed + comparisons = marketing misled audiences\n",
    "    # ========================================\n",
    "    \n",
    "    disappointed = reviews[(reviews['Rating'] <= 5) & (reviews['wish_count'] > 0) & (reviews['has_comparisons'] == True)]\n",
    "    disappointment_rate = safe_percentage(len(disappointed), len(reviews))\n",
    "    \n",
    "    # Extract expectation mismatch quotes\n",
    "    expectation_quotes = extract_contextual_quotes(\n",
    "        disappointed,\n",
    "        search_terms=['expected', 'disappointed', 'thought it would', 'hoped for', 'nothing like', 'misleading', 'overhyped', 'not what I', 'wished'],\n",
    "        limit=3,\n",
    "        context_sentences=2\n",
    "    )\n",
    "    \n",
    "    # What films did disappointed viewers compare to?\n",
    "    disappointed_comparisons = []\n",
    "    for movies in disappointed['movies_mentioned'].dropna():\n",
    "        if isinstance(movies, str) and movies != '[]':\n",
    "            import ast\n",
    "            try:\n",
    "                movie_list = ast.literal_eval(movies)\n",
    "                disappointed_comparisons.extend(movie_list)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    from collections import Counter\n",
    "    top_disappointed_comparisons = dict(Counter(disappointed_comparisons).most_common(5))\n",
    "    \n",
    "    expectation_risk = {\n",
    "        'risk_level': 'HIGH' if disappointment_rate and disappointment_rate > 10 else 'MODERATE' if disappointment_rate and disappointment_rate > 5 else 'LOW',\n",
    "        'disappointment_rate': disappointment_rate,\n",
    "        'disappointed_count': len(disappointed),\n",
    "        'top_comparison_films': top_disappointed_comparisons,\n",
    "        'interpretation': None,\n",
    "        'mitigation': None,\n",
    "        'sample_quotes': expectation_quotes\n",
    "    }\n",
    "    \n",
    "    if disappointment_rate and disappointment_rate > 10:\n",
    "        expectation_risk['interpretation'] = \"High expectation mismatch. Significant portion of audience felt misled - they had wishes unfulfilled and compared to films with different tone/style.\"\n",
    "        expectation_risk['mitigation'] = \"Audit marketing materials carefully. Ensure trailers/posters accurately represent film. Look at comparison films - are we being compared to wrong genre/style? Reposition marketing if needed.\"\n",
    "        risks.append('EXPECTATION_MISMATCH')\n",
    "    elif disappointment_rate and disappointment_rate > 5:\n",
    "        expectation_risk['interpretation'] = \"Moderate expectation issues. Some audiences felt the film didn't match their expectations.\"\n",
    "        expectation_risk['mitigation'] = \"Review marketing positioning. Ensure genre signals are clear and accurate.\"\n",
    "    \n",
    "    # ========================================\n",
    "    # RISK 6: GENDER POLARIZATION\n",
    "    # Significant gender rating gap = marketing may alienate one gender\n",
    "    # ========================================\n",
    "    \n",
    "    male_reviews = reviews[reviews['username_gender_hint'] == 'male']\n",
    "    female_reviews = reviews[reviews['username_gender_hint'] == 'female']\n",
    "    \n",
    "    male_avg_rating = safe_mean(male_reviews['Rating'])\n",
    "    female_avg_rating = safe_mean(female_reviews['Rating'])\n",
    "    \n",
    "    gender_gap = None\n",
    "    if male_avg_rating and female_avg_rating:\n",
    "        gender_gap = abs(male_avg_rating - female_avg_rating)\n",
    "    \n",
    "    # Determine which gender rates higher\n",
    "    gender_preference = None\n",
    "    if male_avg_rating and female_avg_rating:\n",
    "        if male_avg_rating > female_avg_rating:\n",
    "            gender_preference = 'male'\n",
    "        elif female_avg_rating > male_avg_rating:\n",
    "            gender_preference = 'female'\n",
    "        else:\n",
    "            gender_preference = 'neutral'\n",
    "    \n",
    "    # Extract quotes from lower-rating gender\n",
    "    lower_rating_gender = 'female' if gender_preference == 'male' else 'male'\n",
    "    gender_segment = female_reviews if gender_preference == 'male' else male_reviews\n",
    "    gender_haters = gender_segment[gender_segment['Rating'] <= 5]\n",
    "    \n",
    "    gender_quotes = extract_contextual_quotes(\n",
    "        gender_haters,\n",
    "        search_terms=None,  # Just get top engaged reviews from this segment\n",
    "        limit=3,\n",
    "        context_sentences=2\n",
    "    )\n",
    "    \n",
    "    gender_risk = {\n",
    "        'risk_level': 'HIGH' if gender_gap and gender_gap > 1.5 else 'MODERATE' if gender_gap and gender_gap > 1.0 else 'LOW',\n",
    "        'gender_gap': gender_gap,\n",
    "        'male_avg_rating': male_avg_rating,\n",
    "        'female_avg_rating': female_avg_rating,\n",
    "        'gender_preference': gender_preference,\n",
    "        'male_count': len(male_reviews),\n",
    "        'female_count': len(female_reviews),\n",
    "        'interpretation': None,\n",
    "        'mitigation': None,\n",
    "        'sample_quotes': gender_quotes\n",
    "    }\n",
    "    \n",
    "    if gender_gap and gender_gap > 1.5:\n",
    "        gender_risk['interpretation'] = f\"Significant gender polarization detected. {gender_preference.capitalize()} reviewers rate {gender_gap:.2f} points higher. Film may alienate {lower_rating_gender} audiences.\"\n",
    "        gender_risk['mitigation'] = f\"Marketing should acknowledge gender appeal skew. Target {gender_preference} audiences primarily. If trying to broaden appeal, understand WHY {lower_rating_gender} audiences dislike it and address in positioning.\"\n",
    "        risks.append('GENDER_POLARIZATION')\n",
    "    elif gender_gap and gender_gap > 1.0:\n",
    "        gender_risk['interpretation'] = f\"Moderate gender gap. {gender_preference.capitalize()} audiences prefer it somewhat.\"\n",
    "        gender_risk['mitigation'] = \"Consider gender-specific marketing angles for different platforms.\"\n",
    "    \n",
    "    # ========================================\n",
    "    # OVERALL RISK ASSESSMENT\n",
    "    # ========================================\n",
    "    \n",
    "    total_risk_score = sum([\n",
    "        1 if intensity_risk['risk_level'] == 'HIGH' else 0.5 if intensity_risk['risk_level'] == 'MODERATE' else 0,\n",
    "        1 if complexity_risk['risk_level'] == 'HIGH' else 0.5 if complexity_risk['risk_level'] == 'MODERATE' else 0,\n",
    "        1 if early_buzz_risk['risk_level'] == 'HIGH' else 0.5 if early_buzz_risk['risk_level'] == 'MODERATE' else 0,\n",
    "        1 if pacing_risk['risk_level'] == 'HIGH' else 0.5 if pacing_risk['risk_level'] == 'MODERATE' else 0,\n",
    "        1 if expectation_risk['risk_level'] == 'HIGH' else 0.5 if expectation_risk['risk_level'] == 'MODERATE' else 0,\n",
    "        1 if gender_risk['risk_level'] == 'HIGH' else 0.5 if gender_risk['risk_level'] == 'MODERATE' else 0\n",
    "    ])\n",
    "    \n",
    "    overall_risk = 'HIGH' if total_risk_score >= 3 else 'MODERATE' if total_risk_score >= 1.5 else 'LOW'\n",
    "    \n",
    "    return {\n",
    "        'movie': movie_name,\n",
    "        'overall_risk_assessment': {\n",
    "            'risk_level': overall_risk,\n",
    "            'risk_score': total_risk_score,\n",
    "            'high_risks': [r for r in risks],\n",
    "            'risk_count': len(risks)\n",
    "        },\n",
    "        'intensity_risk': intensity_risk,\n",
    "        'complexity_risk': complexity_risk,\n",
    "        'early_buzz_risk': early_buzz_risk,\n",
    "        'pacing_risk': pacing_risk,\n",
    "        'expectation_risk': expectation_risk,\n",
    "        'gender_risk': gender_risk\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ risk_factors_analysis() function defined (with contextual quotes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Module 6 (Rewritten) on The Witch\n",
    "\n",
    "print(\"üß™ Testing Module 6: Risk Factors Analysis (REWRITTEN - Contextual Quotes)\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_movie = \"The Witch\"\n",
    "result = risk_factors_analysis(test_movie)\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  RISK FACTORS ANALYSIS: {test_movie}\")\n",
    "\n",
    "# Overall Assessment\n",
    "print(f\"\\nüìä OVERALL RISK ASSESSMENT:\")\n",
    "print(f\"  Risk Level: {result['overall_risk_assessment']['risk_level']}\")\n",
    "print(f\"  Risk Score: {result['overall_risk_assessment']['risk_score']:.1f}/6.0\")\n",
    "print(f\"  High Risks Identified: {result['overall_risk_assessment']['risk_count']}\")\n",
    "\n",
    "if result['overall_risk_assessment']['high_risks']:\n",
    "    print(f\"\\n  ‚ö†Ô∏è  Critical Risk Flags:\")\n",
    "    for i, risk in enumerate(result['overall_risk_assessment']['high_risks'], 1):\n",
    "        print(f\"    {i}. {risk.replace('_', ' ').title()}\")\n",
    "\n",
    "# Detailed Risk Breakdown with CONTEXTUAL QUOTES\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"\\n1Ô∏è‚É£  INTENSITY RISK: {result['intensity_risk']['risk_level']}\")\n",
    "print(f\"  Avg Fear Score: {result['intensity_risk']['avg_fear']:.3f}\")\n",
    "print(f\"  Avg Disgust Score: {result['intensity_risk']['avg_disgust']:.3f}\")\n",
    "print(f\"  Hate Review %: {result['intensity_risk']['hate_review_pct']}%\")\n",
    "if result['intensity_risk']['interpretation']:\n",
    "    print(f\"\\n  üí° Interpretation:\")\n",
    "    print(f\"     {result['intensity_risk']['interpretation']}\")\n",
    "    print(f\"\\n  üõ°Ô∏è  Mitigation:\")\n",
    "    print(f\"     {result['intensity_risk']['mitigation']}\")\n",
    "\n",
    "if result['intensity_risk']['sample_quotes']:\n",
    "    print(f\"\\n  üìù Sample Intensity Complaints (Contextual):\")\n",
    "    for i, quote in enumerate(result['intensity_risk']['sample_quotes'], 1):\n",
    "        print(f\"\\n    {i}. [{quote['review_id']}] {quote['reviewer']} - {quote['rating']}/10 ({quote['engagement']} votes)\")\n",
    "        if quote['review_title']:\n",
    "            print(f\"       Title: \\\"{quote['review_title']}\\\"\")\n",
    "        if quote.get('matched_term'):\n",
    "            print(f\"       Matched: '{quote['matched_term']}'\")\n",
    "        print(f\"       \\\"{quote['quote']}\\\"\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"\\n2Ô∏è‚É£  COMPLEXITY BARRIER: {result['complexity_risk']['risk_level']}\")\n",
    "print(f\"  Lovers Reading Ease: {result['complexity_risk']['lovers_reading_ease']:.1f}\")\n",
    "print(f\"  Haters Reading Ease: {result['complexity_risk']['haters_reading_ease']:.1f}\")\n",
    "if result['complexity_risk']['complexity_gap']:\n",
    "    print(f\"  Gap: {result['complexity_risk']['complexity_gap']:+.1f} (haters write simpler)\")\n",
    "if result['complexity_risk']['interpretation']:\n",
    "    print(f\"\\n  üí° Interpretation:\")\n",
    "    print(f\"     {result['complexity_risk']['interpretation']}\")\n",
    "    print(f\"\\n  üõ°Ô∏è  Mitigation:\")\n",
    "    print(f\"     {result['complexity_risk']['mitigation']}\")\n",
    "\n",
    "if result['complexity_risk']['sample_quotes']:\n",
    "    print(f\"\\n  üìù Sample Complexity Complaints (Contextual):\")\n",
    "    for i, quote in enumerate(result['complexity_risk']['sample_quotes'], 1):\n",
    "        print(f\"\\n    {i}. [{quote['review_id']}] {quote['reviewer']} - {quote['rating']}/10 ({quote['engagement']} votes)\")\n",
    "        if quote['review_title']:\n",
    "            print(f\"       Title: \\\"{quote['review_title']}\\\"\")\n",
    "        if quote.get('matched_term'):\n",
    "            print(f\"       Matched: '{quote['matched_term']}'\")\n",
    "        print(f\"       \\\"{quote['quote']}\\\"\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"\\n3Ô∏è‚É£  EARLY NEGATIVE BUZZ: {result['early_buzz_risk']['risk_level']}\")\n",
    "print(f\"  Early Reviews: {result['early_buzz_risk']['total_early_reviews']}\")\n",
    "print(f\"  Early Negative (high engagement): {result['early_buzz_risk']['early_negative_count']}\")\n",
    "if result['early_buzz_risk']['early_negative_pct']:\n",
    "    print(f\"  Early Negative %: {result['early_buzz_risk']['early_negative_pct']}%\")\n",
    "if result['early_buzz_risk']['early_avg_rating']:\n",
    "    print(f\"  Early Avg Rating: {result['early_buzz_risk']['early_avg_rating']:.2f}\")\n",
    "if result['early_buzz_risk']['interpretation']:\n",
    "    print(f\"\\n  üí° Interpretation:\")\n",
    "    print(f\"     {result['early_buzz_risk']['interpretation']}\")\n",
    "    print(f\"\\n  üõ°Ô∏è  Mitigation:\")\n",
    "    print(f\"     {result['early_buzz_risk']['mitigation']}\")\n",
    "\n",
    "if result['early_buzz_risk']['sample_quotes']:\n",
    "    print(f\"\\n  üìù Sample Early Negative Complaints (Contextual):\")\n",
    "    for i, quote in enumerate(result['early_buzz_risk']['sample_quotes'], 1):\n",
    "        print(f\"\\n    {i}. [{quote['review_id']}] {quote['reviewer']} - {quote['rating']}/10 ({quote['engagement']} votes)\")\n",
    "        if quote['review_title']:\n",
    "            print(f\"       Title: \\\"{quote['review_title']}\\\"\")\n",
    "        if quote.get('matched_term'):\n",
    "            print(f\"       Matched: '{quote['matched_term']}'\")\n",
    "        print(f\"       \\\"{quote['quote']}\\\"\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"\\n4Ô∏è‚É£  PACING ISSUES: {result['pacing_risk']['risk_level']}\")\n",
    "if result['pacing_risk']['haters_with_wishes_pct']:\n",
    "    print(f\"  Haters Expressing Wishes: {result['pacing_risk']['haters_with_wishes_pct']}%\")\n",
    "if result['pacing_risk']['interpretation']:\n",
    "    print(f\"\\n  üí° Interpretation:\")\n",
    "    print(f\"     {result['pacing_risk']['interpretation']}\")\n",
    "    print(f\"\\n  üõ°Ô∏è  Mitigation:\")\n",
    "    print(f\"     {result['pacing_risk']['mitigation']}\")\n",
    "\n",
    "if result['pacing_risk']['sample_quotes']:\n",
    "    print(f\"\\n  üìù Sample Pacing Complaints (Contextual):\")\n",
    "    for i, quote in enumerate(result['pacing_risk']['sample_quotes'], 1):\n",
    "        print(f\"\\n    {i}. [{quote['review_id']}] {quote['reviewer']} - {quote['rating']}/10 ({quote['engagement']} votes)\")\n",
    "        if quote['review_title']:\n",
    "            print(f\"       Title: \\\"{quote['review_title']}\\\"\")\n",
    "        if quote.get('matched_term'):\n",
    "            print(f\"       Matched: '{quote['matched_term']}'\")\n",
    "        print(f\"       \\\"{quote['quote']}\\\"\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"\\n5Ô∏è‚É£  EXPECTATION MISMATCH: {result['expectation_risk']['risk_level']}\")\n",
    "if result['expectation_risk']['disappointment_rate']:\n",
    "    print(f\"  Disappointed Reviewers: {result['expectation_risk']['disappointed_count']} ({result['expectation_risk']['disappointment_rate']}%)\")\n",
    "if result['expectation_risk']['top_comparison_films']:\n",
    "    print(f\"\\n  Films Mentioned by Disappointed Viewers:\")\n",
    "    for film, count in list(result['expectation_risk']['top_comparison_films'].items())[:3]:\n",
    "        print(f\"    - {film} ({count} mentions)\")\n",
    "if result['expectation_risk']['interpretation']:\n",
    "    print(f\"\\n  üí° Interpretation:\")\n",
    "    print(f\"     {result['expectation_risk']['interpretation']}\")\n",
    "    print(f\"\\n  üõ°Ô∏è  Mitigation:\")\n",
    "    print(f\"     {result['expectation_risk']['mitigation']}\")\n",
    "\n",
    "if result['expectation_risk']['sample_quotes']:\n",
    "    print(f\"\\n  üìù Sample Expectation Complaints (Contextual):\")\n",
    "    for i, quote in enumerate(result['expectation_risk']['sample_quotes'], 1):\n",
    "        print(f\"\\n    {i}. [{quote['review_id']}] {quote['reviewer']} - {quote['rating']}/10 ({quote['engagement']} votes)\")\n",
    "        if quote['review_title']:\n",
    "            print(f\"       Title: \\\"{quote['review_title']}\\\"\")\n",
    "        if quote.get('matched_term'):\n",
    "            print(f\"       Matched: '{quote['matched_term']}'\")\n",
    "        print(f\"       \\\"{quote['quote']}\\\"\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"\\n6Ô∏è‚É£  GENDER POLARIZATION: {result['gender_risk']['risk_level']}\")\n",
    "print(f\"  Male Avg Rating: {result['gender_risk']['male_avg_rating']:.2f} (n={result['gender_risk']['male_count']})\")\n",
    "print(f\"  Female Avg Rating: {result['gender_risk']['female_avg_rating']:.2f} (n={result['gender_risk']['female_count']})\")\n",
    "if result['gender_risk']['gender_gap']:\n",
    "    print(f\"  Gender Gap: {result['gender_risk']['gender_gap']:.2f} points\")\n",
    "    print(f\"  Preference: {result['gender_risk']['gender_preference'].upper()}\")\n",
    "if result['gender_risk']['interpretation']:\n",
    "    print(f\"\\n  üí° Interpretation:\")\n",
    "    print(f\"     {result['gender_risk']['interpretation']}\")\n",
    "    print(f\"\\n  üõ°Ô∏è  Mitigation:\")\n",
    "    print(f\"     {result['gender_risk']['mitigation']}\")\n",
    "\n",
    "if result['gender_risk']['sample_quotes']:\n",
    "    lower_gender = 'female' if result['gender_risk']['gender_preference'] == 'male' else 'male'\n",
    "    print(f\"\\n  üìù Sample Quotes from {lower_gender.capitalize()} Haters (Contextual):\")\n",
    "    for i, quote in enumerate(result['gender_risk']['sample_quotes'], 1):\n",
    "        print(f\"\\n    {i}. [{quote['review_id']}] {quote['reviewer']} - {quote['rating']}/10 ({quote['engagement']} votes)\")\n",
    "        if quote['review_title']:\n",
    "            print(f\"       Title: \\\"{quote['review_title']}\\\"\")\n",
    "        print(f\"       \\\"{quote['quote']}\\\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n‚úÖ Module 6 test complete (with contextual quotes)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 7 Reach Strategy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_reach_strategy(audience_characteristics, comparison_films, risk_factors):\n",
    "    \"\"\"\n",
    "    Infer marketing channels based on audience characteristics\n",
    "    \n",
    "    Args:\n",
    "        audience_characteristics: Dict with avg_grade_level, avg_engagement, emotions, etc.\n",
    "        comparison_films: List of films this audience mentions\n",
    "        risk_factors: Dict from Module 6 to inform positioning\n",
    "    \n",
    "    Returns: List of specific channel recommendations\n",
    "    \"\"\"\n",
    "    channels = []\n",
    "    notes = []\n",
    "    \n",
    "    # Sophistication-based channels\n",
    "    avg_grade = audience_characteristics.get('avg_reading_grade', 0)\n",
    "    if avg_grade > 10:\n",
    "        channels.extend([\n",
    "            'Film festival audiences (Sundance, Fantastic Fest, SXSW)',\n",
    "            'Letterboxd power users (500+ reviews, arthouse focus)',\n",
    "            'Film Twitter influencers (critics, essayists)',\n",
    "            'Criterion Channel subscribers'\n",
    "        ])\n",
    "        notes.append('High sophistication - position as arthouse/festival film')\n",
    "    elif avg_grade > 8:\n",
    "        channels.extend([\n",
    "            'A24/Neon social media followers',\n",
    "            'Letterboxd users rating similar films 7+',\n",
    "            'Film podcast listeners (The Big Picture, Blank Check)'\n",
    "        ])\n",
    "        notes.append('Moderate sophistication - indie film audience')\n",
    "    \n",
    "    # Engagement-based channels\n",
    "    avg_engagement = audience_characteristics.get('avg_engagement', 0)\n",
    "    if avg_engagement > 50:\n",
    "        channels.extend([\n",
    "            'Reddit r/TrueFilm community (active discussers)',\n",
    "            'YouTube film essayists (in-depth analysis)',\n",
    "            'Film Discord servers'\n",
    "        ])\n",
    "        notes.append('High engagement - these are evangelists who drive word-of-mouth')\n",
    "    \n",
    "    # Genre/emotion-based channels\n",
    "    emotions = audience_characteristics.get('top_emotions', [])\n",
    "    if 'fear' in emotions[:2]:  # Fear is top emotion\n",
    "        channels.extend([\n",
    "            'Shudder subscribers',\n",
    "            'Reddit r/horror community',\n",
    "            'Horror podcasts (Faculty of Horror, Post Mortem)',\n",
    "            'Fangoria / Rue Morgue readers'\n",
    "        ])\n",
    "        notes.append('Horror enthusiasts - not casual scary movie fans')\n",
    "    \n",
    "    # Risk factor positioning\n",
    "    if risk_factors.get('complexity_risk', {}).get('risk_level') == 'HIGH':\n",
    "        channels.append('Position as \"elevated horror\" / \"slow burn\" to set expectations')\n",
    "        notes.append('CRITICAL: Marketing must emphasize arthouse nature to avoid complexity barrier')\n",
    "    \n",
    "    if risk_factors.get('intensity_risk', {}).get('risk_level') in ['HIGH', 'MODERATE']:\n",
    "        notes.append('Content warnings recommended - intensity may turn off casual viewers')\n",
    "    \n",
    "    # Gender-based channels\n",
    "    gender_pref = audience_characteristics.get('gender_preference')\n",
    "    if gender_pref == 'male':\n",
    "        notes.append('Male-skewing audience - consider male-focused horror communities')\n",
    "    elif gender_pref == 'female':\n",
    "        notes.append('Female-skewing audience - emphasize in marketing to female horror fans')\n",
    "    \n",
    "    # Comparison film strategy\n",
    "    if comparison_films:\n",
    "        top_comparisons = list(comparison_films.items())[:5]\n",
    "        comp_text = ', '.join([film for film, count in top_comparisons])\n",
    "        channels.append(f'Cross-promote with fans of: {comp_text}')\n",
    "        notes.append(f'Audiences actively compare to these films - use in positioning')\n",
    "    \n",
    "    # Platform strategy\n",
    "    channels.extend([\n",
    "        'Platform release strategy: Limited theatrical ‚Üí VOD/Streaming',\n",
    "        'Target: Specialty theaters in major metro areas (LA, NYC, Austin, Portland)'\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        'channels': channels,\n",
    "        'strategic_notes': notes\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ infer_reach_strategy() helper function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_audience_recommendation(movie_name):\n",
    "    \"\"\"\n",
    "    Generate Slides 2 & 7: Target Audience Recommendation\n",
    "    \n",
    "    Uses 4-criteria framework: Passionate + Understanding + Scalable + Reachable\n",
    "    \n",
    "    Returns: Dictionary with three audience tiers and reach strategy\n",
    "    \"\"\"\n",
    "    reviews = get_movie_reviews(movie_name)\n",
    "    \n",
    "    if len(reviews) == 0:\n",
    "        return {\n",
    "            'movie': movie_name,\n",
    "            'message': 'No reviews available for analysis'\n",
    "        }\n",
    "    \n",
    "    # Get lovers, mixed, haters\n",
    "    lovers = reviews[reviews['Rating'] >= 8].copy()\n",
    "    mixed = reviews[(reviews['Rating'] >= 4) & (reviews['Rating'] <= 7)].copy()\n",
    "    haters = reviews[reviews['Rating'] <= 3].copy()\n",
    "    \n",
    "    # ========================================\n",
    "    # PRIMARY AUDIENCE: Passionate + Understanding + Scalable\n",
    "    # ========================================\n",
    "    \n",
    "    # Criteria:\n",
    "    # - Passionate: love_count > 0 OR exclamation_count > 0 OR high engagement (votes > 10)\n",
    "    # - Understanding: reading grade > 8 AND has_comparisons = True (can contextualize)\n",
    "    # - Scalable: n > 30 (large enough to be a pattern)\n",
    "    \n",
    "    primary = lovers[\n",
    "        (\n",
    "            (lovers['love_count'] > 0) |\n",
    "            (lovers['exclamation_count'] > 0) |\n",
    "            (lovers['total_votes'] > 10)\n",
    "        ) &\n",
    "        (lovers['flesch_kincaid_grade'] > 8.0) &\n",
    "        (lovers['has_comparisons'] == True)\n",
    "    ].copy()\n",
    "    \n",
    "    primary_size = len(primary)\n",
    "    primary_pct = safe_percentage(primary_size, len(reviews))\n",
    "    \n",
    "    # Check scalability threshold\n",
    "    is_scalable = primary_size >= 30\n",
    "    \n",
    "    if primary_size < 30:\n",
    "        # Loosen criteria if too small\n",
    "        primary = lovers[\n",
    "            (\n",
    "                (lovers['love_count'] > 0) |\n",
    "                (lovers['exclamation_count'] > 0) |\n",
    "                (lovers['total_votes'] > 10)\n",
    "            ) &\n",
    "            (lovers['flesch_kincaid_grade'] > 7.0)  # Lower bar\n",
    "        ].copy()\n",
    "        primary_size = len(primary)\n",
    "        primary_pct = safe_percentage(primary_size, len(reviews))\n",
    "        is_scalable = primary_size >= 30\n",
    "    \n",
    "    # Demographics\n",
    "    primary_male = len(primary[primary['username_gender_hint'] == 'male'])\n",
    "    primary_female = len(primary[primary['username_gender_hint'] == 'female'])\n",
    "    primary_gender_pct = safe_percentage(primary_male + primary_female, primary_size)\n",
    "    \n",
    "    primary_gender_skew = 'neutral'\n",
    "    if primary_male > primary_female * 1.5:\n",
    "        primary_gender_skew = 'male'\n",
    "    elif primary_female > primary_male * 1.5:\n",
    "        primary_gender_skew = 'female'\n",
    "    \n",
    "    # Characteristics\n",
    "    primary_avg_rating = safe_mean(primary['Rating'])\n",
    "    primary_avg_grade = safe_mean(primary['flesch_kincaid_grade'])\n",
    "    primary_avg_engagement = safe_mean(primary['total_votes'])\n",
    "    \n",
    "    # Passion indicators\n",
    "    primary_love_count = len(primary[primary['love_count'] > 0])\n",
    "    primary_exclamation_count = len(primary[primary['exclamation_count'] > 0])\n",
    "    primary_high_engagement = len(primary[primary['total_votes'] > 20])\n",
    "    \n",
    "    # Psychographics - emotions\n",
    "    emotion_cols = ['emotion_joy', 'emotion_trust', 'emotion_fear', 'emotion_surprise', \n",
    "                    'emotion_sadness', 'emotion_disgust', 'emotion_anger', 'emotion_anticipation']\n",
    "    primary_emotions = {}\n",
    "    for col in emotion_cols:\n",
    "        emotion_name = col.replace('emotion_', '')\n",
    "        primary_emotions[emotion_name] = safe_mean(primary[col])\n",
    "    \n",
    "    # Sort emotions by intensity\n",
    "    sorted_emotions = sorted(primary_emotions.items(), key=lambda x: x[1] if x[1] else 0, reverse=True)\n",
    "    top_3_emotions = [e[0] for e in sorted_emotions[:3]]\n",
    "    \n",
    "    # Comparison films mentioned by primary audience\n",
    "    primary_comparisons = []\n",
    "    for movies in primary['movies_mentioned'].dropna():\n",
    "        if isinstance(movies, str) and movies != '[]':\n",
    "            import ast\n",
    "            try:\n",
    "                movie_list = ast.literal_eval(movies)\n",
    "                primary_comparisons.extend(movie_list)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    from collections import Counter\n",
    "    primary_comparison_films = dict(Counter(primary_comparisons).most_common(10))\n",
    "    \n",
    "    # Extract passion quotes (why they loved it)\n",
    "    primary_passion_quotes = extract_contextual_quotes(\n",
    "        primary,\n",
    "        search_terms=['love', 'amazing', 'brilliant', 'masterpiece', 'perfect', 'favorite', 'incredible', 'beautiful'],\n",
    "        limit=3,\n",
    "        context_sentences=2\n",
    "    )\n",
    "    \n",
    "    # Extract sophistication quotes (how they articulate themes)\n",
    "    primary_sophistication_quotes = extract_contextual_quotes(\n",
    "        primary[primary['has_comparisons'] == True],\n",
    "        search_terms=None,  # Get most engaged reviews with comparisons\n",
    "        limit=3,\n",
    "        context_sentences=2\n",
    "    )\n",
    "    \n",
    "    # ========================================\n",
    "    # SECONDARY AUDIENCE: Positive but Less Passionate\n",
    "    # ========================================\n",
    "    \n",
    "    # Criteria:\n",
    "    # - Rating 7-8 (positive but not ecstatic)\n",
    "    # - OR lovers who don't meet primary criteria\n",
    "    \n",
    "    secondary = reviews[\n",
    "        ((reviews['Rating'] >= 7) & (reviews['Rating'] < 8)) |\n",
    "        ((reviews['Rating'] >= 8) & (~reviews.index.isin(primary.index)))\n",
    "    ].copy()\n",
    "    \n",
    "    secondary_size = len(secondary)\n",
    "    secondary_pct = safe_percentage(secondary_size, len(reviews))\n",
    "    \n",
    "    # Demographics\n",
    "    secondary_male = len(secondary[secondary['username_gender_hint'] == 'male'])\n",
    "    secondary_female = len(secondary[secondary['username_gender_hint'] == 'female'])\n",
    "    \n",
    "    secondary_gender_skew = 'neutral'\n",
    "    if secondary_male > secondary_female * 1.5:\n",
    "        secondary_gender_skew = 'male'\n",
    "    elif secondary_female > secondary_male * 1.5:\n",
    "        secondary_gender_skew = 'female'\n",
    "    \n",
    "    # Characteristics\n",
    "    secondary_avg_rating = safe_mean(secondary['Rating'])\n",
    "    secondary_avg_grade = safe_mean(secondary['flesch_kincaid_grade'])\n",
    "    secondary_avg_engagement = safe_mean(secondary['total_votes'])\n",
    "    \n",
    "    # ========================================\n",
    "    # TERTIARY AUDIENCE: AVOID - Wrong Fit\n",
    "    # ========================================\n",
    "    \n",
    "    # These are haters - wrong expectations, complexity barrier, etc.\n",
    "    tertiary = haters.copy()\n",
    "    \n",
    "    tertiary_size = len(tertiary)\n",
    "    tertiary_pct = safe_percentage(tertiary_size, len(reviews))\n",
    "    \n",
    "    # What did they expect? (comparison films)\n",
    "    tertiary_comparisons = []\n",
    "    for movies in tertiary['movies_mentioned'].dropna():\n",
    "        if isinstance(movies, str) and movies != '[]':\n",
    "            import ast\n",
    "            try:\n",
    "                movie_list = ast.literal_eval(movies)\n",
    "                tertiary_comparisons.extend(movie_list)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    tertiary_comparison_films = dict(Counter(tertiary_comparisons).most_common(5))\n",
    "    \n",
    "    # Top complaints\n",
    "    tertiary_avg_grade = safe_mean(tertiary['flesch_kincaid_grade'])\n",
    "    tertiary_wish_pct = safe_percentage(len(tertiary[tertiary['wish_count'] > 0]), len(tertiary))\n",
    "    \n",
    "    # Complexity barrier?\n",
    "    complexity_barrier = False\n",
    "    if primary_avg_grade and tertiary_avg_grade:\n",
    "        if primary_avg_grade - tertiary_avg_grade > 2.5:\n",
    "            complexity_barrier = True\n",
    "    \n",
    "    # Extract warning quotes (why to avoid marketing to them)\n",
    "    tertiary_warning_quotes = extract_contextual_quotes(\n",
    "        tertiary,\n",
    "        search_terms=['waste', 'boring', 'nothing happens', 'slow', 'disappointed', 'overhyped', 'pretentious'],\n",
    "        limit=3,\n",
    "        context_sentences=2\n",
    "    )\n",
    "    \n",
    "    # ========================================\n",
    "    # REACH STRATEGY INFERENCE\n",
    "    # ========================================\n",
    "    \n",
    "    # Get risk factors from Module 6 (if we want to reference them)\n",
    "    # For now, we'll create a simplified version\n",
    "    risk_factors_summary = {\n",
    "        'complexity_risk': {\n",
    "            'risk_level': 'HIGH' if complexity_barrier else 'LOW'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    primary_reach = infer_reach_strategy(\n",
    "        audience_characteristics={\n",
    "            'avg_reading_grade': primary_avg_grade,\n",
    "            'avg_engagement': primary_avg_engagement,\n",
    "            'top_emotions': top_3_emotions,\n",
    "            'gender_preference': primary_gender_skew\n",
    "        },\n",
    "        comparison_films=primary_comparison_films,\n",
    "        risk_factors=risk_factors_summary\n",
    "    )\n",
    "    \n",
    "    # ========================================\n",
    "    # MESSAGING RECOMMENDATIONS\n",
    "    # ========================================\n",
    "    \n",
    "    # Based on what resonated with primary audience\n",
    "    messaging = {\n",
    "        'tone': 'sophisticated' if primary_avg_grade and primary_avg_grade > 9 else 'accessible',\n",
    "        'keywords': [],\n",
    "        'avoid': []\n",
    "    }\n",
    "    \n",
    "    # Add keywords based on emotions\n",
    "    if 'fear' in top_3_emotions:\n",
    "        messaging['keywords'].append('atmospheric horror')\n",
    "    if 'anticipation' in top_3_emotions:\n",
    "        messaging['keywords'].append('suspenseful')\n",
    "    if 'sadness' in top_3_emotions:\n",
    "        messaging['keywords'].append('emotional depth')\n",
    "    \n",
    "    # Add comparison film positioning\n",
    "    if primary_comparison_films:\n",
    "        top_comp = list(primary_comparison_films.keys())[:3]\n",
    "        messaging['keywords'].append(f\"For fans of: {', '.join(top_comp)}\")\n",
    "    \n",
    "    # What to avoid based on tertiary complaints\n",
    "    if tertiary_wish_pct and tertiary_wish_pct > 10:\n",
    "        messaging['avoid'].append('Promising jump scares or action that isn\\'t delivered')\n",
    "    if complexity_barrier:\n",
    "        messaging['avoid'].append('Marketing to mainstream horror audiences expecting conventional scares')\n",
    "    \n",
    "    # ========================================\n",
    "    # RETURN STRUCTURE\n",
    "    # ========================================\n",
    "    \n",
    "    return {\n",
    "        'movie': movie_name,\n",
    "        \n",
    "        'primary_audience': {\n",
    "            'tier': 'PRIMARY - Core Target',\n",
    "            'size': primary_size,\n",
    "            'percentage': primary_pct,\n",
    "            'criteria': 'Passionate + Understanding + Scalable',\n",
    "            'is_scalable': is_scalable,\n",
    "            'scalability_note': 'Sufficient size for viable audience' if is_scalable else 'WARNING: Small sample - may be too niche',\n",
    "            \n",
    "            'demographics': {\n",
    "                'gender_skew': primary_gender_skew,\n",
    "                'male_count': primary_male,\n",
    "                'female_count': primary_female,\n",
    "                'male_pct': safe_percentage(primary_male, primary_size),\n",
    "                'female_pct': safe_percentage(primary_female, primary_size),\n",
    "                'gender_coverage': primary_gender_pct\n",
    "            },\n",
    "            \n",
    "            'characteristics': {\n",
    "                'avg_rating': primary_avg_rating,\n",
    "                'avg_reading_grade': primary_avg_grade,\n",
    "                'avg_engagement': primary_avg_engagement,\n",
    "                'sophistication_level': 'High' if primary_avg_grade and primary_avg_grade > 10 else 'Moderate' if primary_avg_grade and primary_avg_grade > 8 else 'Standard'\n",
    "            },\n",
    "            \n",
    "            'passion_indicators': {\n",
    "                'love_statements': primary_love_count,\n",
    "                'love_pct': safe_percentage(primary_love_count, primary_size),\n",
    "                'exclamations': primary_exclamation_count,\n",
    "                'exclamation_pct': safe_percentage(primary_exclamation_count, primary_size),\n",
    "                'high_engagement': primary_high_engagement,\n",
    "                'high_engagement_pct': safe_percentage(primary_high_engagement, primary_size)\n",
    "            },\n",
    "            \n",
    "            'psychographics': {\n",
    "                'top_3_emotions': top_3_emotions,\n",
    "                'all_emotions': primary_emotions,\n",
    "                'comparison_films': primary_comparison_films,\n",
    "                'top_5_comparisons': dict(list(primary_comparison_films.items())[:5])\n",
    "            },\n",
    "            \n",
    "            'reach_strategy': primary_reach['channels'],\n",
    "            'strategic_notes': primary_reach['strategic_notes'],\n",
    "            \n",
    "            'sample_quotes': {\n",
    "                'passion': primary_passion_quotes,\n",
    "                'sophistication': primary_sophistication_quotes\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        'secondary_audience': {\n",
    "            'tier': 'SECONDARY - Broader Appeal',\n",
    "            'size': secondary_size,\n",
    "            'percentage': secondary_pct,\n",
    "            'criteria': 'Positive (7-8 rating) or lovers not meeting primary criteria',\n",
    "            \n",
    "            'demographics': {\n",
    "                'gender_skew': secondary_gender_skew,\n",
    "                'male_count': secondary_male,\n",
    "                'female_count': secondary_female\n",
    "            },\n",
    "            \n",
    "            'characteristics': {\n",
    "                'avg_rating': secondary_avg_rating,\n",
    "                'avg_reading_grade': secondary_avg_grade,\n",
    "                'avg_engagement': secondary_avg_engagement,\n",
    "                'sophistication_level': 'Moderate' if secondary_avg_grade and secondary_avg_grade > 8 else 'Standard'\n",
    "            },\n",
    "            \n",
    "            'reach_strategy': [\n",
    "                'Broader horror platforms (Shudder, genre streaming)',\n",
    "                'Social media (targeted ads to horror fans)',\n",
    "                'VOD platforms (Amazon, iTunes horror categories)',\n",
    "                'Genre festivals and conventions'\n",
    "            ],\n",
    "            \n",
    "            'messaging_notes': 'More accessible positioning than primary audience - emphasize entertainment value alongside artistic merit'\n",
    "        },\n",
    "        \n",
    "        'tertiary_avoid': {\n",
    "            'tier': 'TERTIARY - Avoid Marketing To',\n",
    "            'size': tertiary_size,\n",
    "            'percentage': tertiary_pct,\n",
    "            'warning': '‚ö†Ô∏è  DO NOT market to this segment - wrong expectations, will generate negative word-of-mouth',\n",
    "            \n",
    "            'characteristics': {\n",
    "                'avg_rating': safe_mean(tertiary['Rating']),\n",
    "                'avg_reading_grade': tertiary_avg_grade,\n",
    "                'complexity_barrier': complexity_barrier,\n",
    "                'wish_statement_pct': tertiary_wish_pct\n",
    "            },\n",
    "            \n",
    "            'wrong_expectations': {\n",
    "                'expected_films': tertiary_comparison_films,\n",
    "                'top_complaints': 'Expected mainstream horror with scares' if tertiary_wish_pct and tertiary_wish_pct > 10 else 'Film too slow/complex'\n",
    "            },\n",
    "            \n",
    "            'sample_warnings': tertiary_warning_quotes\n",
    "        },\n",
    "        \n",
    "        'messaging_recommendations': messaging\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ target_audience_recommendation() function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Module 7 on The Witch\n",
    "\n",
    "print(\"üß™ Testing Module 7: Target Audience Recommendation\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_movie = \"The Witch\"\n",
    "result = target_audience_recommendation(test_movie)\n",
    "\n",
    "print(f\"\\nüéØ TARGET AUDIENCE RECOMMENDATION: {test_movie}\\n\")\n",
    "\n",
    "# ========================================\n",
    "# PRIMARY AUDIENCE\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n1Ô∏è‚É£  PRIMARY AUDIENCE - Core Target\")\n",
    "print(f\"\\nüìä Size & Scalability:\")\n",
    "print(f\"  Count: {result['primary_audience']['size']} ({result['primary_audience']['percentage']}% of all reviews)\")\n",
    "print(f\"  Scalable: {'‚úÖ YES' if result['primary_audience']['is_scalable'] else '‚ö†Ô∏è  NO'}\")\n",
    "print(f\"  Note: {result['primary_audience']['scalability_note']}\")\n",
    "print(f\"  Criteria: {result['primary_audience']['criteria']}\")\n",
    "\n",
    "print(f\"\\nüë• Demographics:\")\n",
    "print(f\"  Gender Skew: {result['primary_audience']['demographics']['gender_skew'].upper()}\")\n",
    "print(f\"  Male: {result['primary_audience']['demographics']['male_count']} ({result['primary_audience']['demographics']['male_pct']}%)\")\n",
    "print(f\"  Female: {result['primary_audience']['demographics']['female_count']} ({result['primary_audience']['demographics']['female_pct']}%)\")\n",
    "\n",
    "print(f\"\\nüìà Characteristics:\")\n",
    "print(f\"  Avg Rating: {result['primary_audience']['characteristics']['avg_rating']:.2f}/10\")\n",
    "print(f\"  Avg Reading Grade: {result['primary_audience']['characteristics']['avg_reading_grade']:.1f}\")\n",
    "print(f\"  Sophistication: {result['primary_audience']['characteristics']['sophistication_level']}\")\n",
    "print(f\"  Avg Engagement: {result['primary_audience']['characteristics']['avg_engagement']:.1f} votes\")\n",
    "\n",
    "print(f\"\\nüî• Passion Indicators:\")\n",
    "print(f\"  Love Statements: {result['primary_audience']['passion_indicators']['love_statements']} ({result['primary_audience']['passion_indicators']['love_pct']}%)\")\n",
    "print(f\"  Exclamations: {result['primary_audience']['passion_indicators']['exclamations']} ({result['primary_audience']['passion_indicators']['exclamation_pct']}%)\")\n",
    "print(f\"  High Engagement (20+ votes): {result['primary_audience']['passion_indicators']['high_engagement']} ({result['primary_audience']['passion_indicators']['high_engagement_pct']}%)\")\n",
    "\n",
    "print(f\"\\nüß† Psychographics:\")\n",
    "print(f\"  Top 3 Emotions: {', '.join([e.capitalize() for e in result['primary_audience']['psychographics']['top_3_emotions']])}\")\n",
    "print(f\"\\n  Top Comparison Films:\")\n",
    "for film, count in list(result['primary_audience']['psychographics']['top_5_comparisons'].items())[:5]:\n",
    "    print(f\"    - {film} ({count} mentions)\")\n",
    "\n",
    "print(f\"\\nüì¢ Reach Strategy:\")\n",
    "for i, channel in enumerate(result['primary_audience']['reach_strategy'], 1):\n",
    "    print(f\"  {i}. {channel}\")\n",
    "\n",
    "print(f\"\\nüí° Strategic Notes:\")\n",
    "for i, note in enumerate(result['primary_audience']['strategic_notes'], 1):\n",
    "    print(f\"  {i}. {note}\")\n",
    "\n",
    "print(f\"\\nüí¨ Sample Quotes - PASSION:\")\n",
    "for i, quote in enumerate(result['primary_audience']['sample_quotes']['passion'], 1):\n",
    "    print(f\"\\n  {i}. [{quote['review_id']}] {quote['reviewer']} - {quote['rating']}/10 ({quote['engagement']} votes)\")\n",
    "    if quote['review_title']:\n",
    "        print(f\"     Title: \\\"{quote['review_title']}\\\"\")\n",
    "    if quote.get('matched_term'):\n",
    "        print(f\"     Matched: '{quote['matched_term']}'\")\n",
    "    print(f\"     \\\"{quote['quote']}\\\"\")\n",
    "\n",
    "print(f\"\\nüí¨ Sample Quotes - SOPHISTICATION (Theme Articulation):\")\n",
    "for i, quote in enumerate(result['primary_audience']['sample_quotes']['sophistication'], 1):\n",
    "    print(f\"\\n  {i}. [{quote['review_id']}] {quote['reviewer']} - {quote['rating']}/10 ({quote['engagement']} votes)\")\n",
    "    if quote['review_title']:\n",
    "        print(f\"     Title: \\\"{quote['review_title']}\\\"\")\n",
    "    print(f\"     \\\"{quote['quote']}\\\"\")\n",
    "\n",
    "# ========================================\n",
    "# SECONDARY AUDIENCE\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"\\n2Ô∏è‚É£  SECONDARY AUDIENCE - Broader Appeal\")\n",
    "print(f\"\\nüìä Size:\")\n",
    "print(f\"  Count: {result['secondary_audience']['size']} ({result['secondary_audience']['percentage']}% of all reviews)\")\n",
    "print(f\"  Criteria: {result['secondary_audience']['criteria']}\")\n",
    "\n",
    "print(f\"\\nüë• Demographics:\")\n",
    "print(f\"  Gender Skew: {result['secondary_audience']['demographics']['gender_skew'].upper()}\")\n",
    "print(f\"  Male: {result['secondary_audience']['demographics']['male_count']}\")\n",
    "print(f\"  Female: {result['secondary_audience']['demographics']['female_count']}\")\n",
    "\n",
    "print(f\"\\nüìà Characteristics:\")\n",
    "print(f\"  Avg Rating: {result['secondary_audience']['characteristics']['avg_rating']:.2f}/10\")\n",
    "print(f\"  Avg Reading Grade: {result['secondary_audience']['characteristics']['avg_reading_grade']:.1f}\")\n",
    "print(f\"  Sophistication: {result['secondary_audience']['characteristics']['sophistication_level']}\")\n",
    "\n",
    "print(f\"\\nüì¢ Reach Strategy:\")\n",
    "for i, channel in enumerate(result['secondary_audience']['reach_strategy'], 1):\n",
    "    print(f\"  {i}. {channel}\")\n",
    "\n",
    "print(f\"\\nüí° Messaging Note:\")\n",
    "print(f\"  {result['secondary_audience']['messaging_notes']}\")\n",
    "\n",
    "# ========================================\n",
    "# TERTIARY - AVOID\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"\\n3Ô∏è‚É£  TERTIARY AUDIENCE - AVOID MARKETING TO\")\n",
    "print(f\"\\n‚ö†Ô∏è  {result['tertiary_avoid']['warning']}\")\n",
    "print(f\"\\nüìä Size:\")\n",
    "print(f\"  Count: {result['tertiary_avoid']['size']} ({result['tertiary_avoid']['percentage']}% of all reviews)\")\n",
    "\n",
    "print(f\"\\nüìâ Characteristics:\")\n",
    "print(f\"  Avg Rating: {result['tertiary_avoid']['characteristics']['avg_rating']:.2f}/10\")\n",
    "print(f\"  Avg Reading Grade: {result['tertiary_avoid']['characteristics']['avg_reading_grade']:.1f}\")\n",
    "print(f\"  Complexity Barrier: {'YES - Too arthouse for them' if result['tertiary_avoid']['characteristics']['complexity_barrier'] else 'No'}\")\n",
    "print(f\"  Wish Statements: {result['tertiary_avoid']['characteristics']['wish_statement_pct']}% (unfulfilled expectations)\")\n",
    "\n",
    "print(f\"\\n‚ùå Wrong Expectations:\")\n",
    "print(f\"  {result['tertiary_avoid']['wrong_expectations']['top_complaints']}\")\n",
    "if result['tertiary_avoid']['wrong_expectations']['expected_films']:\n",
    "    print(f\"\\n  Films They Expected (but this isn't):\")\n",
    "    for film, count in list(result['tertiary_avoid']['wrong_expectations']['expected_films'].items())[:3]:\n",
    "        print(f\"    - {film} ({count} mentions)\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Sample Warning Quotes:\")\n",
    "for i, quote in enumerate(result['tertiary_avoid']['sample_warnings'], 1):\n",
    "    print(f\"\\n  {i}. [{quote['review_id']}] {quote['reviewer']} - {quote['rating']}/10 ({quote['engagement']} votes)\")\n",
    "    if quote['review_title']:\n",
    "        print(f\"     Title: \\\"{quote['review_title']}\\\"\")\n",
    "    if quote.get('matched_term'):\n",
    "        print(f\"     Matched: '{quote['matched_term']}'\")\n",
    "    print(f\"     \\\"{quote['quote']}\\\"\")\n",
    "\n",
    "# ========================================\n",
    "# MESSAGING RECOMMENDATIONS\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"\\nüì£ MESSAGING RECOMMENDATIONS\")\n",
    "print(f\"\\n  Tone: {result['messaging_recommendations']['tone'].upper()}\")\n",
    "print(f\"\\n  Keywords:\")\n",
    "for keyword in result['messaging_recommendations']['keywords']:\n",
    "    print(f\"    ‚Ä¢ {keyword}\")\n",
    "print(f\"\\n  Avoid:\")\n",
    "for avoid in result['messaging_recommendations']['avoid']:\n",
    "    print(f\"    ‚Ä¢ {avoid}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n‚úÖ Module 7 test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 8 JSON Export "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODULE 8: JSON EXPORT FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def export_movie_analysis(movie_name, output_dir='../insights'):\n",
    "    \"\"\"\n",
    "    Run all analysis modules for a single movie and export to JSON\n",
    "    \n",
    "    Args:\n",
    "        movie_name: Name of the movie to analyze\n",
    "        output_dir: Directory to save JSON file (default: ../insights)\n",
    "    \n",
    "    Returns: Dictionary with all analysis results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üé¨ Analyzing: {movie_name}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Run all analysis modules\n",
    "    results = {\n",
    "        'movie': movie_name,\n",
    "        'analysis_date': datetime.now().isoformat(),\n",
    "        'modules': {}\n",
    "    }\n",
    "    \n",
    "    # Module 1: Audience Breakdown\n",
    "    print(\"üìä Module 1: Audience Breakdown...\")\n",
    "    try:\n",
    "        results['modules']['audience_breakdown'] = audience_breakdown(movie_name)\n",
    "        print(\"   ‚úÖ Complete\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "        results['modules']['audience_breakdown'] = {'error': str(e)}\n",
    "    \n",
    "    # Module 2: What Resonated\n",
    "    print(\"‚ù§Ô∏è  Module 2: What Resonated...\")\n",
    "    try:\n",
    "        results['modules']['what_resonated'] = what_resonated(movie_name)\n",
    "        print(\"   ‚úÖ Complete\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "        results['modules']['what_resonated'] = {'error': str(e)}\n",
    "    \n",
    "    # Module 3: What Didn't Work\n",
    "    print(\"üíî Module 3: What Didn't Work...\")\n",
    "    try:\n",
    "        results['modules']['what_didnt_work'] = what_didnt_work(movie_name)\n",
    "        print(\"   ‚úÖ Complete\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "        results['modules']['what_didnt_work'] = {'error': str(e)}\n",
    "    \n",
    "    # Module 4: Polarization Analysis\n",
    "    print(\"‚ö° Module 4: Polarization Analysis...\")\n",
    "    try:\n",
    "        results['modules']['polarization'] = polarization_analysis(movie_name)\n",
    "        print(\"   ‚úÖ Complete\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "        results['modules']['polarization'] = {'error': str(e)}\n",
    "    \n",
    "    # Module 5: Marketing Disconnect\n",
    "    print(\"üìä Module 5: Marketing Disconnect...\")\n",
    "    try:\n",
    "        results['modules']['marketing_disconnect'] = marketing_disconnect_analysis(movie_name)\n",
    "        print(\"   ‚úÖ Complete\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "        results['modules']['marketing_disconnect'] = {'error': str(e)}\n",
    "    \n",
    "    # Module 6: Risk Factors\n",
    "    print(\"‚ö†Ô∏è  Module 6: Risk Factors...\")\n",
    "    try:\n",
    "        results['modules']['risk_factors'] = risk_factors_analysis(movie_name)\n",
    "        print(\"   ‚úÖ Complete\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "        results['modules']['risk_factors'] = {'error': str(e)}\n",
    "    \n",
    "    # Module 7: Target Audience (if function exists)\n",
    "    try:\n",
    "        print(\"üéØ Module 7: Target Audience...\")\n",
    "        results['modules']['target_audience'] = target_audience_recommendation(movie_name)\n",
    "        print(\"   ‚úÖ Complete\")\n",
    "    except NameError:\n",
    "        print(\"üéØ Module 7: Target Audience... ‚è≠Ô∏è  Skipped (function not defined)\")\n",
    "        results['modules']['target_audience'] = {'status': 'skipped', 'reason': 'function not defined'}\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "        results['modules']['target_audience'] = {'error': str(e)}\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Generate filename (sanitize movie name)\n",
    "    safe_movie_name = movie_name.lower().replace(' ', '_').replace(\"'\", \"\")\n",
    "    filename = f\"{safe_movie_name}.json\"\n",
    "    filepath = output_path / filename\n",
    "    \n",
    "    # Export to JSON\n",
    "    print(f\"\\nüíæ Exporting to JSON...\")\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"   ‚úÖ Saved: {filepath}\")\n",
    "    print(f\"\\n{'='*80}\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def export_all_movies(output_dir='../insights'):\n",
    "    \"\"\"\n",
    "    Run analysis on all 10 movies and export individual JSON files\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory to save JSON files (default: ../insights)\n",
    "    \n",
    "    Returns: Dictionary with all movie results\n",
    "    \"\"\"\n",
    "    \n",
    "    all_results = {\n",
    "        'export_date': datetime.now().isoformat(),\n",
    "        'total_movies': len(MOVIES),\n",
    "        'movies': {}\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüé¨ BATCH EXPORT: Analyzing {len(MOVIES)} movies\")\n",
    "    print(f\"üìÅ Output directory: {output_dir}\\n\")\n",
    "    \n",
    "    for i, movie in enumerate(MOVIES, 1):\n",
    "        print(f\"\\n[{i}/{len(MOVIES)}] Processing: {movie}\")\n",
    "        \n",
    "        try:\n",
    "            result = export_movie_analysis(movie, output_dir)\n",
    "            # Create safe filename outside f-string\n",
    "            safe_name = movie.lower().replace(' ', '_')\n",
    "            safe_name = safe_name.replace(\"'\", \"\")\n",
    "            json_filename = safe_name + \".json\"\n",
    "            \n",
    "            all_results['movies'][movie] = {\n",
    "                'status': 'success',\n",
    "                'filepath': json_filename\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå FAILED: {e}\")\n",
    "            all_results['movies'][movie] = {\n",
    "                'status': 'failed',\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    # Export master index file\n",
    "    output_path = Path(output_dir)\n",
    "    master_file = output_path / '_index.json'\n",
    "    \n",
    "    with open(master_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"‚úÖ BATCH EXPORT COMPLETE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nüìä Summary:\")\n",
    "    print(f\"   Total movies: {len(MOVIES)}\")\n",
    "    \n",
    "    successful = sum(1 for m in all_results['movies'].values() if m['status'] == 'success')\n",
    "    failed = sum(1 for m in all_results['movies'].values() if m['status'] == 'failed')\n",
    "    \n",
    "    print(f\"   Successful: {successful}\")\n",
    "    print(f\"   Failed: {failed}\")\n",
    "    print(f\"   Master index: {master_file}\")\n",
    "    print(f\"\\n\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "def create_combined_export(output_dir='../insights', output_file='all_movies_combined.json'):\n",
    "    \"\"\"\n",
    "    Create a single JSON file with all movie analyses combined\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory containing individual JSON files\n",
    "        output_file: Name of combined output file\n",
    "    \n",
    "    Returns: Combined results dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nüì¶ Creating combined export...\")\n",
    "    \n",
    "    output_path = Path(output_dir)\n",
    "    combined_data = {\n",
    "        'export_date': datetime.now().isoformat(),\n",
    "        'total_movies': len(MOVIES),\n",
    "        'movies': {}\n",
    "    }\n",
    "    \n",
    "    # Read all individual movie JSON files\n",
    "    for movie in MOVIES:\n",
    "        # Create safe filename outside f-string\n",
    "        safe_movie_name = movie.lower().replace(' ', '_')\n",
    "        safe_movie_name = safe_movie_name.replace(\"'\", \"\")\n",
    "        json_filename = safe_movie_name + \".json\"\n",
    "        \n",
    "        filepath = output_path / json_filename\n",
    "        \n",
    "        if filepath.exists():\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                movie_data = json.load(f)\n",
    "                combined_data['movies'][movie] = movie_data\n",
    "            print(f\"   ‚úÖ Loaded: {movie}\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  Missing: {movie}\")\n",
    "            combined_data['movies'][movie] = {'status': 'file_not_found'}\n",
    "    \n",
    "    # Save combined file\n",
    "    combined_filepath = output_path / output_file\n",
    "    with open(combined_filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(combined_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    file_size_kb = combined_filepath.stat().st_size / 1024\n",
    "    print(f\"\\n   üíæ Combined file saved: {combined_filepath}\")\n",
    "    print(f\"   üìä Size: {file_size_kb:.1f} KB\")\n",
    "    print(f\"\\n\")\n",
    "    \n",
    "    return combined_data\n",
    "\n",
    "\n",
    "def quick_export(movie_name, output_dir='../insights'):\n",
    "    \"\"\"Quick export for a single movie (convenience wrapper)\"\"\"\n",
    "    return export_movie_analysis(movie_name, output_dir)\n",
    "\n",
    "print(\"‚úÖ Module 8: JSON Export Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Module 8 with The Witch\n",
    "print(\"üß™ Testing Module 8: Single Movie Export\\n\")\n",
    "\n",
    "result = quick_export(\"The Witch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Export all "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = export_all_movies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# MODULE 9: CROSS-MOVIE SYNTHESIS"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MODULE 9: CROSS-MOVIE SYNTHESIS\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODULE 9: CROSS-MOVIE SYNTHESIS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüì¶ Loading all movie data...\\n\")\n",
    "\n",
    "# Load all JSON files\n",
    "insights_dir = Path('../insights')\n",
    "all_movies_data = {}\n",
    "\n",
    "for movie in MOVIES:\n",
    "    safe_name = movie.lower().replace(' ', '_').replace(\"'\", \"\")\n",
    "    filepath = insights_dir / f\"{safe_name}.json\"\n",
    "    \n",
    "    if filepath.exists():\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            all_movies_data[movie] = json.load(f)\n",
    "        print(f\"  ‚úÖ Loaded: {movie}\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è  Missing: {movie}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded {len(all_movies_data)} movies\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for cross-movie analysis\n",
    "\n",
    "def extract_rating_stats(movies_data):\n",
    "    \"\"\"Extract basic rating statistics across all movies\"\"\"\n",
    "    stats = []\n",
    "    for movie, data in movies_data.items():\n",
    "        if 'audience_breakdown' in data['modules']:\n",
    "            mod = data['modules']['audience_breakdown']\n",
    "            stats.append({\n",
    "                'movie': movie,\n",
    "                'total_reviews': mod['total_reviews'],\n",
    "                'avg_rating': mod['avg_rating'],\n",
    "                'rating_variance': mod['rating_variance'],\n",
    "                'lovers_pct': mod['rating_segments']['lovers_pct'],\n",
    "                'haters_pct': mod['rating_segments']['haters_pct']\n",
    "            })\n",
    "    return stats\n",
    "\n",
    "def extract_risk_patterns(movies_data):\n",
    "    \"\"\"Extract risk factors across all movies\"\"\"\n",
    "    risks = []\n",
    "    for movie, data in movies_data.items():\n",
    "        if 'risk_factors' in data['modules']:\n",
    "            mod = data['modules']['risk_factors']\n",
    "            if 'overall_risk_assessment' in mod:\n",
    "                risks.append({\n",
    "                    'movie': movie,\n",
    "                    'risk_level': mod['overall_risk_assessment']['risk_level'],\n",
    "                    'risk_score': mod['overall_risk_assessment']['risk_score'],\n",
    "                    'high_risks': mod['overall_risk_assessment'].get('high_risks', [])\n",
    "                })\n",
    "    return risks\n",
    "\n",
    "def extract_polarization_patterns(movies_data):\n",
    "    \"\"\"Extract polarization data across all movies\"\"\"\n",
    "    polar = []\n",
    "    for movie, data in movies_data.items():\n",
    "        if 'polarization' in data['modules']:\n",
    "            mod = data['modules']['polarization']\n",
    "            polar.append({\n",
    "                'movie': movie,\n",
    "                'level': mod['polarization_metrics']['level'],\n",
    "                'variance': mod['polarization_metrics']['rating_variance'],\n",
    "                'temporal_shift': mod['temporal_polarization']['temporal_shift'],\n",
    "                'gender_gap': mod['gender_polarization']['gender_rating_gap']\n",
    "            })\n",
    "    return polar\n",
    "\n",
    "def extract_audience_quotes(movies_data, module_name, quote_type, limit=3):\n",
    "    \"\"\"Extract top quotes from a specific module across all movies\"\"\"\n",
    "    all_quotes = []\n",
    "    \n",
    "    for movie, data in movies_data.items():\n",
    "        if module_name in data['modules']:\n",
    "            mod = data['modules'][module_name]\n",
    "            \n",
    "            # Navigate to quotes based on module structure\n",
    "            if quote_type in mod:\n",
    "                if 'quotes' in mod[quote_type]:\n",
    "                    quotes = mod[quote_type]['quotes'][:limit]\n",
    "                    for q in quotes:\n",
    "                        q['source_movie'] = movie\n",
    "                        all_quotes.append(q)\n",
    "    \n",
    "    # Sort by engagement\n",
    "    all_quotes.sort(key=lambda x: x.get('engagement', 0), reverse=True)\n",
    "    return all_quotes\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 1: SUCCESS FACTORS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Get rating statistics\n",
    "rating_stats = extract_rating_stats(all_movies_data)\n",
    "\n",
    "# Sort by average rating\n",
    "rating_stats_sorted = sorted(rating_stats, key=lambda x: x['avg_rating'], reverse=True)\n",
    "\n",
    "print(\"üìä Films Ranked by Average Rating:\\n\")\n",
    "for i, stat in enumerate(rating_stats_sorted, 1):\n",
    "    print(f\"  {i}. {stat['movie']:25} - {stat['avg_rating']:.2f}/10 (Variance: {stat['rating_variance']:.2f})\")\n",
    "\n",
    "# Identify high performers (avg rating > 7.0)\n",
    "high_performers = [s for s in rating_stats if s['avg_rating'] > 7.0]\n",
    "low_performers = [s for s in rating_stats if s['avg_rating'] < 6.0]\n",
    "\n",
    "print(f\"\\n‚úÖ High Performers (>7.0): {len(high_performers)} films\")\n",
    "for hp in high_performers:\n",
    "    print(f\"   ‚Ä¢ {hp['movie']} - {hp['avg_rating']:.2f}/10\")\n",
    "\n",
    "print(f\"\\n‚ùå Low Performers (<6.0): {len(low_performers)} films\")\n",
    "for lp in low_performers:\n",
    "    print(f\"   ‚Ä¢ {lp['movie']} - {lp['avg_rating']:.2f}/10\")\n",
    "\n",
    "# Extract success patterns\n",
    "print(\"\\nüîç Success Patterns:\")\n",
    "if high_performers:\n",
    "    avg_lover_pct = np.mean([hp['lovers_pct'] for hp in high_performers])\n",
    "    avg_hater_pct = np.mean([hp['haters_pct'] for hp in high_performers])\n",
    "    print(f\"   High performers average: {avg_lover_pct:.1f}% lovers, {avg_hater_pct:.1f}% haters\")\n",
    "\n",
    "if low_performers:\n",
    "    avg_lover_pct_low = np.mean([lp['lovers_pct'] for lp in low_performers])\n",
    "    avg_hater_pct_low = np.mean([lp['haters_pct'] for lp in low_performers])\n",
    "    print(f\"   Low performers average: {avg_lover_pct_low:.1f}% lovers, {avg_hater_pct_low:.1f}% haters\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 2: UNIVERSAL AUDIENCE PATTERNS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Aggregate audience data across all films\n",
    "total_reviews = 0\n",
    "total_lovers = 0\n",
    "total_haters = 0\n",
    "gender_distribution = {'male': 0, 'female': 0, 'unknown': 0}\n",
    "\n",
    "for movie, data in all_movies_data.items():\n",
    "    if 'audience_breakdown' in data['modules']:\n",
    "        mod = data['modules']['audience_breakdown']\n",
    "        total_reviews += mod['total_reviews']\n",
    "        total_lovers += mod['rating_segments']['lovers_8_10']\n",
    "        total_haters += mod['rating_segments']['haters_1_3']\n",
    "        \n",
    "        gender_distribution['male'] += mod['gender_breakdown']['male']\n",
    "        gender_distribution['female'] += mod['gender_breakdown']['female']\n",
    "        gender_distribution['unknown'] += mod['gender_breakdown']['unknown']\n",
    "\n",
    "print(f\"üìä Aggregate Statistics Across {len(all_movies_data)} Films:\\n\")\n",
    "print(f\"   Total Reviews Analyzed: {total_reviews:,}\")\n",
    "print(f\"   Total Lovers (8-10): {total_lovers:,} ({total_lovers/total_reviews*100:.1f}%)\")\n",
    "print(f\"   Total Haters (1-3): {total_haters:,} ({total_haters/total_reviews*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüë• Gender Distribution:\\n\")\n",
    "identified = gender_distribution['male'] + gender_distribution['female']\n",
    "print(f\"   Male: {gender_distribution['male']:,} ({gender_distribution['male']/total_reviews*100:.1f}%)\")\n",
    "print(f\"   Female: {gender_distribution['female']:,} ({gender_distribution['female']/total_reviews*100:.1f}%)\")\n",
    "print(f\"   Unknown: {gender_distribution['unknown']:,} ({gender_distribution['unknown']/total_reviews*100:.1f}%)\")\n",
    "print(f\"   Gender ID Coverage: {identified/total_reviews*100:.1f}%\")\n",
    "\n",
    "# Extract emotion patterns from lovers\n",
    "print(f\"\\nüòä Emotion Patterns (Lovers Across All Films):\\n\")\n",
    "\n",
    "all_lover_emotions = defaultdict(list)\n",
    "for movie, data in all_movies_data.items():\n",
    "    if 'what_resonated' in data['modules']:\n",
    "        emotions = data['modules']['what_resonated']['emotion_profiles']['all_lovers']\n",
    "        for emotion, score in emotions.items():\n",
    "            if score:\n",
    "                all_lover_emotions[emotion].append(score)\n",
    "\n",
    "# Average emotions across all films\n",
    "avg_emotions = {emotion: np.mean(scores) for emotion, scores in all_lover_emotions.items()}\n",
    "sorted_emotions = sorted(avg_emotions.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"   Top 5 Emotions in Positive Reviews:\")\n",
    "for emotion, score in sorted_emotions[:5]:\n",
    "    print(f\"      {emotion.capitalize():12} {score:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 3: POLARIZATION PATTERNS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Get polarization data\n",
    "polar_data = extract_polarization_patterns(all_movies_data)\n",
    "\n",
    "print(\"‚ö° Polarization Levels Across Films:\\n\")\n",
    "for pd in sorted(polar_data, key=lambda x: x['variance'], reverse=True):\n",
    "    print(f\"   {pd['movie']:25} - {pd['level']:20} (Variance: {pd['variance']:.2f})\")\n",
    "\n",
    "# Count polarization levels\n",
    "level_counts = Counter([pd['level'] for pd in polar_data])\n",
    "print(f\"\\nüìä Polarization Distribution:\")\n",
    "for level, count in level_counts.items():\n",
    "    print(f\"   {level}: {count} films ({count/len(polar_data)*100:.1f}%)\")\n",
    "\n",
    "# Temporal shift analysis\n",
    "print(f\"\\nüìÖ Temporal Rating Shifts (Early vs Late Reviews):\\n\")\n",
    "for pd in polar_data:\n",
    "    if pd['temporal_shift']:\n",
    "        direction = \"üìà Improved\" if pd['temporal_shift'] > 0 else \"üìâ Declined\"\n",
    "        print(f\"   {pd['movie']:25} {direction:12} {pd['temporal_shift']:+.2f} points\")\n",
    "\n",
    "# Gender gap analysis\n",
    "print(f\"\\nüë• Gender Rating Gaps:\\n\")\n",
    "for pd in sorted(polar_data, key=lambda x: x['gender_gap'] if x['gender_gap'] else 0, reverse=True):\n",
    "    if pd['gender_gap'] and pd['gender_gap'] > 0.5:\n",
    "        significance = \"‚ö†Ô∏è  Significant\" if pd['gender_gap'] > 1.0 else \"Moderate\"\n",
    "        print(f\"   {pd['movie']:25} {significance:15} {pd['gender_gap']:.2f} point gap\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 4: RISK PATTERNS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Get risk data\n",
    "risk_data = extract_risk_patterns(all_movies_data)\n",
    "\n",
    "print(\"‚ö†Ô∏è  Risk Levels Across Films:\\n\")\n",
    "for rd in sorted(risk_data, key=lambda x: x['risk_score'], reverse=True):\n",
    "    print(f\"   {rd['movie']:25} - {rd['risk_level']:10} (Score: {rd['risk_score']:.1f}/6.0)\")\n",
    "    if rd['high_risks']:\n",
    "        for risk in rd['high_risks']:\n",
    "            print(f\"      üö® {risk}\")\n",
    "\n",
    "# Count common risks\n",
    "all_high_risks = []\n",
    "for rd in risk_data:\n",
    "    all_high_risks.extend(rd['high_risks'])\n",
    "\n",
    "risk_frequency = Counter(all_high_risks)\n",
    "print(f\"\\nüìä Most Common HIGH Risk Factors:\\n\")\n",
    "if risk_frequency:\n",
    "    for risk, count in risk_frequency.most_common():\n",
    "        print(f\"   {risk:30} - {count} films ({count/len(risk_data)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"   No HIGH risk factors identified across films\")\n",
    "\n",
    "# Extract risk quotes\n",
    "print(f\"\\nüí¨ Sample Risk Evidence (Complexity Barrier):\\n\")\n",
    "complexity_quotes = []\n",
    "for movie, data in all_movies_data.items():\n",
    "    if 'risk_factors' in data['modules']:\n",
    "        if 'complexity_risk' in data['modules']['risk_factors']:\n",
    "            complexity = data['modules']['risk_factors']['complexity_risk']\n",
    "            if complexity['risk_level'] == 'HIGH' and complexity.get('sample_quotes'):\n",
    "                quote = complexity['sample_quotes'][0]\n",
    "                quote['source_movie'] = movie\n",
    "                complexity_quotes.append(quote)\n",
    "\n",
    "for i, quote in enumerate(complexity_quotes[:3], 1):\n",
    "    print(f\"   {i}. {quote['source_movie']} - {quote['reviewer']} ({quote['rating']}/10):\")\n",
    "    print(f\"      \\\"{quote['quote'][:150]}...\\\"\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 5: MARKETING STRATEGY INSIGHTS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Analyze temporal sentiment shifts (indicator of marketing alignment)\n",
    "print(\"üìä Marketing Effectiveness (Temporal Shift Analysis):\\n\")\n",
    "\n",
    "improved_films = []\n",
    "declined_films = []\n",
    "\n",
    "for pd in polar_data:\n",
    "    if pd['temporal_shift']:\n",
    "        if pd['temporal_shift'] > 1.0:\n",
    "            improved_films.append((pd['movie'], pd['temporal_shift']))\n",
    "        elif pd['temporal_shift'] < -0.5:\n",
    "            declined_films.append((pd['movie'], pd['temporal_shift']))\n",
    "\n",
    "if improved_films:\n",
    "    print(\"‚úÖ Films That Found Their Audience (Improved Over Time):\\n\")\n",
    "    for movie, shift in sorted(improved_films, key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   {movie:25} +{shift:.2f} points (late reviews better)\")\n",
    "        \n",
    "    print(\"\\n   üí° Interpretation: These films likely had misaligned initial marketing\")\n",
    "    print(\"      but found their true audience through word-of-mouth.\\n\")\n",
    "\n",
    "if declined_films:\n",
    "    print(\"‚ùå Films That Lost Momentum (Declined Over Time):\\n\")\n",
    "    for movie, shift in sorted(declined_films, key=lambda x: x[1]):\n",
    "        print(f\"   {movie:25} {shift:.2f} points (late reviews worse)\")\n",
    "    print()\n",
    "\n",
    "# Early negative buzz analysis\n",
    "print(\"‚ö†Ô∏è  Early Negative Buzz Patterns:\\n\")\n",
    "\n",
    "early_buzz_issues = []\n",
    "for movie, data in all_movies_data.items():\n",
    "    if 'risk_factors' in data['modules']:\n",
    "        if 'early_buzz_risk' in data['modules']['risk_factors']:\n",
    "            buzz = data['modules']['risk_factors']['early_buzz_risk']\n",
    "            if buzz['risk_level'] in ['HIGH', 'MODERATE']:\n",
    "                early_buzz_issues.append({\n",
    "                    'movie': movie,\n",
    "                    'level': buzz['risk_level'],\n",
    "                    'negative_pct': buzz['early_negative_pct']\n",
    "                })\n",
    "\n",
    "for issue in sorted(early_buzz_issues, key=lambda x: x['negative_pct'] if x['negative_pct'] else 0, reverse=True):\n",
    "    print(f\"   {issue['movie']:25} {issue['level']:10} ({issue['negative_pct']:.1f}% early negative)\")\n",
    "\n",
    "print(\"\\n   üí° Recommendation: Films with high early negative buzz need:\")\n",
    "print(\"      ‚Ä¢ Festival circuit first (build critical support)\")\n",
    "print(\"      ‚Ä¢ Platform release (not wide theatrical)\")\n",
    "print(\"      ‚Ä¢ Accurate marketing (set correct expectations)\\n\")\n",
    "\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING SYNTHESIS REPORT\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "synthesis_report = {\n",
    "    'report_date': datetime.now().isoformat(),\n",
    "    'total_movies_analyzed': len(all_movies_data),\n",
    "    'total_reviews_analyzed': total_reviews,\n",
    "    \n",
    "    'key_findings': {\n",
    "        'success_factors': {\n",
    "            'high_performers': len(high_performers),\n",
    "            'avg_lover_percentage': np.mean([hp['lovers_pct'] for hp in high_performers]) if high_performers else None,\n",
    "            'interpretation': \"High-performing folk horror films maintain 50%+ lover rate despite polarization\"\n",
    "        },\n",
    "        \n",
    "        'audience_profile': {\n",
    "            'total_engaged_viewers': total_reviews,\n",
    "            'lover_rate': f\"{total_lovers/total_reviews*100:.1f}%\",\n",
    "            'hater_rate': f\"{total_haters/total_reviews*100:.1f}%\",\n",
    "            'gender_skew': 'male' if gender_distribution['male'] > gender_distribution['female'] * 2 else 'balanced',\n",
    "            'male_percentage': f\"{gender_distribution['male']/total_reviews*100:.1f}%\",\n",
    "            'female_percentage': f\"{gender_distribution['female']/total_reviews*100:.1f}%\",\n",
    "            'top_emotions': [emotion for emotion, score in sorted_emotions[:3]]\n",
    "        },\n",
    "        \n",
    "        'polarization_insights': {\n",
    "            'highly_polarizing_count': level_counts.get('HIGHLY_POLARIZING', 0),\n",
    "            'consensus_count': level_counts.get('CONSENSUS', 0),\n",
    "            'films_that_improved': len(improved_films),\n",
    "            'interpretation': \"Folk horror is inherently polarizing - 50% of films are HIGHLY_POLARIZING\"\n",
    "        },\n",
    "        \n",
    "        'risk_factors': {\n",
    "            'most_common_risk': risk_frequency.most_common(1)[0][0] if risk_frequency else 'None',\n",
    "            'risk_frequency': dict(risk_frequency),\n",
    "            'interpretation': \"Complexity barrier is the primary risk - arthouse positioning is critical\"\n",
    "        },\n",
    "        \n",
    "        'marketing_recommendations': {\n",
    "            'festival_first': len([f for f in improved_films if f[1] > 1.5]),\n",
    "            'platform_release_candidates': len(early_buzz_issues),\n",
    "            'key_insight': \"Films that improved over time needed better initial positioning\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save synthesis report\n",
    "synthesis_file = Path('../insights/module_9_synthesis.json')\n",
    "with open(synthesis_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(synthesis_report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ Synthesis report saved: {synthesis_file}\")\n",
    "print(f\"\\nüìä Key Metrics Summary:\")\n",
    "print(f\"   ‚Ä¢ {len(all_movies_data)} movies analyzed\")\n",
    "print(f\"   ‚Ä¢ {total_reviews:,} total reviews\")\n",
    "print(f\"   ‚Ä¢ {len(high_performers)} high performers identified\")\n",
    "print(f\"   ‚Ä¢ {len(risk_frequency)} unique risk factors found\")\n",
    "print(f\"   ‚Ä¢ {len(improved_films)} films improved over time\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXECUTIVE SUMMARY: FOLK HORROR LANDSCAPE\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"üìå KEY FINDINGS:\\n\")\n",
    "\n",
    "print(\"1. AUDIENCE SIZE & ENGAGEMENT\")\n",
    "print(f\"   ‚Ä¢ {total_reviews:,} reviews across 10 films\")\n",
    "print(f\"   ‚Ä¢ {total_lovers/total_reviews*100:.1f}% are lovers (8-10 rating)\")\n",
    "print(f\"   ‚Ä¢ {total_haters/total_reviews*100:.1f}% are haters (1-3 rating)\")\n",
    "print(f\"   ‚Ä¢ Genre is HIGHLY POLARIZING by nature\\n\")\n",
    "\n",
    "print(\"2. AUDIENCE DEMOGRAPHICS\")\n",
    "print(f\"   ‚Ä¢ {gender_distribution['male']/total_reviews*100:.1f}% male skew\")\n",
    "print(f\"   ‚Ä¢ {gender_distribution['female']/total_reviews*100:.1f}% female\")\n",
    "print(f\"   ‚Ä¢ Top emotions: {', '.join([e for e, _ in sorted_emotions[:3]])}\")\n",
    "print(f\"   ‚Ä¢ Sophisticated viewers (higher reading grades)\\n\")\n",
    "\n",
    "print(\"3. SUCCESS PATTERNS\")\n",
    "if high_performers:\n",
    "    print(f\"   ‚Ä¢ High performers maintain ~{np.mean([hp['lovers_pct'] for hp in high_performers]):.0f}% lover rate\")\n",
    "    print(\"   ‚Ä¢ Films that succeed:\")\n",
    "    for hp in high_performers[:3]:\n",
    "        print(f\"     - {hp['movie']} ({hp['avg_rating']:.1f}/10)\")\n",
    "print()\n",
    "\n",
    "print(\"4. COMMON RISKS\")\n",
    "if risk_frequency:\n",
    "    print(f\"   ‚Ä¢ Most common: {risk_frequency.most_common(1)[0][0]}\")\n",
    "    print(\"   ‚Ä¢ Affects: \" + \", \".join([rd['movie'] for rd in risk_data if risk_frequency.most_common(1)[0][0] in rd['high_risks']]))\n",
    "print()\n",
    "\n",
    "print(\"5. MARKETING INSIGHTS\")\n",
    "if improved_films:\n",
    "    print(f\"   ‚Ä¢ {len(improved_films)} films improved +1.0 points over time\")\n",
    "    print(\"   ‚Ä¢ Indicates initial marketing misalignment\")\n",
    "    print(\"   ‚Ä¢ Festival-first strategy works better\")\n",
    "print()\n",
    "\n",
    "print(\"6. POSITIONING IMPLICATIONS FOR 'ROOTS'\")\n",
    "print(\"   ‚Ä¢ Target arthouse horror audience (not mainstream)\")\n",
    "print(\"   ‚Ä¢ Expect 50%+ polarization (this is normal for genre)\")\n",
    "print(\"   ‚Ä¢ Platform release > wide theatrical\")\n",
    "print(\"   ‚Ä¢ Build through festivals and critics first\")\n",
    "print(\"   ‚Ä¢ Male-skewing but sophisticated audience\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"‚úÖ Module 9 Complete!\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
