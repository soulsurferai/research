{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8b3ea58-335d-4ced-864e-8ad4ee2f9989",
   "metadata": {},
   "source": [
    "# Insights "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "68693251-d5e7-44b8-bc8b-e76961670d68",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Library Imports"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc936cf3-8606-43b6-9bf5-9d8a94eb4051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "from scipy.stats import (\n",
    "    ttest_ind, f_oneway, chi2_contingency, \n",
    "    pearsonr, spearmanr, shapiro, levene\n",
    ")\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_squared_error, classification_report,\n",
    "    confusion_matrix, roc_auc_score, silhouette_score\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b222e78-8189-49e2-a94c-7ea19000e14f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load Data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1287240e-8ba9-488b-bd4f-0bfefc4a2e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the enhanced reviews dataset\n",
    "data_path = '/Users/jamesroot/Desktop/JAMES/Noetheca/Reviews/Data/reviews_enhanced.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"✅ Data loaded successfully\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a2f0e2-56f3-4810-b1ab-741e84fe0439",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Collection and Overview"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f5366f-92eb-440f-bd2a-4d69d0e75662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset info\n",
    "print(\"=\"*80)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal reviews: {len(df):,}\")\n",
    "print(f\"Total features: {len(df.columns)}\")\n",
    "print(f\"Movies: {df['Movie_Title'].nunique()}\")\n",
    "\n",
    "# Convert Review_Date to datetime if it's a string\n",
    "if df['Review_Date'].dtype == 'object':\n",
    "    df['Review_Date'] = pd.to_datetime(df['Review_Date'], errors='coerce')\n",
    "    \n",
    "print(f\"Date range: {df['Review_Date'].min()} to {df['Review_Date'].max()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MISSING DATA SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing[missing > 0],\n",
    "    'Missing_Pct': missing_pct[missing > 0]\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(\"No missing data found!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA TYPES\")\n",
    "print(\"=\"*80)\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7e435-272d-4d66-8e30-fa121f32ebff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Classify features by type"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d38f02b-ef38-4dea-883c-7444314dfb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify features by type\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove ID and non-analytic columns\n",
    "exclude_cols = [\n",
    "    'Review_ID', 'Review_Text', 'Reviewer', 'Review_Date', 'Movie_Title', \n",
    "    'Review_Title', 'Source', 'username_gender_hint', 'username_age_hint',\n",
    "    'username_interests', 'username_patterns', 'movies_mentioned', \n",
    "    'comparison_context', 'love_statements', 'hate_statements', \n",
    "    'wish_statements', 'questions', 'review_window'\n",
    "]\n",
    "numeric_features = [col for col in numeric_features if col not in exclude_cols]\n",
    "categorical_features = [col for col in categorical_features if col not in exclude_cols]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE CLASSIFICATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nNumeric features ({len(numeric_features)}):\")\n",
    "for i in range(0, len(numeric_features), 5):\n",
    "    print(numeric_features[i:i+5])\n",
    "\n",
    "print(f\"\\nCategorical features ({len(categorical_features)}):\")\n",
    "print(categorical_features)\n",
    "\n",
    "# Store for later use\n",
    "print(f\"\\n✅ Identified {len(numeric_features)} numeric and {len(categorical_features)} categorical features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5322c395-4e3a-4e7d-8c8b-2f435da47388",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Target Variables"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7644cb85-6475-4a96-871e-ad15a753d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key outcome variables for analysis\n",
    "print(\"=\"*80)\n",
    "print(\"TARGET VARIABLES FOR ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Primary outcome: Rating\n",
    "print(f\"\\nRating distribution:\")\n",
    "print(df['Rating'].describe())\n",
    "\n",
    "# Create binary outcome: High performer (>7.0)\n",
    "df['high_performer'] = (df['Rating'] > 7.0).astype(int)\n",
    "print(f\"\\nHigh performers (>7.0): {df['high_performer'].sum()} ({df['high_performer'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Create polarization indicator\n",
    "df['is_polarizing'] = ((df['love_count'] > 0) & (df['hate_count'] > 0)).astype(int)\n",
    "print(f\"Polarizing reviews: {df['is_polarizing'].sum()} ({df['is_polarizing'].mean()*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n✅ Target variables defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4468660a-a251-4912-82a3-db90fa793c60",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Movie Level Aggregation "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5340fd97-db11-4107-b062-85667fdff1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create movie-level summary statistics for cross-movie analysis\n",
    "movie_stats = df.groupby('Movie_Title').agg({\n",
    "    'Rating': ['mean', 'std', 'count'],\n",
    "    'love_count': 'mean',\n",
    "    'hate_count': 'mean',\n",
    "    'vader_compound': 'mean',\n",
    "    'total_votes': 'sum',\n",
    "    'high_performer': 'mean',\n",
    "    'is_polarizing': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "# Flatten column names\n",
    "movie_stats.columns = ['_'.join(col).strip() for col in movie_stats.columns.values]\n",
    "movie_stats = movie_stats.reset_index()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MOVIE-LEVEL SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(movie_stats.to_string())\n",
    "\n",
    "print(\"\\n✅ Movie-level data aggregated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a1be6a-4feb-4215-930a-f6504122090f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Correlation Matrix Predictors"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04290479-1a3a-4379-a25c-b373c8a51226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis: Which features correlate with Rating?\n",
    "print(\"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS: RATING PREDICTORS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate correlations with Rating\n",
    "correlations = df[numeric_features].corr()['Rating'].sort_values(ascending=False)\n",
    "\n",
    "# Remove Rating's self-correlation\n",
    "correlations = correlations.drop('Rating')\n",
    "\n",
    "print(\"\\nTop 20 Positive Correlations with Rating:\")\n",
    "print(correlations.head(20))\n",
    "\n",
    "print(\"\\nTop 20 Negative Correlations with Rating:\")\n",
    "print(correlations.tail(20))\n",
    "\n",
    "# Statistical significance test for top correlations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL SIGNIFICANCE OF TOP CORRELATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_features = list(correlations.head(10).index) + list(correlations.tail(10).index)\n",
    "\n",
    "for feature in top_features:\n",
    "    r, p_value = pearsonr(df[feature].dropna(), df.loc[df[feature].notna(), 'Rating'])\n",
    "    significance = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"ns\"\n",
    "    print(f\"{feature:30s} r={r:6.3f}, p={p_value:.4e} {significance}\")\n",
    "\n",
    "print(\"\\n✅ Correlation analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed68ec5-ceba-438b-b9f3-84eb743ed3c7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Visualize top correlations"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b02f46-b59e-4d47-9612-f6b390b36017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top correlations\n",
    "print(\"=\"*80)\n",
    "print(\"VISUALIZATION: TOP 15 RATING CORRELATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get top 15 positive and negative (exclude NaN)\n",
    "correlations_clean = correlations.dropna()\n",
    "top_pos = correlations_clean.head(15)\n",
    "top_neg = correlations_clean.tail(15)\n",
    "top_combined = pd.concat([top_pos, top_neg])\n",
    "\n",
    "# Create horizontal bar plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['green' if x > 0 else 'red' for x in top_combined.values]\n",
    "plt.barh(range(len(top_combined)), top_combined.values, color=colors, alpha=0.6)\n",
    "plt.yticks(range(len(top_combined)), top_combined.index, fontsize=9)\n",
    "plt.xlabel('Correlation with Rating', fontsize=11)\n",
    "plt.title('Top Features Correlated with Rating', fontsize=13, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3015b7-cf16-49b1-8f23-ad65cd60fcc6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Linear Regression to Predict Rating"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f4c79-102e-4786-b89b-53b897178420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple linear regression to predict Rating\n",
    "print(\"=\"*80)\n",
    "print(\"LINEAR REGRESSION: PREDICTING RATING FROM ALL FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare features - EXCLUDE Rating and derived variables\n",
    "features_to_exclude = ['Rating', 'high_performer', 'is_polarizing']\n",
    "predictor_features = [f for f in numeric_features if f not in features_to_exclude]\n",
    "\n",
    "print(f\"Using {len(predictor_features)} predictor features (excluded: {features_to_exclude})\")\n",
    "\n",
    "# Prepare data - remove rows with missing values\n",
    "X = df[predictor_features].dropna()\n",
    "y = df.loc[X.index, 'Rating']\n",
    "\n",
    "print(f\"Sample size: n={len(X):,} reviews\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "\n",
    "# Model performance\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"  Training R² = {train_r2:.4f}\")\n",
    "print(f\"  Test R² = {test_r2:.4f}\")\n",
    "print(f\"  Training RMSE = {train_rmse:.4f}\")\n",
    "print(f\"  Test RMSE = {test_rmse:.4f}\")\n",
    "\n",
    "# Feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': predictor_features,\n",
    "    'Coefficient': lr.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features (by |coefficient|):\")\n",
    "print(feature_importance.head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\n✅ Linear regression complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9aa18-3923-4d01-9099-c89fc4cbe132",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ridge Regression to handle multicollinearity"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc902f0-6391-4702-9b45-16d5953a677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression to handle multicollinearity\n",
    "print(\"=\"*80)\n",
    "print(\"RIDGE REGRESSION: REGULARIZED PREDICTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use the same predictor features (excluding Rating)\n",
    "X = df[predictor_features].dropna()\n",
    "y = df.loc[X.index, 'Rating']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Ridge regression with cross-validation\n",
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "ridge_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    scores = cross_val_score(ridge, X_scaled, y, cv=5, scoring='r2')\n",
    "    ridge_scores.append(scores.mean())\n",
    "    print(f\"Alpha={alpha:6.3f}: Mean R² = {scores.mean():.4f} (±{scores.std():.4f})\")\n",
    "\n",
    "# Best alpha\n",
    "best_alpha = alphas[np.argmax(ridge_scores)]\n",
    "print(f\"\\nBest alpha: {best_alpha}\")\n",
    "\n",
    "# Fit final model with train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "ridge_final = Ridge(alpha=best_alpha)\n",
    "ridge_final.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ridge = ridge_final.predict(X_test)\n",
    "ridge_r2 = r2_score(y_test, y_pred_ridge)\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
    "\n",
    "print(f\"\\nFinal Ridge Model Performance:\")\n",
    "print(f\"  Test R² = {ridge_r2:.4f}\")\n",
    "print(f\"  Test RMSE = {ridge_rmse:.4f}\")\n",
    "\n",
    "print(\"\\n✅ Ridge regression complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff332626-c0c7-469a-9883-4231707ecd57",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## K-Means clustering"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98658a-d029-4f9a-8058-5b948a74402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means clustering to identify audience segments\n",
    "print(\"=\"*80)\n",
    "print(\"K-MEANS CLUSTERING: AUDIENCE SEGMENTATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select features for clustering (sentiment, emotions, engagement)\n",
    "cluster_features = [\n",
    "    'vader_compound', 'vader_pos', 'vader_neg',\n",
    "    'emotion_joy', 'emotion_trust', 'emotion_fear', 'emotion_surprise',\n",
    "    'emotion_sadness', 'emotion_disgust', 'emotion_anger', 'emotion_anticipation',\n",
    "    'love_count', 'hate_count', 'wish_count',\n",
    "    'total_votes', 'helpfulness_ratio',\n",
    "    'flesch_reading_ease', 'exclamation_count'\n",
    "]\n",
    "\n",
    "# Prepare data\n",
    "X_cluster = df[cluster_features].dropna()\n",
    "print(f\"Sample size: n={len(X_cluster):,} reviews\")\n",
    "print(f\"Clustering on {len(cluster_features)} features\")\n",
    "\n",
    "# Standardize\n",
    "scaler_cluster = StandardScaler()\n",
    "X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)\n",
    "\n",
    "# Test different numbers of clusters\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_cluster_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    sil_score = silhouette_score(X_cluster_scaled, kmeans.labels_)\n",
    "    silhouette_scores.append(sil_score)\n",
    "    print(f\"k={k}: Inertia={kmeans.inertia_:.2f}, Silhouette={sil_score:.4f}\")\n",
    "\n",
    "print(\"\\n✅ Clustering analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792034ce-5039-4568-9e2e-d17979937ff4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fit Optimal Clustering"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed21837f-c1d9-4de9-ab11-99a0a7a256e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit optimal clustering solution (k=3)\n",
    "print(\"=\"*80)\n",
    "print(\"3-CLUSTER SOLUTION: AUDIENCE SEGMENT PROFILES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "kmeans_final = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans_final.fit_predict(X_cluster_scaled)\n",
    "\n",
    "# Add cluster labels to dataframe\n",
    "df_clustered = df.loc[X_cluster.index].copy()\n",
    "df_clustered['cluster'] = cluster_labels\n",
    "\n",
    "print(f\"Cluster sizes:\")\n",
    "print(df_clustered['cluster'].value_counts().sort_index())\n",
    "\n",
    "# Profile each cluster\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLUSTER PROFILES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for cluster_id in range(3):\n",
    "    cluster_data = df_clustered[df_clustered['cluster'] == cluster_id]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CLUSTER {cluster_id} (n={len(cluster_data)})\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Key statistics\n",
    "    print(f\"\\nRating: {cluster_data['Rating'].mean():.2f} (±{cluster_data['Rating'].std():.2f})\")\n",
    "    print(f\"Sentiment (vader_compound): {cluster_data['vader_compound'].mean():.3f}\")\n",
    "    print(f\"Love count: {cluster_data['love_count'].mean():.2f}\")\n",
    "    print(f\"Hate count: {cluster_data['hate_count'].mean():.2f}\")\n",
    "    print(f\"Total votes: {cluster_data['total_votes'].mean():.1f}\")\n",
    "    \n",
    "    # Emotions\n",
    "    print(f\"\\nTop emotions:\")\n",
    "    emotion_cols = ['emotion_joy', 'emotion_trust', 'emotion_fear', 'emotion_surprise',\n",
    "                    'emotion_sadness', 'emotion_disgust', 'emotion_anger', 'emotion_anticipation']\n",
    "    emotion_means = cluster_data[emotion_cols].mean().sort_values(ascending=False)\n",
    "    for emotion, value in emotion_means.head(3).items():\n",
    "        print(f\"  {emotion}: {value:.3f}\")\n",
    "    \n",
    "    # Gender distribution\n",
    "    if 'username_gender_hint' in cluster_data.columns:\n",
    "        gender_dist = cluster_data['username_gender_hint'].value_counts(normalize=True)\n",
    "        print(f\"\\nGender distribution:\")\n",
    "        for gender, pct in gender_dist.items():\n",
    "            if gender in ['male', 'female']:\n",
    "                print(f\"  {gender}: {pct*100:.1f}%\")\n",
    "    \n",
    "    # High performers\n",
    "    if 'high_performer' in cluster_data.columns:\n",
    "        high_perf_pct = cluster_data['high_performer'].mean() * 100\n",
    "        print(f\"\\nHigh performers (>7.0): {high_perf_pct:.1f}%\")\n",
    "\n",
    "print(\"\\n✅ Cluster profiling complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ef7d4-7846-40b8-bbd5-b2af0889b9e8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Principle Component Analysis"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f54a1a-5061-44a4-81ac-e5fa8aa88bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis\n",
    "print(\"=\"*80)\n",
    "print(\"PRINCIPAL COMPONENT ANALYSIS (PCA)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use all numeric predictors\n",
    "X_pca = df[predictor_features].dropna()\n",
    "print(f\"Sample size: n={len(X_pca):,}\")\n",
    "\n",
    "# Standardize\n",
    "scaler_pca = StandardScaler()\n",
    "X_pca_scaled = scaler_pca.fit_transform(X_pca)\n",
    "\n",
    "# Fit PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_pca_scaled)\n",
    "\n",
    "# Variance explained\n",
    "variance_explained = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(variance_explained)\n",
    "\n",
    "print(f\"\\nVariance explained by first 10 components:\")\n",
    "for i in range(10):\n",
    "    print(f\"  PC{i+1}: {variance_explained[i]*100:.2f}% (cumulative: {cumulative_variance[i]*100:.2f}%)\")\n",
    "\n",
    "# How many components for 80% variance?\n",
    "n_components_80 = np.argmax(cumulative_variance >= 0.80) + 1\n",
    "print(f\"\\nComponents needed for 80% variance: {n_components_80}\")\n",
    "\n",
    "# Scree plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, 21), variance_explained[:20], 'bo-')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.title('Scree Plot')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, 21), cumulative_variance[:20], 'ro-')\n",
    "plt.axhline(y=0.80, color='g', linestyle='--', label='80% threshold')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Variance Explained')\n",
    "plt.title('Cumulative Variance')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ PCA complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1fe47-cb1b-4719-84b1-66ca1991d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the top principal components\n",
    "print(\"=\"*80)\n",
    "print(\"INTERPRETING TOP PRINCIPAL COMPONENTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Refit PCA with first 5 components for interpretation\n",
    "pca_5 = PCA(n_components=5)\n",
    "pca_5.fit(X_pca_scaled)\n",
    "\n",
    "# Get loadings\n",
    "loadings = pd.DataFrame(\n",
    "    pca_5.components_.T,\n",
    "    columns=[f'PC{i+1}' for i in range(5)],\n",
    "    index=predictor_features\n",
    ")\n",
    "\n",
    "# Show top features for each component\n",
    "for i in range(5):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PC{i+1} - {variance_explained[i]*100:.2f}% variance\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    component_loadings = loadings[f'PC{i+1}'].abs().sort_values(ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Features:\")\n",
    "    for feature in component_loadings.head(10).index:\n",
    "        loading = loadings.loc[feature, f'PC{i+1}']\n",
    "        print(f\"  {feature:30s} {loading:7.3f}\")\n",
    "\n",
    "print(\"\\n✅ PCA interpretation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b61ca6f-4cd6-4e30-b9ab-0d2f60ab2ce8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Logistic regression what predicts performance?"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6790c2-ffd1-452c-aa9e-f16d1b6bc00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression: What predicts high performance (>7.0)?\n",
    "print(\"=\"*80)\n",
    "print(\"LOGISTIC REGRESSION: PREDICTING HIGH PERFORMERS (>7.0)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare data\n",
    "X_log = df[predictor_features].dropna()\n",
    "y_log = df.loc[X_log.index, 'high_performer']\n",
    "\n",
    "print(f\"Sample size: n={len(X_log):,}\")\n",
    "print(f\"High performers: {y_log.sum()} ({y_log.mean()*100:.1f}%)\")\n",
    "\n",
    "# Train/test split\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(\n",
    "    X_log, y_log, test_size=0.2, random_state=42, stratify=y_log\n",
    ")\n",
    "\n",
    "# Standardize\n",
    "scaler_log = StandardScaler()\n",
    "X_train_scaled = scaler_log.fit_transform(X_train_log)\n",
    "X_test_scaled = scaler_log.transform(X_test_log)\n",
    "\n",
    "# Fit logistic regression\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train_scaled, y_train_log)\n",
    "\n",
    "# Predictions\n",
    "y_pred_log = logreg.predict(X_test_scaled)\n",
    "y_pred_proba = logreg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_test_log, y_pred_log)\n",
    "precision = precision_score(y_test_log, y_pred_log)\n",
    "recall = recall_score(y_test_log, y_pred_log)\n",
    "f1 = f1_score(y_test_log, y_pred_log)\n",
    "auc = roc_auc_score(y_test_log, y_pred_proba)\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1-Score:  {f1:.4f}\")\n",
    "print(f\"  AUC-ROC:   {auc:.4f}\")\n",
    "\n",
    "# Feature importance (odds ratios)\n",
    "odds_ratios = np.exp(logreg.coef_[0])\n",
    "feature_importance_log = pd.DataFrame({\n",
    "    'Feature': predictor_features,\n",
    "    'Coefficient': logreg.coef_[0],\n",
    "    'Odds_Ratio': odds_ratios\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Features (by |coefficient|):\")\n",
    "print(feature_importance_log.head(15).to_string(index=False))\n",
    "\n",
    "print(\"\\n✅ Logistic regression complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75918ade-eb22-4337-bbbd-34f163908204",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Random Forest"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf5dd6b-4411-41ce-8079-8ef4fced37d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest for high performer prediction\n",
    "print(\"=\"*80)\n",
    "print(\"RANDOM FOREST: PREDICTING HIGH PERFORMERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use same train/test split\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf.fit(X_train_log, y_train_log)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf.predict(X_test_log)\n",
    "y_pred_proba_rf = rf.predict_proba(X_test_log)[:, 1]\n",
    "\n",
    "# Performance\n",
    "accuracy_rf = accuracy_score(y_test_log, y_pred_rf)\n",
    "precision_rf = precision_score(y_test_log, y_pred_rf)\n",
    "recall_rf = recall_score(y_test_log, y_pred_rf)\n",
    "f1_rf = f1_score(y_test_log, y_pred_rf)\n",
    "auc_rf = roc_auc_score(y_test_log, y_pred_proba_rf)\n",
    "\n",
    "print(f\"\\nRandom Forest Performance:\")\n",
    "print(f\"  Accuracy:  {accuracy_rf:.4f}\")\n",
    "print(f\"  Precision: {precision_rf:.4f}\")\n",
    "print(f\"  Recall:    {recall_rf:.4f}\")\n",
    "print(f\"  F1-Score:  {f1_rf:.4f}\")\n",
    "print(f\"  AUC-ROC:   {auc_rf:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'Feature': predictor_features,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "print(feature_importance_rf.head(20).to_string(index=False))\n",
    "\n",
    "# Visualize top 15\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_15_features = feature_importance_rf.head(15)\n",
    "plt.barh(range(len(top_15_features)), top_15_features['Importance'], alpha=0.7)\n",
    "plt.yticks(range(len(top_15_features)), top_15_features['Feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Random Forest: Top 15 Feature Importances', fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Random Forest complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902c9448-424f-4c2a-b21f-ce8151401d69",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Statistical Hypothesis testing"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136eaa56-5d9f-4d09-906e-35ba58190eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical hypothesis testing\n",
    "print(\"=\"*80)\n",
    "print(\"STATISTICAL HYPOTHESIS TESTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test 1: Gender differences in ratings\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST 1: GENDER DIFFERENCES IN RATINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "male_ratings = df[df['username_gender_hint'] == 'male']['Rating'].dropna()\n",
    "female_ratings = df[df['username_gender_hint'] == 'female']['Rating'].dropna()\n",
    "\n",
    "print(f\"Male reviewers: n={len(male_ratings)}, mean={male_ratings.mean():.2f}, SD={male_ratings.std():.2f}\")\n",
    "print(f\"Female reviewers: n={len(female_ratings)}, mean={female_ratings.mean():.2f}, SD={female_ratings.std():.2f}\")\n",
    "\n",
    "# Independent t-test\n",
    "t_stat, p_value = ttest_ind(male_ratings, female_ratings)\n",
    "cohens_d = (male_ratings.mean() - female_ratings.mean()) / np.sqrt(\n",
    "    ((len(male_ratings)-1)*male_ratings.std()**2 + (len(female_ratings)-1)*female_ratings.std()**2) / \n",
    "    (len(male_ratings) + len(female_ratings) - 2)\n",
    ")\n",
    "\n",
    "print(f\"\\nIndependent t-test:\")\n",
    "print(f\"  t({len(male_ratings)+len(female_ratings)-2}) = {t_stat:.4f}\")\n",
    "print(f\"  p = {p_value:.4f} {'***' if p_value < 0.001 else '**' if p_value < 0.01 else '*' if p_value < 0.05 else 'ns'}\")\n",
    "print(f\"  Cohen's d = {cohens_d:.4f}\")\n",
    "print(f\"  Effect size: {'negligible' if abs(cohens_d) < 0.2 else 'small' if abs(cohens_d) < 0.5 else 'medium' if abs(cohens_d) < 0.8 else 'large'}\")\n",
    "\n",
    "# Test 2: Temporal trends - do ratings change over time windows?\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST 2: RATINGS BY REVIEW WINDOW (ANOVA)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "window_groups = []\n",
    "window_labels = []\n",
    "for window in df['review_window'].dropna().unique():\n",
    "    window_ratings = df[df['review_window'] == window]['Rating'].dropna()\n",
    "    if len(window_ratings) > 0:\n",
    "        window_groups.append(window_ratings)\n",
    "        window_labels.append(window)\n",
    "        print(f\"{window}: n={len(window_ratings)}, mean={window_ratings.mean():.2f}, SD={window_ratings.std():.2f}\")\n",
    "\n",
    "# One-way ANOVA\n",
    "f_stat, p_value_anova = f_oneway(*window_groups)\n",
    "print(f\"\\nOne-way ANOVA:\")\n",
    "print(f\"  F({len(window_groups)-1}, {sum(len(g) for g in window_groups)-len(window_groups)}) = {f_stat:.4f}\")\n",
    "print(f\"  p = {p_value_anova:.4e} {'***' if p_value_anova < 0.001 else '**' if p_value_anova < 0.01 else '*' if p_value_anova < 0.05 else 'ns'}\")\n",
    "\n",
    "# Test 3: Sentiment vs Rating correlation by movie\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST 3: SENTIMENT-RATING CORRELATION BY MOVIE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for movie in df['Movie_Title'].unique()[:5]:  # First 5 movies\n",
    "    movie_data = df[df['Movie_Title'] == movie]\n",
    "    if len(movie_data) > 30:\n",
    "        r, p = pearsonr(movie_data['vader_compound'].dropna(), \n",
    "                       movie_data.loc[movie_data['vader_compound'].notna(), 'Rating'])\n",
    "        print(f\"{movie:30s} r={r:.3f}, p={p:.4e}, n={len(movie_data)}\")\n",
    "\n",
    "print(\"\\n✅ Statistical tests complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f1497-1df5-4955-8707-aa3cbc509db8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Actionable Insights"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8cb4e-48d5-4c91-9128-40f2ba9c3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate actionable insights for \"Roots\" positioning\n",
    "print(\"=\"*80)\n",
    "print(\"ACTIONABLE INSIGHTS FOR 'ROOTS' POSITIONING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Key findings summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. RATING PREDICTORS (R² = 0.26)\")\n",
    "print(\"=\"*80)\n",
    "print(\"✓ Positive sentiment (vader_compound) is THE strongest predictor (r=0.264)\")\n",
    "print(\"✓ Complex vocabulary increases ratings (syllable_count OR=2.13)\")\n",
    "print(\"✓ Fear emotion is POSITIVE for folk horror (OR=1.32)\")\n",
    "print(\"✓ Hate statements tank ratings (r=-0.141)\")\n",
    "print(\"✓ Questions/wishes indicate dissatisfaction (both negative)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. AUDIENCE SEGMENTS (3 CLUSTERS)\")\n",
    "print(\"=\"*80)\n",
    "print(\"✓ The Lovers (52%): Rating 6.89, positive sentiment (+0.699)\")\n",
    "print(\"✓ The Conflicted Critics (44%): Rating 6.07, negative sentiment (-0.404)\")\n",
    "print(\"✓ The Haters (4%): Rating 4.47, hate statements (1.10 per review)\")\n",
    "print(\"\\n→ TARGET: The Lovers (largest, highest ratings)\")\n",
    "print(\"→ CONVERT: The Conflicted Critics (reachable with right messaging)\")\n",
    "print(\"→ AVOID: Don't trigger The Haters (disgust, misleading marketing)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. TEMPORAL DYNAMICS (F=48.82, p<0.001)\")\n",
    "print(\"=\"*80)\n",
    "print(\"✓ 5+ Years: 7.48 rating (HIGHEST - legacy effect)\")\n",
    "print(\"✓ Years 4-5: 7.23 rating (positive momentum)\")\n",
    "print(\"✓ Opening Year: 6.06 rating (mixed initial reception)\")\n",
    "print(\"✓ Years 2-3: 5.94-6.10 (LOWEST - backlash period)\")\n",
    "print(\"\\n→ STRATEGY: Position for long-term legacy, not just opening weekend\")\n",
    "print(\"→ EXPECTATION: Initial reviews will be mixed - normal pattern\")\n",
    "print(\"→ PAYOFF: Films gain appreciation over 4-5 years\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. LATENT FACTORS (PCA - 5 COMPONENTS)\")\n",
    "print(\"=\"*80)\n",
    "print(\"✓ PC1 (13%): Review depth - detailed analysis vs brief reactions\")\n",
    "print(\"✓ PC2 (9%): Linguistic sophistication - academic vs casual\")\n",
    "print(\"✓ PC3 (7%): Negative engagement - controversial negativity\")\n",
    "print(\"✓ PC4 (6%): Polarization - divisive debates\")\n",
    "print(\"✓ PC5 (5%): Emotional accessibility - enthusiastic vs measured\")\n",
    "print(\"\\n→ INSIGHT: Folk horror generates DIVERSE response styles\")\n",
    "print(\"→ MARKETING: Appeal to both sophisticated analysts AND enthusiasts\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. CRITICAL SUCCESS FACTORS (Random Forest AUC=0.80)\")\n",
    "print(\"=\"*80)\n",
    "print(\"Top predictors of high performance (>7.0 rating):\")\n",
    "print(\"  1. Movie release year (temporal effect)\")\n",
    "print(\"  2. Years since release (legacy building)\")\n",
    "print(\"  3. Positive sentiment\")\n",
    "print(\"  4. Compound sentiment\")\n",
    "print(\"  5. Noun ratio (substantive language)\")\n",
    "print(\"\\n→ POSITIONING: Build anticipation for a film that will GROW in stature\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"6. GENDER EFFECTS (MINIMAL)\")\n",
    "print(\"=\"*80)\n",
    "print(\"✓ Males: 6.53 rating (n=2,146)\")\n",
    "print(\"✓ Females: 6.15 rating (n=444)\")\n",
    "print(\"✓ Difference: p=0.007 but Cohen's d=0.14 (negligible)\")\n",
    "print(\"\\n→ MARKETING: Don't over-gender the campaign - appeal is universal\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RECOMMENDATION FOR 'ROOTS'\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "POSITIONING STRATEGY:\n",
    "- Frame as a LEGACY folk horror film, not just a theatrical release\n",
    "- Emphasize EMOTIONAL DEPTH (fear + anticipation, avoid disgust)\n",
    "- Target sophisticated horror fans who write detailed reviews\n",
    "- Prepare for mixed opening-year reception (normal pattern)\n",
    "- Build long-term festival/streaming strategy (5+ year appreciation)\n",
    "\n",
    "MARKETING GUARDRAILS:\n",
    "- Avoid misleading trailers that trigger hate/disgust\n",
    "- Don't overpromise - let quality speak for itself\n",
    "- Minimize question-inducing marketing (clarity > mystery overload)\n",
    "- Generate positive sentiment early with influencer screenings\n",
    "\n",
    "AUDIENCE TARGETING:\n",
    "- Primary: \"The Lovers\" (52% - positive, enthusiastic, trust-based)\n",
    "- Secondary: \"Conflicted Critics\" (44% - sophisticated, reachable)\n",
    "- Avoid: Triggering \"The Haters\" (4% - vocal but small)\n",
    "\n",
    "SUCCESS METRICS:\n",
    "- Opening year: Target 6.0+ rating (on par with successful folk horror)\n",
    "- Year 5+: Target 7.5+ rating (legacy appreciation)\n",
    "- Sentiment: Maintain vader_compound > 0.3 (positive territory)\n",
    "- Minimize hate_count < 0.15 per review\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n✅ Analysis complete - ready for investor presentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea6edd5-c451-4bd4-8765-a777446c54d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
