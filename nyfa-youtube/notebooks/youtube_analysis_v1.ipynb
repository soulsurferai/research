{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Competitive Analysis\n",
    "## Film Education Channels Strategic Comparison\n",
    "\n",
    "**Version:** 1.0  \n",
    "**Created:** December 13, 2025  \n",
    "**Purpose:** Analyze YouTube channel performance across film education competitors to identify strategic opportunities for NYFA\n",
    "\n",
    "---\n",
    "\n",
    "### Changelog\n",
    "- **v1.0** (2025-12-13): Initial notebook creation with NYFA and Film Courage data\n",
    "\n",
    "---\n",
    "\n",
    "### Analysis Sections\n",
    "1. Data Loading & Validation\n",
    "2. Channel Overview Comparison\n",
    "3. Publishing Strategy Analysis\n",
    "4. Performance Metrics (Time-Normalized)\n",
    "5. Content Strategy Analysis\n",
    "6. Temporal Trends\n",
    "7. Strategic Insights & Recommendations\n",
    "8. Export LLM-Optimized Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Parameters\n",
    "# Modify these to change analysis behavior\n",
    "\n",
    "CONFIG = {\n",
    "    'data_dir': Path('../data'),\n",
    "    'output_dir': Path('./output'),\n",
    "    'charts_dir': Path('./output/charts'),\n",
    "    \n",
    "    # Analysis parameters\n",
    "    'min_video_age_days': 30,  # Exclude videos younger than this from performance analysis\n",
    "    'recent_period_days': 365,  # Define 'recent' as last N days\n",
    "    'top_performers_pct': 0.10,  # Top 10% of videos\n",
    "    \n",
    "    # Date parameters\n",
    "    'analysis_date': datetime.now().strftime('%Y%m%d'),\n",
    "    'report_date': datetime.now().strftime('%Y-%m-%d'),\n",
    "    \n",
    "    # Output parameters\n",
    "    'save_charts': True,\n",
    "    'chart_dpi': 300,\n",
    "    'chart_format': 'png'\n",
    "}\n",
    "\n",
    "# Helper function to get timezone-aware cutoff dates\n",
    "def get_cutoff_date(days_ago):\n",
    "    \"\"\"Return timezone-aware cutoff date for filtering\"\"\"\n",
    "    return pd.Timestamp(datetime.now(), tz='UTC') - timedelta(days=days_ago)\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "CONFIG['output_dir'].mkdir(exist_ok=True)\n",
    "CONFIG['charts_dir'].mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"✓ Configuration loaded\")\n",
    "print(f\"  - Analysis date: {CONFIG['report_date']}\")\n",
    "print(f\"  - Minimum video age: {CONFIG['min_video_age_days']} days\")\n",
    "print(f\"  - Recent period: {CONFIG['recent_period_days']} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_channel_data(data_dir):\n",
    "    \"\"\"\n",
    "    Load all CSV files from data directory.\n",
    "    Returns a dictionary of DataFrames keyed by channel name.\n",
    "    \"\"\"\n",
    "    channels = {}\n",
    "    csv_files = list(data_dir.glob('*.csv'))\n",
    "    \n",
    "    # Exclude tableau files\n",
    "    csv_files = [f for f in csv_files if 'tableau' not in f.name.lower()]\n",
    "    \n",
    "    print(f\"Found {len(csv_files)} channel data files:\")\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        # Extract channel name from filename (before the date)\n",
    "        channel_name = csv_file.stem.split('_')[0]\n",
    "        \n",
    "        # Load data\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Convert published_date to datetime\n",
    "        df['published_date'] = pd.to_datetime(df['published_date'])\n",
    "        \n",
    "        # Add year and month columns for temporal analysis\n",
    "        df['year'] = df['published_date'].dt.year\n",
    "        df['month'] = df['published_date'].dt.month\n",
    "        df['year_month'] = df['published_date'].dt.to_period('M')\n",
    "        \n",
    "        channels[channel_name] = df\n",
    "        \n",
    "        print(f\"  ✓ {channel_name}: {len(df):,} videos ({df['published_date'].min().year}-{df['published_date'].max().year})\")\n",
    "    \n",
    "    return channels\n",
    "\n",
    "# Load all channel data\n",
    "channels = load_channel_data(CONFIG['data_dir'])\n",
    "print(f\"\\n✓ Loaded {len(channels)} channels successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data validation: Check for required columns\n",
    "required_columns = ['video_id', 'title', 'description', 'published_date', 'duration_seconds',\n",
    "                   'view_count', 'like_count', 'comment_count', 'views_per_day', 'engagement_rate']\n",
    "\n",
    "print(\"Data Validation:\")\n",
    "for channel_name, df in channels.items():\n",
    "    missing_cols = set(required_columns) - set(df.columns)\n",
    "    if missing_cols:\n",
    "        print(f\"  ⚠ {channel_name}: Missing columns {missing_cols}\")\n",
    "    else:\n",
    "        print(f\"  ✓ {channel_name}: All required columns present\")\n",
    "        \n",
    "    # Check for nulls in critical columns\n",
    "    null_counts = df[required_columns].isnull().sum()\n",
    "    if null_counts.any():\n",
    "        print(f\"    Note: Null values found:\")\n",
    "        print(null_counts[null_counts > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Channel Overview Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create channel overview summary\n",
    "overview_data = []\n",
    "\n",
    "for channel_name, df in channels.items():\n",
    "    # Filter for mature videos (>30 days old) for performance metrics\n",
    "    mature_videos = df[df['days_since_published'] >= CONFIG['min_video_age_days']]\n",
    "    \n",
    "    overview_data.append({\n",
    "        'Channel': channel_name,\n",
    "        'Total Videos': len(df),\n",
    "        'Date Range': f\"{df['year'].min()}-{df['year'].max()}\",\n",
    "        'Total Views': df['view_count'].sum(),\n",
    "        'Total Engagement': (df['like_count'].sum() + df['comment_count'].sum()),\n",
    "        'Avg Views/Day (Mature)': mature_videos['views_per_day'].median(),\n",
    "        'Avg Engagement Rate': df['engagement_rate'].mean() * 100,\n",
    "        'Median Duration (min)': df['duration_seconds'].median() / 60,\n",
    "    })\n",
    "\n",
    "overview_df = pd.DataFrame(overview_data)\n",
    "overview_df = overview_df.sort_values('Avg Views/Day (Mature)', ascending=False)\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"CHANNEL OVERVIEW COMPARISON\")\n",
    "print(\"=\" * 100)\n",
    "print(overview_df.to_string(index=False))\n",
    "print(\"\\nNote: 'Mature' videos are those published >30 days ago to allow algorithm settling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize channel comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Channel Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Total Videos\n",
    "ax1 = axes[0, 0]\n",
    "overview_df.plot(x='Channel', y='Total Videos', kind='bar', ax=ax1, color='steelblue')\n",
    "ax1.set_title('Total Videos Published')\n",
    "ax1.set_ylabel('Video Count')\n",
    "ax1.set_xlabel('')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Views per Day (Time-Normalized Performance)\n",
    "ax2 = axes[0, 1]\n",
    "overview_df.plot(x='Channel', y='Avg Views/Day (Mature)', kind='bar', ax=ax2, color='coral')\n",
    "ax2.set_title('Avg Views/Day (Time-Normalized)')\n",
    "ax2.set_ylabel('Views per Day')\n",
    "ax2.set_xlabel('')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Engagement Rate\n",
    "ax3 = axes[1, 0]\n",
    "overview_df.plot(x='Channel', y='Avg Engagement Rate', kind='bar', ax=ax3, color='mediumseagreen')\n",
    "ax3.set_title('Average Engagement Rate')\n",
    "ax3.set_ylabel('Engagement Rate (%)')\n",
    "ax3.set_xlabel('')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Median Video Duration\n",
    "ax4 = axes[1, 1]\n",
    "overview_df.plot(x='Channel', y='Median Duration (min)', kind='bar', ax=ax4, color='mediumpurple')\n",
    "ax4.set_title('Median Video Duration')\n",
    "ax4.set_ylabel('Minutes')\n",
    "ax4.set_xlabel('')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if CONFIG['save_charts']:\n",
    "    plt.savefig(CONFIG['charts_dir'] / f\"channel_comparison_{CONFIG['analysis_date']}.png\", \n",
    "                dpi=CONFIG['chart_dpi'], bbox_inches='tight')\n",
    "    print(f\"✓ Chart saved to {CONFIG['charts_dir']}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Publishing Strategy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate publishing velocity by year for each channel\n",
    "print(\"=\" * 100)\n",
    "print(\"PUBLISHING VELOCITY ANALYSIS (Videos per Month)\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for channel_name, df in channels.items():\n",
    "    print(f\"\\n{channel_name.upper()}:\")\n",
    "    \n",
    "    # Group by year and calculate videos per month\n",
    "    yearly_stats = df.groupby('year').agg({\n",
    "        'video_id': 'count',\n",
    "        'year_month': 'nunique'\n",
    "    }).rename(columns={'video_id': 'total_videos', 'year_month': 'active_months'})\n",
    "    \n",
    "    yearly_stats['videos_per_month'] = yearly_stats['total_videos'] / yearly_stats['active_months']\n",
    "    \n",
    "    print(yearly_stats.to_string())\n",
    "    \n",
    "    # Calculate recent velocity (last 12 months)\n",
    "    cutoff_date = pd.Timestamp(datetime.now(), tz='UTC') - timedelta(days=CONFIG['recent_period_days'])  # FIXED\n",
    "    recent_df = df[df['published_date'] >= cutoff_date]\n",
    "    recent_months = recent_df['year_month'].nunique()\n",
    "    recent_velocity = len(recent_df) / recent_months if recent_months > 0 else 0\n",
    "    \n",
    "    print(f\"\\nRecent Velocity (last {CONFIG['recent_period_days']} days): {recent_velocity:.1f} videos/month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize publishing trends over time\n",
    "fig, axes = plt.subplots(len(channels), 1, figsize=(14, 6 * len(channels)))\n",
    "if len(channels) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "fig.suptitle('Publishing Velocity Trends (Videos per Month)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (channel_name, df) in enumerate(channels.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Calculate monthly publishing counts\n",
    "    monthly_counts = df.groupby('year_month').size()\n",
    "    monthly_counts.index = monthly_counts.index.to_timestamp()\n",
    "    \n",
    "    # Plot\n",
    "    monthly_counts.plot(ax=ax, linewidth=2, marker='o', markersize=4)\n",
    "    ax.set_title(f\"{channel_name} - Publishing Pattern\")\n",
    "    ax.set_ylabel('Videos per Month')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(range(len(monthly_counts)), monthly_counts.values, 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax.plot(monthly_counts.index, p(range(len(monthly_counts))), \n",
    "            \"r--\", alpha=0.5, linewidth=2, label='Trend')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if CONFIG['save_charts']:\n",
    "    plt.savefig(CONFIG['charts_dir'] / f\"publishing_velocity_{CONFIG['analysis_date']}.png\", \n",
    "                dpi=CONFIG['chart_dpi'], bbox_inches='tight')\n",
    "    print(f\"✓ Chart saved\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Metrics (Time-Normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed performance analysis for mature videos\n",
    "print(\"=\" * 100)\n",
    "print(\"TIME-NORMALIZED PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"(Analyzing videos published >{CONFIG['min_video_age_days']} days ago)\\n\")\n",
    "\n",
    "performance_data = []\n",
    "\n",
    "for channel_name, df in channels.items():\n",
    "    mature = df[df['days_since_published'] >= CONFIG['min_video_age_days']]\n",
    "    \n",
    "    perf = {\n",
    "        'Channel': channel_name,\n",
    "        'Videos Analyzed': len(mature),\n",
    "        'Median Views/Day': mature['views_per_day'].median(),\n",
    "        'Mean Views/Day': mature['views_per_day'].mean(),\n",
    "        '75th Percentile Views/Day': mature['views_per_day'].quantile(0.75),\n",
    "        'Median Engagement %': mature['engagement_rate'].median() * 100,\n",
    "        'Top 10% Avg Views/Day': mature.nlargest(int(len(mature) * 0.1), 'views_per_day')['views_per_day'].mean(),\n",
    "    }\n",
    "    performance_data.append(perf)\n",
    "\n",
    "perf_df = pd.DataFrame(performance_data)\n",
    "perf_df = perf_df.sort_values('Median Views/Day', ascending=False)\n",
    "\n",
    "print(perf_df.to_string(index=False))\n",
    "\n",
    "# Calculate efficiency ratios\n",
    "if len(channels) > 1:\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"EFFICIENCY RATIOS (vs NYFA)\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    nyfa_vpd = perf_df[perf_df['Channel'] == 'newyorkfilmacademy']['Median Views/Day'].values[0]\n",
    "    \n",
    "    for _, row in perf_df.iterrows():\n",
    "        if row['Channel'] != 'newyorkfilmacademy':\n",
    "            ratio = row['Median Views/Day'] / nyfa_vpd\n",
    "            print(f\"{row['Channel']}: {ratio:.1f}x more efficient than NYFA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution visualization - Views per Day\n",
    "fig, axes = plt.subplots(1, len(channels), figsize=(8 * len(channels), 6))\n",
    "if len(channels) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "fig.suptitle('Views per Day Distribution (Log Scale)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (channel_name, df) in enumerate(channels.items()):\n",
    "    ax = axes[idx]\n",
    "    mature = df[df['days_since_published'] >= CONFIG['min_video_age_days']]\n",
    "    \n",
    "    # Filter out zeros for log scale\n",
    "    vpd_data = mature[mature['views_per_day'] > 0]['views_per_day']\n",
    "    \n",
    "    ax.hist(vpd_data, bins=50, edgecolor='black', alpha=0.7)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_title(f\"{channel_name}\\nMedian: {vpd_data.median():.1f} views/day\")\n",
    "    ax.set_xlabel('Views per Day (log scale)')\n",
    "    ax.set_ylabel('Video Count (log scale)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add median line\n",
    "    ax.axvline(vpd_data.median(), color='red', linestyle='--', linewidth=2, label='Median')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if CONFIG['save_charts']:\n",
    "    plt.savefig(CONFIG['charts_dir'] / f\"vpd_distribution_{CONFIG['analysis_date']}.png\", \n",
    "                dpi=CONFIG['chart_dpi'], bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Content Strategy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video length analysis\n",
    "print(\"=\" * 100)\n",
    "print(\"VIDEO LENGTH ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for channel_name, df in channels.items():\n",
    "    print(f\"\\n{channel_name.upper()}:\")\n",
    "    \n",
    "    # Create duration buckets\n",
    "    df['duration_minutes'] = df['duration_seconds'] / 60\n",
    "    df['duration_bucket'] = pd.cut(df['duration_minutes'], \n",
    "                                    bins=[0, 5, 10, 20, 30, 60, float('inf')],\n",
    "                                    labels=['0-5 min', '5-10 min', '10-20 min', '20-30 min', '30-60 min', '60+ min'])\n",
    "    \n",
    "    # Analyze performance by duration bucket\n",
    "    mature = df[df['days_since_published'] >= CONFIG['min_video_age_days']]\n",
    "    \n",
    "    length_analysis = mature.groupby('duration_bucket').agg({\n",
    "        'video_id': 'count',\n",
    "        'views_per_day': 'median',\n",
    "        'engagement_rate': 'median'\n",
    "    }).rename(columns={\n",
    "        'video_id': 'video_count',\n",
    "        'views_per_day': 'median_vpd',\n",
    "        'engagement_rate': 'median_engagement'\n",
    "    })\n",
    "    \n",
    "    length_analysis['median_engagement'] *= 100  # Convert to percentage\n",
    "    \n",
    "    print(length_analysis.to_string())\n",
    "    \n",
    "    # Identify optimal length\n",
    "    best_bucket = length_analysis['median_vpd'].idxmax()\n",
    "    print(f\"\\nOptimal Length Range: {best_bucket} ({length_analysis.loc[best_bucket, 'median_vpd']:.1f} views/day)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Duration vs Performance\n",
    "fig, axes = plt.subplots(1, len(channels), figsize=(8 * len(channels), 6))\n",
    "if len(channels) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "fig.suptitle('Video Duration vs Performance', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (channel_name, df) in enumerate(channels.items()):\n",
    "    ax = axes[idx]\n",
    "    mature = df[df['days_since_published'] >= CONFIG['min_video_age_days']]\n",
    "    \n",
    "    # Filter outliers for better visualization\n",
    "    plot_data = mature[\n",
    "        (mature['duration_minutes'] > 0) & \n",
    "        (mature['duration_minutes'] < 120) &\n",
    "        (mature['views_per_day'] > 0)\n",
    "    ]\n",
    "    \n",
    "    ax.scatter(plot_data['duration_minutes'], plot_data['views_per_day'], \n",
    "              alpha=0.4, s=30)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_title(f\"{channel_name}\")\n",
    "    ax.set_xlabel('Video Duration (minutes)')\n",
    "    ax.set_ylabel('Views per Day (log scale)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if CONFIG['save_charts']:\n",
    "    plt.savefig(CONFIG['charts_dir'] / f\"duration_vs_performance_{CONFIG['analysis_date']}.png\", \n",
    "                dpi=CONFIG['chart_dpi'], bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Top Performers Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and analyze top performers\n",
    "print(\"=\" * 100)\n",
    "print(\"TOP PERFORMERS (by Views per Day)\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for channel_name, df in channels.items():\n",
    "    print(f\"\\n{channel_name.upper()} - Top 10 Videos:\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    mature = df[df['days_since_published'] >= CONFIG['min_video_age_days']]\n",
    "    top_videos = mature.nlargest(10, 'views_per_day')[[\n",
    "        'title', 'views_per_day', 'engagement_rate', 'duration_minutes', 'year'\n",
    "    ]].copy()\n",
    "    \n",
    "    top_videos['engagement_rate'] *= 100\n",
    "    top_videos = top_videos.rename(columns={\n",
    "        'views_per_day': 'VPD',\n",
    "        'engagement_rate': 'Eng %',\n",
    "        'duration_minutes': 'Duration (min)'\n",
    "    })\n",
    "    \n",
    "    print(top_videos.to_string(index=False))\n",
    "    \n",
    "    # Analyze common characteristics\n",
    "    print(f\"\\nTop 10% Characteristics:\")\n",
    "    top_pct = mature.nlargest(int(len(mature) * CONFIG['top_performers_pct']), 'views_per_day')\n",
    "    print(f\"  Average VPD: {top_pct['views_per_day'].mean():.1f}\")\n",
    "    print(f\"  Average Duration: {top_pct['duration_minutes'].mean():.1f} minutes\")\n",
    "    print(f\"  Average Engagement: {top_pct['engagement_rate'].mean() * 100:.2f}%\")\n",
    "    print(f\"  Most Common Length: {top_pct['duration_bucket'].mode().values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Strategic Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate strategic insights\n",
    "insights = {\n",
    "    'analysis_date': CONFIG['report_date'],\n",
    "    'channels_analyzed': list(channels.keys()),\n",
    "    'key_metrics': {},\n",
    "    'comparative_insights': [],\n",
    "    'recommendations': []\n",
    "}\n",
    "\n",
    "# Calculate key metrics for each channel\n",
    "for channel_name, df in channels.items():\n",
    "    mature = df[df['days_since_published'] >= CONFIG['min_video_age_days']]\n",
    "    recent_df = df[df['published_date'] >= get_cutoff_date(CONFIG['recent_period_days'])]\n",
    "    \n",
    "    insights['key_metrics'][channel_name] = {\n",
    "        'total_videos': len(df),\n",
    "        'median_vpd': float(mature['views_per_day'].median()),\n",
    "        'engagement_rate': float(mature['engagement_rate'].median()),\n",
    "        'recent_publishing_velocity': float(len(recent_df) / 12),\n",
    "        'median_duration_minutes': float(df['duration_seconds'].median() / 60),\n",
    "        'top_10pct_avg_vpd': float(mature.nlargest(int(len(mature) * 0.1), 'views_per_day')['views_per_day'].mean())\n",
    "    }\n",
    "\n",
    "# Generate comparative insights if multiple channels\n",
    "if len(channels) > 1:\n",
    "    if 'newyorkfilmacademy' in insights['key_metrics']:\n",
    "        nyfa_vpd = insights['key_metrics']['newyorkfilmacademy']['median_vpd']\n",
    "        \n",
    "        for ch_name, metrics in insights['key_metrics'].items():\n",
    "            if ch_name != 'newyorkfilmacademy':\n",
    "                efficiency_ratio = metrics['median_vpd'] / nyfa_vpd\n",
    "                insights['comparative_insights'].append(\n",
    "                    f\"{ch_name} is {efficiency_ratio:.1f}x more efficient than NYFA (median views/day)\"\n",
    "                )\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"STRATEGIC INSIGHTS\")\n",
    "print(\"=\" * 100)\n",
    "print(json.dumps(insights, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate strategic insights\n",
    "insights = {\n",
    "    'analysis_date': CONFIG['report_date'],\n",
    "    'channels_analyzed': list(channels.keys()),\n",
    "    'key_metrics': {},\n",
    "    'comparative_insights': [],\n",
    "    'recommendations': []\n",
    "}\n",
    "\n",
    "# Calculate key metrics for each channel\n",
    "for channel_name, df in channels.items():\n",
    "    mature = df[df['days_since_published'] >= CONFIG['min_video_age_days']]\n",
    "    recent_df = df[df['published_date'] >= get_cutoff_date(CONFIG['recent_period_days'])]\n",
    "    \n",
    "    insights['key_metrics'][channel_name] = {\n",
    "        'total_videos': len(df),\n",
    "        'median_vpd': float(mature['views_per_day'].median()),\n",
    "        'engagement_rate': float(mature['engagement_rate'].median()),\n",
    "        'recent_publishing_velocity': float(len(recent_df) / 12),\n",
    "        'median_duration_minutes': float(df['duration_seconds'].median() / 60),\n",
    "        'top_10pct_avg_vpd': float(mature.nlargest(int(len(mature) * 0.1), 'views_per_day')['views_per_day'].mean())\n",
    "    }\n",
    "\n",
    "# Generate comparative insights if multiple channels\n",
    "if len(channels) > 1:\n",
    "    if 'newyorkfilmacademy' in insights['key_metrics']:\n",
    "        nyfa_vpd = insights['key_metrics']['newyorkfilmacademy']['median_vpd']\n",
    "        \n",
    "        for ch_name, metrics in insights['key_metrics'].items():\n",
    "            if ch_name != 'newyorkfilmacademy':\n",
    "                efficiency_ratio = metrics['median_vpd'] / nyfa_vpd\n",
    "                insights['comparative_insights'].append(\n",
    "                    f\"{ch_name} is {efficiency_ratio:.1f}x more efficient than NYFA (median views/day)\"\n",
    "                )\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"STRATEGIC INSIGHTS\")\n",
    "print(\"=\" * 100)\n",
    "print(json.dumps(insights, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate strategic insights\n",
    "insights = {\n",
    "    'analysis_date': CONFIG['report_date'],\n",
    "    'channels_analyzed': list(channels.keys()),\n",
    "    'key_metrics': {},\n",
    "    'comparative_insights': [],\n",
    "    'recommendations': []\n",
    "}\n",
    "\n",
    "# Calculate key metrics for each channel\n",
    "for channel_name, df in channels.items():\n",
    "    mature = df[df['days_since_published'] >= CONFIG['min_video_age_days']]\n",
    "    recent_df = df[df['published_date'] >= get_cutoff_date(CONFIG['recent_period_days'])]\n",
    "    \n",
    "    insights['key_metrics'][channel_name] = {\n",
    "        'total_videos': len(df),\n",
    "        'median_vpd': float(mature['views_per_day'].median()),\n",
    "        'engagement_rate': float(mature['engagement_rate'].median()),\n",
    "        'recent_publishing_velocity': float(len(recent_df) / 12),\n",
    "        'median_duration_minutes': float(df['duration_seconds'].median() / 60),\n",
    "        'top_10pct_avg_vpd': float(mature.nlargest(int(len(mature) * 0.1), 'views_per_day')['views_per_day'].mean())\n",
    "    }\n",
    "\n",
    "# Generate comparative insights if multiple channels\n",
    "if len(channels) > 1:\n",
    "    if 'newyorkfilmacademy' in insights['key_metrics']:\n",
    "        nyfa_vpd = insights['key_metrics']['newyorkfilmacademy']['median_vpd']\n",
    "        \n",
    "        for ch_name, metrics in insights['key_metrics'].items():\n",
    "            if ch_name != 'newyorkfilmacademy':\n",
    "                efficiency_ratio = metrics['median_vpd'] / nyfa_vpd\n",
    "                insights['comparative_insights'].append(\n",
    "                    f\"{ch_name} is {efficiency_ratio:.1f}x more efficient than NYFA (median views/day)\"\n",
    "                )\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"STRATEGIC INSIGHTS\")\n",
    "print(\"=\" * 100)\n",
    "print(json.dumps(insights, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate strategic insights\n",
    "insights = {\n",
    "    'analysis_date': CONFIG['report_date'],\n",
    "    'channels_analyzed': list(channels.keys()),\n",
    "    'key_metrics': {},\n",
    "    'comparative_insights': [],\n",
    "    'recommendations': []\n",
    "}\n",
    "\n",
    "# Calculate key metrics for each channel\n",
    "for channel_name, df in channels.items():\n",
    "    mature = df[df['days_since_published'] >= CONFIG['min_video_age_days']]\n",
    "    recent_df = df[df['published_date'] >= pd.Timestamp(datetime.now(), tz='UTC') - timedelta(days=CONFIG['recent_period_days'])]\n",
    "    \n",
    "    insights['key_metrics'][channel_name] = {\n",
    "        'total_videos': len(df),\n",
    "        'median_vpd': float(mature['views_per_day'].median()),\n",
    "        'engagement_rate': float(mature['engagement_rate'].median()),\n",
    "        'recent_publishing_velocity': float(len(recent_df) / 12),  # videos per month\n",
    "        'median_duration_minutes': float(df['duration_seconds'].median() / 60),\n",
    "        'top_10pct_avg_vpd': float(mature.nlargest(int(len(mature) * 0.1), 'views_per_day')['views_per_day'].mean())\n",
    "    }\n",
    "\n",
    "# Generate comparative insights if multiple channels\n",
    "if len(channels) > 1:\n",
    "    # Find NYFA's metrics\n",
    "    if 'newyorkfilmacademy' in insights['key_metrics']:\n",
    "        nyfa_vpd = insights['key_metrics']['newyorkfilmacademy']['median_vpd']\n",
    "        \n",
    "        for ch_name, metrics in insights['key_metrics'].items():\n",
    "            if ch_name != 'newyorkfilmacademy':\n",
    "                efficiency_ratio = metrics['median_vpd'] / nyfa_vpd\n",
    "                insights['comparative_insights'].append(\n",
    "                    f\"{ch_name} is {efficiency_ratio:.1f}x more efficient than NYFA (median views/day)\"\n",
    "                )\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"STRATEGIC INSIGHTS\")\n",
    "print(\"=\" * 100)\n",
    "print(json.dumps(insights, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export LLM-Optimized Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate markdown report\n",
    "report_lines = [\n",
    "    \"# YouTube Competitive Analysis Report\",\n",
    "    f\"**Generated:** {CONFIG['report_date']}\",\n",
    "    f\"**Channels Analyzed:** {', '.join(channels.keys())}\",\n",
    "    \"\",\n",
    "    \"---\",\n",
    "    \"\",\n",
    "    \"## Executive Summary\",\n",
    "    \"\",\n",
    "    f\"This analysis examines {len(channels)} YouTube channels in the film education space, \",\n",
    "    f\"analyzing {sum(len(df) for df in channels.values()):,} total videos to identify \",\n",
    "    \"strategic opportunities and competitive positioning.\",\n",
    "    \"\",\n",
    "    \"### Key Findings\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "# Add key findings\n",
    "for idx, insight in enumerate(insights['comparative_insights'], 1):\n",
    "    report_lines.append(f\"{idx}. {insight}\")\n",
    "\n",
    "report_lines.extend([\"\", \"---\", \"\", \"## Channel Overview Comparison\", \"\"])\n",
    "report_lines.append(overview_df.to_markdown(index=False))\n",
    "\n",
    "report_lines.extend([\"\", \"\", \"---\", \"\", \"## Performance Metrics (Time-Normalized)\", \"\"])\n",
    "report_lines.append(perf_df.to_markdown(index=False))\n",
    "\n",
    "report_lines.extend([\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"---\",\n",
    "    \"\",\n",
    "    \"## Strategic Recommendations\",\n",
    "    \"\",\n",
    "    \"### Immediate Actions (Week 1)\",\n",
    "    \"- [ ] Analyze top performer titles for pattern recognition\",\n",
    "    \"- [ ] Benchmark current publishing velocity against competitors\",\n",
    "    \"- [ ] Identify optimal video length range for content planning\",\n",
    "    \"\",\n",
    "    \"### Short-term Improvements (30-90 days)\",\n",
    "    \"- [ ] Increase publishing consistency to match competitor velocity\",\n",
    "    \"- [ ] Test optimal length formats identified in analysis\",\n",
    "    \"- [ ] Develop content series based on top performer patterns\",\n",
    "    \"\",\n",
    "    \"### Long-term Strategic Shifts (6-12 months)\",\n",
    "    \"- [ ] Build systematic content production pipeline\",\n",
    "    \"- [ ] Develop signature content formats\",\n",
    "    \"- [ ] Implement data-driven optimization process\",\n",
    "    \"\",\n",
    "    \"---\",\n",
    "    \"\",\n",
    "    \"## Methodology Notes\",\n",
    "    \"\",\n",
    "    f\"- **Time Normalization:** All performance metrics use views per day to account for video age\",\n",
    "    f\"- **Mature Videos:** Analysis excludes videos <{CONFIG['min_video_age_days']} days old\",\n",
    "    f\"- **Recent Period:** Defined as last {CONFIG['recent_period_days']} days\",\n",
    "    \"- **Engagement Rate:** (Likes + Comments) / Views\",\n",
    "    \"\",\n",
    "    \"---\",\n",
    "    \"\",\n",
    "    \"*End of Report*\"\n",
    "])\n",
    "\n",
    "report_text = \"\\n\".join(report_lines)\n",
    "\n",
    "# Save markdown report\n",
    "report_path = CONFIG['output_dir'] / f\"analysis_{CONFIG['analysis_date']}.md\"\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(report_text)\n",
    "\n",
    "print(f\"✓ Markdown report saved to: {report_path}\")\n",
    "\n",
    "# Save JSON insights\n",
    "json_path = CONFIG['output_dir'] / f\"insights_{CONFIG['analysis_date']}.json\"\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(insights, f, indent=2)\n",
    "\n",
    "print(f\"✓ JSON insights saved to: {json_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"\\nOutputs generated:\")\n",
    "print(f\"  - Markdown report: {report_path.name}\")\n",
    "print(f\"  - JSON insights: {json_path.name}\")\n",
    "print(f\"  - Charts: {len(list(CONFIG['charts_dir'].glob('*.png')))} files in {CONFIG['charts_dir']}\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"  1. Review markdown report for strategic insights\")\n",
    "print(f\"  2. Share findings with leadership\")\n",
    "print(f\"  3. Add more competitor data and re-run analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
